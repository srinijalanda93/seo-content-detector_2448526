url,title,body_text,word_count
https://www.cm-alliance.com/cybersecurity-blog,Cyber Security Blog,"Cyber Crisis Tabletop Exercise Cyber Security Awareness Training for Executives Prepare to respond to ransomware attacks Learn how to Plan, Produce  Conduct Tabletop Exercises Validate your ransomware readiness Is your organisation data-breach ready? One-window view of all security activity Assess your cyber incident response  crisis readiness Check your cyber health  readiness to respond to cyber-attacks Recognise cybersecurity strengths  identify improvements Implement and achieve ISO 27001 certification Secure the Weakest Link in your Cyber Security Chain Full support Security as a Service Cybersecurity Advisory Services Subscription-based, remote cybersecurity service Training, Plans and Templates Strengthen Your Cyber Defences with Bespoke IR Plans CreatedReviewed Custom Incident Response Playbooks Respond effectively to cybersecurity incidents with our experts Check out our Events Calendar to know about upcoming events Look at past events  see how they helped our clients Hear from our clients about the ROI achieved through our live events Showcase your productsservices to an engaged niche audience Connect with cybersecurity decision-makers in an intimate setting Keynote addresses by our sponsors at Wisdom of Crowds events Digital content assets to elevate your marketing activities Visit our Blog Highly engaged discussions with an experienced CISO Our flagship event for live open discussion and collaboration. CMA Case Studies Cybersecurity Training and Consultancy Cyber Security Training Feedback A few of our Global Training  Consultancy Clients Cyber Management Alliance Advisory and Management Team Contact Cyber Management Alliance About Us Cyber Management Alliance Headquartered in London UK, Cyber Management Alliance Ltd. is a world leader in cybersecurity consultancy and training. We have enabled over 750 enterprise clients in 38 countries, including FIFA, NHS, Capita, BNP Paribas and Unilever, across all verticals to strengthen their cyber defences. Cyber Management Alliance is also renowned globally as the creator of the UKs NCSC-Certified training courses in Incident Response. 44 (0) 203 189 1422 infocm-alliance.com 71-75 Shelton Street, Covent Garden, London, WC2H 9JQ See below list of our core services  free cybersecurity resources:",319
https://www.varonis.com/blog/cybersecurity-tips,Top 10 Cybersecurity Awareness Tips: How to Stay Safe and Proactive,"Cybersecurity is gaining more importance globally as technology continues to advance. The emphasis on security stems from the need for organizations to be prepared for when, not if, a data breach occurs. Unfortunately, human error is often the cause of breaches. Understanding how to combat cyberattacks is crucial, as protecting sensitive information is everyone's responsibility in our data-driven world. In honor of Cybersecurity Awareness Month , weve compiled the top security tips you can implement to be more secure. By incorporating these tactics, you decrease the likelihood of your information or actions causing a catastrophic breach. Multifactor authentication adds an extra layer of security by verifying a user's identity through methods like receiving a verification code or clicking a link when logging in. Enabling MFA is crucial because the absence of it increases your vulnerability to risks. Attackers dont break in; they log in, said Joseph Avanzato, a forensics expert at Varonis, during a live session on understanding a threat actors mindset. Enable MFA for services that offer it and use an authenticator app if available. Report any unusual login attempts immediately. For organizations, it's best to require MFA and restrict the option to disable it. Its tempting to create a link accessible to anyone, rather than just specific users, in the event that additional stakeholders need access. However, Microsoft reports that only 1 of org-wide permissions granted are actually used. A vast amount of business documents contain sensitive information that shouldn't be accessible to everyone in the org, let alone anyone on the internet. Removing the ability to create org-wide links can significantly reduce your orgs blast radius. In the average company, 157,000 sensitive records are exposed to everyone on the internet through SaaS sharing features, representing 28 million in data-breach risk. Rather than opting for an over-permissioned link, users should share files directly with those who need access to do their job and invite others to access on a case-by-case basis. Social engineering and phishing tactics are still some of the most effective ways hackers gain access. Common signs of phishing include a peculiar sender address, a sense of urgency in the request, and prompting users to click a link. Phishing simulations are an effective way for organizations to educate teams on the impact of engaging with suspicious communications and encourage users to proactively look for scams. As a consumer or employee, its important to vet any unknown senders who contact you via text, email, and more. All it takes is one click to give threat actors keys to the data kingdom. To expand on tip number three, its not enough to shrug off a suspicious text message and call it a day. Most phishing attempts target more than one user in an organization, so if you receive one, report it to your IT department. Some companies have plug-ins within their email service or a dedicated inbox to forward suspicious activity to. Even a simple response to phishing attempts can backfire, so avoid engaging in any type of conversation. Additionally, never share information or make purchases without verifying the contacts identity. Administrative access in cloud platforms like Salesforce is powerful. At many organizations, existing admins can grant access to others in these tools without IT oversight. This results in too many users having escalated privileges and access to sensitive information. In Varonis DSPM Snapshot Report , we found that 60 of an average company's administrative accounts do not enable MFA, making it easier for attackers to compromise internally exposed data. Many orgs are unaware of the shared responsibility model , which holds SaaS providers accountable for securing a platform's infrastructure and providing a highly available solution, while consumers are responsible for protecting and securing their data within. When someone in your organization requests admin access to an application you manage, assess if the request is justified and consider setting an expiration for the permissions to maintain security. Coordinate with your IT and security teams to ensure all administrators understand the shared responsibility model and adhere to the established permission protocols. Imagine signing up for the latest social networking app, and to bypass filling out a lengthy form, you can simply connect it to your Gmail account, thus opening up access to your information stored within this app. But while setting this connection up is easy, its challenging to understand how the apps are configured and what access they have to information stored in your connected service. There is also the risk that apps contain vulnerabilities that threat actors could exploit. Through a single click, access can be granted to these malicious applications. The Varonis Threat Labs team created an attack scenario in which we created a realistic-looking app and used a phishing technique to convince a user to install an app and grant full access to their Microsoft 365 environment. While our scenario was a simulation, most hackers and ransomware groups wouldn't stop at gaining access and would further exploit the information they find. As the use of third-party apps rises, its essential to assess your connected apps and the risks involved with them. We recommend analyzing the permissions for each app and ranking their risk level as low, medium, or high. With Varonis, organizations can see how many employees use a third-party app and view their activity levels via automation or manual reporting. To avoid breaches, users who havent opened a high-risk app in the last six months should have their permissions revoked. You may want to consider disconnecting the app altogether if its not being used. As technology has evolved, the public expects access to Wi-Fi nearly everywhere they go, said Matt Radolec, Varonis Vice President of Incident Response and Cloud Operations, in an interview with CNBC . He added that users arent reading the terms and conditions or checking URLs when connecting to free Wi-Fi options, increasing their chances of compromise. Its almost a game to see how fast you can click accept and then sign in or connect. This is the ploy, especially when visiting a new location; a user might not even know what a legitimate site should look like when presented with a fake site, Matt said. Be cautious of free Wi-Fi networks you connect your device to, and make your computer forget them from your stored networks once you have finished your session. Large language models (LLMs) like ChatGPT can use your data to train their systems. If you share sensitive information during a chat, your data might unknowingly appear in another session or, even worse, in a hacker's hands. Tools like Microsoft 365 Copilot are also designed to access everything the user can, which is often far too much. Ensure your organization is ready to deploy AI tools safely before, during, and after rollout. Data privacy is a major concern regarding AI. Organizations recognize the need to safeguard privacy while maintaining AI functionality, which can be challenging. We want to leverage LLM technology, Varonis Security Architect Brock Bauer said during a webinar on LLM risks in the cloud . We want to give the productivity capabilities to our users, but we also need to protect the privacy of the data they're accessing. When using AI, always keep your sensitive details out of chats. Security teams should set up AI policies in their orgs and ensure employees are trained to properly use approved gen AI solutions. It can be pesky to see an automatic restart window pop up right in the middle of an important task, but the longer you wait to update your computer, the more misconfigurations remain unpatched. Patches are solutions to vulnerabilities discovered in different software and cloud platforms. In 2021, our research team identified a bug in Salesforce dubbed Einstein's Wormhole . This bug exposed calendar events that could contain highly sensitive data such as attendee names, emails, meeting URLs, passwords, and replies being sent to organizers. Before the bug was patched, meeting information with potentially sensitive information was exposed to the entire internet. Being proactive with your device and software updates decreases the likelihood of being compromised due to a misconfiguration. Password managers let users create complex passwords for all their sign-ins, preventing threat actors from accessing their accounts. Whether you use a password manager or not, it is important to create different passwords for different sites, opt for additional security measures like MFA, and set up alerts when logins occur from unknown devices or locations. These small best practices for password generation can be key to preventing data compromise in a breach. With breaches on the rise, its crucial to prioritize cybersecurity. Following these preventative cybersecurity tips can help you have stronger security practices at work and at home. For organizations, pairing effective training with top-tier security technology creates an ideal cybersecurity solution. Want to learn more? Get started with a free Data Risk Assessment to see if Varonis is the right match for you. Below are three ways you can continue your journey to reduce data risk at your company: Schedule a demo with us to see Varonis in action. We'll personalize the session to your org's data security needs and answer any questions. See a sample of our Data Risk Assessment and learn the risks that could be lingering in your environment. Varonis' DRA is completely free and offers a clear path to automated remediation. Follow us on LinkedIn , YouTube , and X (Twitter) for bite-sized insights on all things data security, including DSPM, threat detection, AI security, and more.",1578
https://www.cisecurity.org/insights/blog/11-cyber-defense-tips-to-stay-secure-at-work-and-home,11 Cyber Defense Tips to Stay Secure at Work and Home," Cybersecurity is inextricably tied to the technology it protects. Just as technology continues to grow in variety, quantity, and presence in all of our lives, so too does cybersecurity and our personal responsibility for it. You might be wondering how you can best act on this responsibility. The answer? Strengthen your cyber defense at home and at work. Provided below are 11 steps that you can use to get started. What are your cyber defense goals? Have you identified which devices and data you want to protect? What level of security do they need? By considering these and similar types of questions, you can start to formulate a cybersecurity roadmap that makes sense for you. Hover over a link to reveal the destination URL. If it looks different from the hyperlinked text, dont click on it. It could be an attempt to trick you into visiting a phishing landing page. To protect yourself against phishing attacks, search instead for your intended website or enter the URL directly into your browsers navigation bar. Speaking of phishing, if you receive a suspicious email at work, dont open or click on it. Instead, follow up with your IT andor security department. How can you tell a suspicious email from a legitimate one? The former will often use a sense of urgency, including a sale, an emergency, or a negative consequence such as an account closure, to motivate you to click on a link or open an email attachment. Don't fall for it. If you come across this type of email, just stop, breathe, and forward it to your IT andor your security department. If you receive this type of email on your personal device, delete the email and consider blocking the domain. Check out our short guide to phishing to learn more. Cyber threat actors (CTAs) can easily crack passwords like ""password,"" ""admin,"" or ""123456."" The same goes for dictionary-based passwords, or combinations made up of words that you can find in a dictionary. Instead of a simple password, try using a passphrase that sometimes substitutes numbers and symbols for letters. This unique approach can help you remember long strings for added security. As an example, consider the weak password cheese compared to the complex passphrases 1l0v3(h33s3 (modified from ""Ilovecheese"") or m0r3(h33s3pl3s3 (modified from ""morecheeseplease""). To properly secure your devices and data, protect your laptop, smartphone, and any other device you use with a secure passphrase such as the examples above. You can also consider using biometric passcodes if your device supports this option, or you can use a PIN or matric passcode for authentication. If you end up creating an alphanumeric passphrase with symbols, make sure you use unique combinations for each of your accounts. Remember that you can also generate passphrases using a password manager. The benefit there is that you can have the password manager remember each of your passwords so you don't have to. All you need to do is to protect access to your password manager with a strong passphrase and with multi-factor authentication (MFA). Check out our Password Policy Guide to learn more. To implement multi-factor authentication (MFA), you need to protect your account with authentication mechanisms from at least two of the following categories. Use a minimum of two-factor authentication (2FA) on any important accounts or computers where sensitive data is handled. That way, even if a CTA gains access to your username and password, they won't be able to access your account without the other factor(s). Always install the latest updates for your operating system, browser, and any applications installed on your device. CTAs try to use known vulnerabilities to access your devices andor other devices that are connected to the same network. Dont let yourself (or your organization) become an easy target. Before you connect to an unfamiliar andor public Wi-Fi network, think about the risks of doing so. What data might you share over the connection? To minimize the risk of data exposure, use a virtual private network (VPN). A VPN acts as a secure tunnel over the internet by creating an encrypted, private web connection. With a VPN, you can rest assured that your personal or work-related data is secure. Shopping online is a modern, everyday convenience. Protect sensitive banking data by only shopping on sites you trust. Never save your card information where it could be stolen and used later. Also, make sure to monitor your payment card records for unfamiliar charges. If you come across anything suspicious, reach out to the payment card issuer to dispute the charge and request a new payment card. Configuration sounds like a big responsibility  and it's an important part of your security program. But it really comes down to the settings for a particular program or machine. Securely configure your computer, printer, smartphone, and other web-connected devices in your home and your office. When online, remember to be thoughtful and to use polite language. Sharing someones private personal information online, also known as ""doxxing,"" is never okay and may get you in legal trouble. Dont plug your mobile devices into any outlet you find. Whether its a work or personal device, you could risk becoming the victim of juicejacking, a type of attack where CTAs compromise public USB charging stations to infect unsuspecting users with malware or data theft. If youre worried about running out of battery, bring a back-up power bank or charge your device using your own charging cable and a wall outlet. Want even more tips to stay safe at home and at work? As of June 23, 2025, the MS-ISAC has introduced a fee-based membership. Any potential reference to no-cost MS-ISAC services no longer applies.",945
https://www.cisa.gov/topics/cybersecurity-best-practices,Cybersecurity Best Practices | Cybersecurity and Infrastructure Security Agency CISA,"Cyberspace is particularly difficult to secure due to a number of factors: the ability of malicious actors to operate from anywhere in the world, the linkages between cyberspace and physical systems, and the difficulty of reducing vulnerabilities and consequences in complex cyber networks. Implementing safe cybersecurity best practices is important for individuals as well as organizations of all sizes. Using strong passwords, updating your software, thinking before you click on suspicious links, and turning on multi-factor authentication are the basics of what we call cyber hygiene and will drastically improve your online safety. These cybersecurity basics apply to both individuals and organizations. For both government and private entities, developing and implementing tailored cybersecurity plans and processes is key to protecting and maintaining business operations. As information technology becomes increasingly integrated with all aspects of our society, there is increased risk for wide scale or high-consequence events that could cause harm or disrupt services upon which our economy and the daily lives of millions of Americans depend. In light of the risk and potential consequences of cyber events, CISA strengthens the security and resilience of cyberspace, an important homeland security mission. CISA offers a range of cybersecurity services and resources focused on operational resilience, cybersecurity practices, organizational management of external dependencies, and other key elements of a robust and resilient cyber framework. CISA helps individuals and organizations communicate current cyber trends and attacks, manage cyber risks, strengthen defenses, and implement preventative measures. Every mitigated risk or prevented attack strengthens the cybersecurity of the nation. It's time to build cybersecurity into the design and manufacture of technology products. Explore the cybersecurity services CISA offers that are available to Federal Government; State, Local, Tribal and Territorial Government; Industry; Educational Institutions; and General Public stakeholders. The exercise series brings together the public and private sectors to simulate discovery of and response to a significant cyber incident impacting the Nations critical infrastructure. This course is ideal for those working in cybersecurity roles who are interested in learning technical incident response skills and requires active engagement from all participants. Discover the latest CISA news on Cybersecurity Best Practices. Use CISA's resources to gain important cybersecurity best practices knowledge and skills. Everyone has the power to stop a threat and help secure the nation. Read about how, by just reporting suspicious activity or strange behavior, you play an essential role in keeping our communities safe and secure. CISA offers a range of cybersecurity assessments that evaluate operational resilience, cybersecurity practices, organizational management of external dependencies, and other key elements of a robust and resilient cyber framework. Together, CISA brings technical expertise as the nations cyber defense agency, HHS offers extensive expertise in healthcare and public health, and the HSCC Cybersecurity Working Group offers the practical expertise of industry experts. Need CISA's help but don't know where to start? Organizations can also report anomalous cyber activity andor cyber incidents 247 to Contactmail.cisa.dhs.gov or by calling 1-844-Say-CISA (1-844-729-2472)",489
https://nordlayer.com/learn/network-security/basics/,Network Security 101: Understanding the Basics,"Every week, networks seem to grow in size and complexity. New SaaS services come online, while innovative communication tools make remote working easier. Data storage methods shift, with new assets to secure. And new malware threats constantly emerge. In an ever-changing digital world, network security has never been more crucial. Network security is not a fixed constant. Methods to protect networks change all the time. In this glossary article, we will explain network security basics. We will introduce the CIA concept, and we will also look at contemporary security techniques. This article overviews the topic, but you can fine-tune your knowledge with detailed texts about related concepts. Networks are collections of devices and applications. When linked together, these assets serve core business functions. Network managers can place devices on different network segments, while they may also be geographically distant. But they are all part of the same workstations, servers, switches, and SaaS gateways community . Networks come in a variety of types. Security measures required vary depending on network configurations. Common variants include: Networks operate at level 3 of the OSI model . The network layer is where data is transmitted. Servers create packets of information, which they send to network devices via routing devices. Packets are then rendered readable at the other end. Numerical IP addresses usually identify network devices. But more advanced network architecture uses text labels for the same purpose. Systems may also apply encryption to data passing over the network. Encryption conceals the contents of packets, protecting them against external observers. Network devices are any items of hardware connected to the network architecture. Every network should be documented and mapped. Mapping enables managers to understand which devices require protection. Company networks generally rely on several device types: Monitoring tools track traffic and user behavior inside the network perimeter. It also checks the status of network devices such as servers or switches and informs network managers when faults occur. Monitoring can be reactive or proactive. Proactive monitoring is preferable, anticipating problems and seeking threats before they cause damage. Monitoring can also be agent-based or agentless: This form of monitoring installs software agents on every network client . Agents connect to centralized monitoring software. They provide a stream of data about the status of the device. This data could include memory usage and processes running on the device. Agents may track user connections or assess general performance. Agent-based monitoring delivers granular information and enhances network visibility . However, the proliferation of agents poses problems. Security teams must set aside time to update and log agents. Managing large communities of agents can be difficult for smaller organizations. This type of monitoring focuses on data passing across external and internal network connections . It involves packet inspection to discover information about data and network usage. And it can also involve app monitoring to ensure only authenticated users have access. Agentless monitoring is non-intrusive and requires few resources. It provides a data stream that can be used to improve security setups. But this information is generally not granular. Network managers may lack complete awareness of threats. Monitoring is not always constant. Instead, security managers schedule inspections of digital assets to assess functionality and security status. The gap between security inspections is the monitoring interval. Intervals vary depending on device type and situation. Technicians schedule constant inspections of the internal network. However, general network performance measurements may have longer monitoring intervals. This reduces the load placed on the network. Network security is the process of protecting networks against potential threats . It includes software and hardware designed to detect and block malicious agents. Securing networks also extends to access control, network organization, and security policies. Networking security is closely related to cybersecurity and information security . Cybersecurity guards against digital threats. InfoSec focuses on data protection. Both feed into protecting a single computer connected to the network infrastructure against outside threats. Network security matters because data and apps need protection . Businesses depend on reliable access to workloads and databases. However, they must secure confidential data from external observers via information security techniques. A well-thought-out security strategy balances access and protection while also meeting compliance goals. There are several networking security policy ingredients. Common approaches include: Levels of control make securing networks easier to understand. There are three control levels. Companies should factor them all into their security strategies: Physical controls Technical controls Administrative controls Secure physical devices with multiple credentials for access Safeguard data flow within the computer network Manage user behavior through Identity and Access Management systems Locks and access controls protect servers and data storage devices Protect data on network devices, including servers and workstations Define user privileges with security policies Enhance security with cameras and biometric scanners Cover both locally connected and remote working devices Onboard new employees and remove obsolete accounts to prevent credential theft Ensure security without compromising network performance Provide staff training to address security challenges The CIA model is the most popular way of visualizing security methods for modern networks. This model is the basis for defense-in-depth, which means defending connected assets across all network layers. CIA refers to the initials of the models core principles. These ideas include: Network managers must enforce all three CIA principles across the entire network. In practice, this means using several of the networking security approaches mentioned above. For example, traffic monitoring identifies which users access specific apps at a given moment. But it also means employing the right tools to achieve the CIA triad model. The exact mixture of tools varies, but popular security options include: A load balancer uses algorithms to determine traffic flows across the network. Traffic balancing helps to avoid bottlenecks but also has cybersecurity benefits. For example, load balancers can divert traffic when a service attack (or DDoS ) occurs. A sandbox operates alongside IPS tools to block aggressive malware actively. Sandboxes create emulated environments. These environments assess network traffic and can identify attack techniques like port scanning that other scanners often miss. Network Traffic Analysis tools use AI to analyze network traffic. They compare real-time traffic to secure baselines. Baseline comparison allows traffic analysis tools to detect anomalies and report attacks before they cause harm. Robust networking security is the key to preventing data breaches and ransomware attacks. Follow the CIA model to create a comprehensive security strategy. Take into account physical, administrative, and technical controls. And choose agent or agentless monitoring to ensure total awareness.",1074
https://www.fortinet.com/resources/cyberglossary/what-is-network-security,What Is Network Security? Definition and Types | Fortinet,"Discover the types of network security and how it can help secure your networks. Network security refers to the technologies, policies, people, and procedures that defend any communication infrastructure from cyberattacks, unauthorized access, and data loss, while upholding the principles of the CIA triad .In addition to the network itself, they also secure traffic and network-accessible assets at both the network edge and inside the perimeter. Digital acceleration paved the way for business efficiencies, cost reductions, and productivity improvements. Yet, it has also led to an expanded attack surface across the growing network edge. From local area networks (LAN) and wide area networks (WAN) to the Internet of Things (IoT) and cloud computing, each new deployment results in another potential vulnerability. Worse yet, increasingly sophisticated cybercriminals are exploiting network vulnerabilities at an alarming rate. Malware , ransomware, distributed denial-of-service (DDoS) attacks, and countless other threats are challenging IT teams to fortify their defenses. In turn, enterprises have much to gain by strengthening their network protections: Hardware plays a vital role in securing the infrastructure. Three devices, in particular, are relevant to network security: Network Security Solutions To Stay Ahead of Cyberthreats Discover key network security components to achieve secure digital acceleration. 1. Firewalls A firewall is a device that monitors, filters, and controls incoming and outgoing network traffic based on predefined security rules. Acting as a barrier between trusted internal and untrusted external networks, it works by inspecting data packets and choosing to block or allow them. For example, a financial institution might configure its firewall to block traffic coming from unauthorized IP addresses while still allowing legitimate traffic to pass through. This mitigates a potential breach without interrupting core operations. Next-Generation Firewall (NGFW) is a modern iteration that goes beyond traditional solutions, incorporating deeper packet inspection for more robust protection. NGFWs often package many essential network security capabilities into one comprehensive offering, including intrusion prevention, antivirus and file sandboxing, web and DNS filtering, and more. With a hybrid mesh architecture  firewalls next evolution  organizations can centralize control and visibility of formerly disparate tools. This makes it easier to coordinate and control policies across on-premise and cloud-based firewalls, not to mention multiple branches and campus locations. 2. Intrusion Prevention Systems (IPS) Intrusion prevention systems detect and block known and suspected threats before they can impact the network core or devices at its edge. In addition to northsouth and eastwest deep packet inspection, including inspection of encrypted traffic, they can also provide virtual patching, which mitigates vulnerabilities at the network level. Using an IPS, organizations can rapidly detect attack signatures and abnormal behavior. The system automatically takes action to block malicious traffic while alerting administrators for further investigation. 3. Antivirus and sandboxing Antivirus and sandboxing tools are key to determining whether a file is malicious. While antivirus blocks known malware threats, sandboxing provides a safe environment to analyze suspicious files. Lets say a user downloads a file from an email attachment. The antivirus software scans it for known attack signatures and behaviors. If its a confirmed threat, the software quarantines or removes the file. For an unknown file, sandboxing isolates it into a protected space where it can be tested to determine if its malicious. Some security vendors are leveraging these capabilities in concert with AI, allowing them to perform sub-second analysis of never-before-seen threats. 4. Web and DNS filtering Domain Name System (DNS) filtering allows organizations to stop domain-based attacks, such as DNS hijacking, tunneling, etc. Likewise, URL filtering prevents users and applications from accessing suspicious URLs, which could be linked to malicious websites. These web security tools help enterprises enforce acceptable-use policies while protecting them from harmful content. For instance, if a user attempts to access a malicious website, the web filter checks its database of categorized sites. If the domain has been flagged, itll block access entirely. 5. Attack surface management Some firewall solutions now include Cyber Asset Attack Surface Management tools that can help organizations automatically identify network IT, OT, and IoT assets, and assess those assets for potential risks. The tools can also assess existing security infrastructure and controls for misconfigurations and less-than-optimal settings that can then be updated to strengthen an organizations security posture. 6. Remote access VPNs Remote access VPNs allow users to securely access the corporate network from outside their organizations office. They create a private, encrypted connection from a public Wi-Fi network, enabling employees to safely use critical resources from their personal devices regardless of location. These solutions are especially useful in hybrid work environments, allowing remote workers to stay productive with the assurance their data is safe from malicious interception. 7. Network Access Control (NAC) Network access control governs access to the network, ensuring that only authorized and compliant devices gain entry. NAC solutions identify and authenticate devices, granting access only if they meet predefined compliance policies. For example, enterprises might configure their NAC to block certain device types. This prevents users from accessing the network on unprotected personal devices, but it also can help the company manage IoT and operational technology (OT) deployments. Hardware that fails to meet the criteria may be quarantined, redirected to a remediation network, or denied entirely. Although not directly supporting the network, there are related cybersecurity technologies that help protect the infrastructure: Application programming interfaces (APIs) allow open-architecture CASBs to directly integrate with SaaS providers. This enables admins to scan cloud configurations, ensuring their users are monitored and protected no matter what device theyre using. Here are the five key benefits of network security. Network security protects sensitive data, such as personal data, intellectual property, customer details, financial records, and more, from cyber threats like malware, ransomware, and phishing. Robust network security minimizes downtime and ensures the business remains operational and resilient against cyberattacks. Effective network security ensures that organizations remain compliant with regulatory frameworks like the General Data Protection Regulation (GDPR) and the Payment Card Industry Data Security Standard (PCI DSS). This reduces the risk of legal fines and penalties. Network security strengthens access control and authentication, ensuring only authorized employees can access sensitive data and minimizing the risk of insider threats. Commitment to protecting sensitive organizational and client data can enhance a businesss reputation and build trust with partners. The top challenges in network security are: The rise in new technology and platforms has expanded the attack surface, providing hackers with multiple points to access an organizations network. In the context of cyber warfare , these expanded vulnerabilities can be exploited by nation-state actors to target critical infrastructure and disrupt essential services. While bring-your-own-device (BYOD) policies and remote work have blurred traditional location and network boundaries, they have also introduced new vulnerabilities. For instance, employees devices may lack robust network security controls, which can expose data over unsecured networks. The complexity of modern networks, especially with the growing use of cloud environments, and human errors can result in misconfigurations, leading to security gaps and cyber attacks. Uncontrolled admin access can increase the risk of insider threats and data breaches. Therefore, organizations must monitor user activity and manage privileged access to prevent misuse. Network security in inherently more complex in larger, more complicated IT environments. Fortunately, there are several solutions fit for network protection at scale: Modern security operations centers (SOC) require a centralized approach to event management. Without it, they lack the context or visibility to protect the organization effectively. SIEM solutions provide a unified view of security across the enterprise, collecting information from network, endpoint, cloud, and other security products. They also offer behavior-based AI-powered threat detection, investigation, compliance reporting, and more. In short, SIEM reduces the complexity of managing network and security operations. NDR monitors internal network traffic, baselining normal behaviors and using machine learning (ML) and other analytics to detect malware, malicious traffic, and abnormal patterns that may indicate an attacker within the network. It also provides a robust capability to investigate and take immediate action on verified alerts. XDR streamlines threat detection and response across an enterprise's security ecosystem. By consolidating data from endpoints, networks, emails, and the cloud, it identifies and links suspicious activities that individual tools might miss. This integrated approach enables quick investigation and remediation of alerts or multi-step incidents through automated and manual actions. Leveraging endpoint detection and response (EDR) capabilities, XDR provides endpoint agents, telemetry, and endpoint blocking to effectively manage challenges while enhancing threat detection and response capabilities. The progression from endpoint detection and response ( EDR ) to managed detection and response (MDR) to extended detection and response (XDR) follows the path of digital acceleration with ever-expanding attack surfaces and a hybrid workforce. Essentially, the difference between EDR, MDR, and XDR are as follows: Today, network edges are anywhere the user connects and businesses may not be able to extend security everywhere its needed. Managed security service providers (MSSPs) can help fill the gap with the critical expertise and infrastructure required immediately, at less cost. For example, a managed detection and response (MDR) service can be a great choice for SMBs that need enterprise-grade threat monitoring and response but find it too expensive to build or staff internally. Larger organizations who need more comprehensive protection of a distributed environment and dont have the resources in house, can choose an XDR service for cross-layered detection and response. XDR collects, normalizes, and then correlates data over a variety of security layers, including endpoints, firewalls, email, servers, cloud workloads, and the general network. MDR is a fully managed threat detection and response service delivered by an outsourced MSSP. With MDR services, security teams can enhance their ability to rapidly detect, investigate, and respond to unauthorized andor suspicious activity. Some MDR services also offer threat hunting and recommendations for improving overall security posture. Some MSSPs also extend MDR with XDR which monitors, detects and analyzes security signals across endpoints, network, cloud, SIEM and email security systems. XDR is a new, alternative approach to traditional detection and incident response , integrating detection and response procedures across multiple environments to reduce the mean time to detect and repair attacks. XDR is a natural extension of EDR suitable for organizations that have complex IT environments or are highly vulnerable to cyberattacks. XDR is highly scalable, supports multiple data sources, and ensures end-to-end protection of an organizations attack surfaces. A typical in-house security operations center (SOC) requires a dedicated staff of security engineers and analysts and the tools to support their work. The high cost of running a SOC in house compounded by the shortage of cybersecurity talent and the burnout that often transpires, leads many organizations to choose a managed SOC-as-a-Service (SOCaaS). This allows them to outsource threat hunting, monitoring, detection, and remediation to an MDR or MXDR service provider with the cybersecurity experience, infrastructure, and tools, to actively monitor customers threat surfaces 247. Cloud security is a shared responsibility. In general, the public cloud infrastructure is secured by the service providersuch as AWS, Azure, or GCPand the workloads running on the infrastructure are secured by the customer. To meet the business imperative of cloud migration, organizations need a network security solution in the cloud that offers advanced protection, flexibility, and predictable costs. However, organizations that are accelerating their cloud adoption may not have the resources, skills , or time to build, scale, or adapt their cloud security to meet the pace of their business. A managed firewall service allows organizations to offload cloud security infrastructure maintenance, get deep visibility, apply robust controls, and optimize cloud security spend. A cloud-native, managed firewall service removes the heavy lifting around network security operations and provides a frictionless experience to help customers easily deploy enterprise-grade security on the public cloud. Cloud migration requires organizations to secure key cloud services. A next-generation, managed firewall service or network Firewall-as-a-Service (FWaaS) simplifies security management with full visibility across environments and broad protection across cloud workloads and applications. Whether a managed firewall service or a network FWaaS, it is critical that organizations ensure that their public cloud workloads are protected by next-generation security solutions powered by comprehensive threat intelligence. With bad actors increasingly using Generative Pre-trained Transformers (GPT) and other AI technologies to create new, more compelling exploits and threats faster than ever, security teams must also leverage AI technologies to fight fire with fire. AI-powered threat intelligence is arguably the most important use case, as it can help organizations remain in lockstep with emerging threats. Thats why cybersecurity vendors, including Fortinet, are escalating their AI capabilities. To stay ahead of the curve, IT leaders should ask their providers how theyre applying AI, what technologies their AI tools use, and most importantly, how their applications contribute to one or more of the benefits below: Cloud workload security signifies the security of data, applications, and all the infrastructure in cloud environments. It is a leading trend in next-gen network security because of the increasing usage of cloud applications. Organizations are transitioning to the cloud and prioritizing visibility, risk mitigation, and integration with DevOps to ensure secure distributed workloads across containers, virtual machines, and serverless environments. Cloud workload security helps them achieve the goal by providing real-time threat detection and continuous network security without impacting performance. Mobile devices have become a vital part of everyday work, and therefore, organizations are focusing on security trends like building mobile security policies. The goal is to create a secure work environment, even when employees access data through mobile devices. Organizations are offering employee training and leveraging mobile device management tools to monitor and secure devices. Moreover, they are creating and teaching employees the best practices for protecting sensitive data and reducing risks associated with mobile device use. Hybrid IT network environments include multiple threat surfaces by combining on-premises equipment at corporate sites, cloud environments, and remote access by work-from-anywhere usersall of which add complexity to network security management. To solve this problem, a hybrid mesh firewall addresses network security with a unified security platform that provides coordinated protection across multiple areas of enterprise IT, to secure corporate sites such as branches, campuses, and data centers; public and private clouds; and remote access points. To do this, hybrid mesh firewalls come in various form factors, including appliances, virtual machines, cloud-native firewalls, and Firewall-as-a-Service (FWaaS). SD-WAN provides secure, reliable connectivity between branch and remote locations. Secure SD-WAN extends that protection to cloud-first, security-sensitive, global enterprises, and their hybrid workforces. Using one operating system, Secure SD-WAN consolidates functions across SD-WAN, next-generation firewall (NGFW), advanced routing, and ZTNA application gateway to simplify management and secure networking while enabling organizations to implement a robust SD-WAN security architecture for comprehensive protection. Secure SD-WAN is the foundation for a seamless transition to SASE and SD-Branch. It enables organizations to protect their investment and simplify operations along their journey to a Zero Trust Architecture . A Secure Access Service Edge (SASE) architecture converges networking and several cloud-delivered Secure Service Edge solutions to protect distributed networks with advanced cybersecurity at every endpointedge. SD-WAN is the networking component and FWaaS, SWG , CASB, and ZTNA comprise the edge security of SASE. The advantage of a SASE architecture is that it provides users with secure connections without the latency that results from backlogging traffic all the way to the central data center. A Unified SASE solution seamlessly integrates essential networking and security technologies delivered via the cloud. It ensures secure access for hybrid workers and safeguards applications and data on any cloud. A single operating system unifies the SASE components enabling seamless and complete convergence of networking and security. Unifed SASE secures access to the internet, corporate resources, and SaaS applications no matter the users or resources locations. According to the National Institute of Standards and Technology (NIST), a zero trust architecture (ZTA) uses zero trust principles to plan industrial and enterprise infrastructure and workflows. Zero trust assumes there is no implicit trust granted to assets or user accounts based solely on their physical or network location (i.e., local area networks versus the internet) or based on asset ownership (enterprise or personally owned). Authentication and authorization (of both subject and device) are discrete functions performed before a session to an enterprise resource is established. Zero trust is a response to enterprise network trends that include remote users, bring your own device (BYOD) , IoT, and cloud-based assets that are not located within an enterprise-owned network boundary. Zero trust focuses on protecting resources (assets, services, workflows, network accounts, etc.), not network segments, as the network location is no longer seen as the prime component to the security posture of the resource. ZTNA is a capability that controls access to applications. It extends the principles of ZTA to verify users and devices before every application session. ZTNA confirms that they meet the organizations policy before they can access that application. However, ZTNA may work differently, depending on where a user is located, meaning that access to applications or networks may work from one location but fail from another. In contrast, Universal ZTNA enables secure connections regardless of the location of the network or user. Users can work from anywhere, and administrators can apply zero-trust principles without having to worry about the quality of network connections. Universal ZTNA improves security and connectivity regardless of where users are locatedon-premise or remote, or the type of network architecture. Stay ahead with AI-powered, next-gen network security solutions designed to detect, prevent, and mitigate cyber threats in real-time. Fortify Your Network with Fortinet Today . Here are the top eight best practices for network security Regular security audits help organizations identify and detect vulnerabilities before they escalate, keeping network infrastructure secure. Dividing the network into small, multiple segments enables granular control over data flow and access. This reduces the attack surface and contains potential damage within isolated segments. Implementing MFA, which adds an extra verification step before granting access, combined with strong passwords, can reduce unauthorized access and strengthen network security. VPNs encrypt traffic between remote users and the network, establishing secure connections and safeguarding sensitive data over the internet. The zero-trust security framework works on the principle of never trust, always verify, assuming no device is secure. It verifies each device in the network before granting access, thus minimizing the chances of breaches. A least privilege access policy limits users access and provides only the minimum level of access required to perform a job. This minimizes the attack surface, safeguarding sensitive data. Implement strong encryption protocols and strict authentication policies, and continuously monitor the wireless network. According to the Fortinet 2023 Cloud Security Report , 43 of companies state that talent shortage is their biggest challenge in securing cloud workloads. So, its crucial to educate the employees about what is network security, how to identify cyberattacks like phishing and social engineering, and steps to take after an incident. Network security defines an organizations readiness to combat ever-evolving cyber threats and its seriousness to safeguard the integrity of its data and that of its customers from unauthorized access. The basic password encryption approach is no longer relevant and cannot prevent threats. Statista reveals that data breaches are among the top concerns of company leaders. Around 422.61 million data records were compromised in the third quarter of 2024. Such incidents can damage a companys reputation and lead to the loss of customer trust in the long term. Therefore, implementing strong and advanced network security measures and tools is crucial to preventing these breaches and safeguarding sensitive data. Fortinets FortiGate Next-Generation Firewall (NGFW) provides AI-driven threat intelligence for proactive defense and protection against cyber attacks. Its purpose-built ASICs, called Security Processing Units (SPUs), ensure fast-speed security processing, making FortiGate a trustworthy and reliable solution for modern network security needs. Connect with Fortinets team for more details. Vulnerabilities in your network security give hackers an opening to do untold damage to your network while exposing potentially sensitive and confidential information. Network security protection has been developed to implement measures to protect your computer network's data from being lost, stolen, or manipulated. A computer network provides communication and enables the sharing of information to multiple users within a network. Network security technologies work within several layers to protect your network as a whole against any potential threats. Some of the common network security threats include phishing scams, malicious software (malware), and Distributed Denial of Service (DDoS). Cybersecurity is a broader field that covers different security measures and threats, while network security is a specific subset focused on protecting the communication infrastructure and ensuring secure data transmission across networks. Network security policies act as a framework for maintaining a secure network. They guide technical setups and user behavior to ensure the network remains protected from potential threats. Please fill out the form and a knowledgeable representative will get in touch with you soon. By clicking submit you agree to the Fortinet Terms and Conditions  Privacy Policy .",3463
https://www.cisco.com/site/us/en/learn/topics/security/what-is-network-security.html,What Is Network Security? - Cisco,"Network security is the protection of the underlying networking infrastructure from unauthorized access, misuse, or theft. It involves creating a secure infrastructure for devices, applications, users, and applications to work in a secure manner. Network security combines multiple layers of defenses at the edge and in the network. Each network security layer implements policies and controls. Authorized users gain access to network resources, but malicious actors are blocked from carrying out exploits and threats. Digitization has transformed our world. How we live, work, play, and learn have all changed. Every organization that wants to deliver the services that customers and employees demand must protect its network. Network security also helps you protect proprietary information from attack. Ultimately it protects your reputation. A firewall is a network security device that monitors incoming and outgoing network traffic and decides whether to allow or block specific traffic based on a defined set of security rules. Cisco offers both threat-focused firewalls and unified threat management (UTM) devices. Explore Cisco Secure Firewall Workload security protects workloads moving across different cloud and hybrid environments. These distributed workloads have larger attack surfaces, which must be secured without affecting the agility of the business. Explore Cisco Secure Workload NetWORK security is Cisco's vision for simplifying network, workload, and multicloud security by delivering unified security controls to dynamic environments. Explore our NetWORK vision Software-defined segmentation puts network traffic into different classifications and makes enforcing security policies easier. Ideally, the classifications are based on endpoint identity, not mere IP addresses. You can assign access rights based on role, location, and more so that the right level of access is given to the right people and suspicious devices are contained and remediated. Learn about network segmentation A virtual private network encrypts the connection from an endpoint to a network, often over the internet. Typically, a remote-access VPN uses IPsec or Secure Sockets Layer to authenticate the communication between device and network. Explore VPN Not every user should have access to your network. To keep out potential attackers, you need to recognize each user and each device. Then you can enforce your security policies. You can block noncompliant endpoint devices or give them only limited access. This process is network access control (NAC). Cisco Identity Services Engine ""Malware,"" short for ""malicious software,"" includes viruses, worms, Trojans, ransomware, and spyware. Sometimes malware will infect a network but lie dormant for days or even weeks. The best antimalware programs not only scan for malware upon entry, but also continuously track files afterward to find anomalies, remove malware, and fix damage. Learn about Cisco Secure Endpoint Any software you use to run your business needs to be protected, whether your IT staff builds it or whether you buy it. Unfortunately, any application may contain holes, or vulnerabilities, that attackers can use to infiltrate your network. Application security encompasses the hardware, software, and processes you use to close those holes. Full-stack Observability AppDynamics APM Cisco application-first products Security Advisory Services To detect abnormal network behavior, you must know what normal behavior looks like. Behavioral analytics tools automatically discern activities that deviate from the norm. Your security team can then better identify indicators of compromise that pose a potential problem and quickly remediate threats. Cisco Secure Network Analytics Built-in security analytics across Cisco Cloud security is a broad set of technologies, policies, and applications applied to defend online IP, services, applications, and other imperative data. It helps you better manage your security by shielding users against threats anywhere they access the internet and securing your data and applications in the cloud. Explore cloud security solutions Organizations must make sure that their staff does not send sensitive information outside the network. Data loss prevention, or DLP, technologies can stop people from uploading, forwarding, or even printing critical information in an unsafe manner. Learn about data loss prevention Email gateways are the number one threat vector for a security breach. Attackers use personal information and social engineering tactics to build sophisticated phishing campaigns to deceive recipients and send them to sites serving up malware. An email security application blocks incoming attacks and controls outbound messages to prevent the loss of sensitive data. As you are digitizing your industrial operations, the deeper integration between IT, cloud, and industrial networks is exposing your Industrial Control Systems (ICS) to cyberthreats. You need full visibility into your OT security posture to segment the industrial network, and feed IT security tools with rich details on OT devices and behaviors. Explore Cisco industrialOT security Learn about Cisco Cyber Vision Cybercriminals are increasingly targeting mobile devices and apps. Within the next three years, 90 percent of IT organizations may support corporate applications on personal mobile devices. Of course, you need to control which devices can access your network. You will also need to configure their connections to keep network traffic private. Learn about Cisco Meraki SIEM products pull together the information that your security staff needs to identify and respond to threats. These products come in various forms, including physical and virtual appliances and server software. Identity Services Engine with SIEM A web security solution will control your staff's web use, block web-based threats, and deny access to malicious websites. It will protect your web gateway on site or in the cloud. ""Web security"" also refers to the steps you take to protect your own website. Cisco Secure Web Appliance Wireless networks are not as secure as wired ones. Without stringent security measures, installing a wireless LAN can be like putting Ethernet ports everywhere, including the parking lot. To prevent an exploit from taking hold, you need products specifically designed to protect a wireless network. Cisco Aironet AP Module for Wireless Security",946
https://www.trendmicro.com/en_us/what-is/network-security/network-security-basics.html,What Are Network Security Basics? | Trend Micro (US),"How to spot data threats in moments, not days Book your live demo  Pwn2Own Ireland: Elite hackers take home top honors for real-world zero-click discoveries Learn more ",27
https://digitdefence.com/blog/fundamentals-of-network-security-in-computer-networks,Fundamentals of Network Security in Computer Networks - Digitdefence,"Fathima Oct 6, 2025 0 128 Fathima Oct 1, 2025 0 88 Fathima Sep 12, 2025 0 153 Fathima Sep 2, 2025 0 166 Fathima Sep 1, 2025 0 176 ajith Oct 30, 2025 0 30 Fathima Oct 29, 2025 0 35 Fathima Oct 27, 2025 0 29 Fathima Oct 25, 2025 0 73 Fathima Oct 24, 2025 0 63 Fathima Oct 23, 2025 0 82 Fathima Oct 17, 2025 0 68 Fathima Sep 25, 2025 0 117 Fathima Sep 22, 2025 0 94 Fathima Sep 18, 2025 0 156 Fathima Oct 28, 2025 0 55 Fathima Oct 22, 2025 0 90 Fathima Oct 21, 2025 0 130 Fathima Oct 16, 2025 0 82 Fathima Oct 15, 2025 0 90 Fathima Oct 31, 2025 0 20 Fathima Oct 10, 2025 0 77 Fathima Sep 24, 2025 0 91 Fathima Sep 10, 2025 0 114 Fathima Sep 4, 2025 0 147 Fathima Oct 2, 2025 0 86 Fathima Sep 30, 2025 0 96 Fathima Mar 25, 2025 0 247 Fathima Mar 23, 2025 0 215 ajith Nov 13, 2024 0 695 Join our subscribers list to get the latest news, updates and special offers directly in your inbox As a professional working in the field of IT and cybersecurity, Ive come to understand that network security is one of the most critical aspects of maintaining a secure digital environment. Every day, businesses, government agencies, and individuals are exposed to a range of cyber threats, from data breaches to malicious attacks that can cripple entire systems. At its core, network security involves protecting both the hardware and software technologies used within a computer network, with the goal of safeguarding data, devices, and systems from unauthorized access and malicious activities. In a world where connectivity is constantly increasing, securing a network has never been more important. The fundamentals of network security include practices like using firewalls to filter traffic, implementing encryption to protect sensitive data, and ensuring that systems are protected by strong intrusion detection systems (IDS). By understanding these foundational principles and keeping them updated, businesses and individuals can greatly reduce the risk of cyberattacks that threaten to compromise their data, reputations, and overall safety in the digital space. Network security refers to the policies, procedures, and technologies used to protect the integrity, confidentiality, and availability of computer networks and their resources. The main goal of network security is to safeguard data, devices, and users from unauthorized access, cyberattacks, data breaches, and other security threats. Protects Sensitive Information: Personal, financial, and business data are at risk of being intercepted, stolen, or altered. Prevents Unauthorized Access: Ensures that only authorized users can access critical network resources and data. Reduces the Risk of Cyberattacks: Safeguards against malware, ransomware, DDoS attacks, and phishing attempts. Regulatory Compliance: Helps businesses comply with data protection laws such as GDPR, HIPAA, and PCI-DSS. Maintains Business Continuity: By defending against network disruptions, security ensures that business operations remain uninterrupted. To understand network security fully, it's essential to explore the core components and concepts that define it: 1. Confidentiality Confidentiality ensures that only authorized individuals can access specific data or information. Sensitive data like customer records, financial transactions, and personal information must be protected from unauthorized access. Methods: Encryption: Converting data into an unreadable format to prevent unauthorized access. Access Controls: Restricting access to sensitive data based on user roles and permissions. 2. Integrity Integrity ensures that data is accurate, reliable, and has not been tampered with during transmission. Any unauthorized alteration of data can compromise the trustworthiness of the information. Methods: Hashing: Creating a unique representation of data to detect any changes. Digital Signatures: Used to verify the authenticity of data and ensure it has not been altered. 3. Availability Availability ensures that network resources, data, and services are accessible and functional when needed. A denial of service or an attack that causes downtime can lead to severe disruptions. Methods: Redundancy: Having backup systems in place to maintain service during outages. Load Balancing: Distributing traffic across multiple servers to ensure availability during high demand. Malware: Malicious software designed to damage, disrupt, or gain unauthorized access to systems. This includes viruses, worms, ransomware, and trojans. Phishing: Fraudulent attempts to obtain sensitive information through deceptive emails, messages, or websites. Denial of Service (DoS) Attacks: Attacks aimed at making a network service unavailable to users by overwhelming it with traffic. Man-in-the-Middle (MitM) Attacks: Where attackers intercept and potentially alter the communication between two parties without their knowledge. SQL Injection: A form of attack where malicious SQL queries are inserted into an input field to manipulate the database. Insider Threats: Security risks posed by individuals within the organization who have authorized access but misuse it. To protect computer networks, several technologies, protocols, and practices are employed. Lets explore the most common and important components: 1. Firewalls A firewall is a security system that monitors and controls incoming and outgoing network traffic based on predetermined security rules. It acts as a barrier between trusted internal networks and untrusted external networks (such as the internet). Types: Packet Filtering Firewalls: Basic form of firewall that inspects packets and allows or blocks them based on predefined rules. Stateful Firewalls: Track the state of active connections and make decisions based on context. Next-Generation Firewalls (NGFW): Advanced firewalls that combine traditional firewall functionality with additional features like application awareness and intrusion prevention. 2. Intrusion Detection and Prevention Systems (IDPS) IDPS are designed to detect and respond to potential network security threats. An Intrusion Detection System (IDS) monitors network traffic for suspicious activity, while an Intrusion Prevention System (IPS) actively blocks detected threats. Key Features: Real-time monitoring Alerting system for suspicious activities Response mechanisms to block or mitigate attacks 3. Virtual Private Networks (VPNs) A VPN is a secure network connection that allows users to send and receive data over public networks (like the internet) as if they were on a private network. It encrypts data, ensuring confidentiality and protection against eavesdropping. Use Cases: Remote access for employees working from different locations. Secure communication over unsecured networks, such as public Wi-Fi. 4. Network Access Control (NAC) NAC solutions ensure that only authorized devices can connect to the network. It enforces security policies by checking the health of a device before granting access to the network. Methods: Device authentication Endpoint security checks (e.g., antivirus status, software updates) 5. Encryption Encryption is a fundamental aspect of network security. It involves encoding data in such a way that only authorized parties can read it. Encryption protects data in transit and at rest, ensuring confidentiality. Common Encryption Methods: SSLTLS: Protocols used to secure communications over the internet. AES (Advanced Encryption Standard): A widely used encryption algorithm for data protection. RSA Encryption: A public-key encryption method used for secure data transmission. Regular Software Updates: Ensure that all software, including operating systems, firewalls, and applications, are up to date with the latest security patches to prevent exploitation of known vulnerabilities. Strong Authentication mechanisms: Use multi-factor authentication (MFA) wherever possible to ensure that only authorized users can access sensitive systems. Data Backups: Regularly back up important data and configurations to minimize the impact of cyberattacks like ransomware or hardware failures. Network Segmentation: Divide the network into smaller, isolated segments to limit the spread of potential breaches. Employee Training: Educate employees on common cybersecurity threats such as phishing and social engineering. Human error is often the weakest link in cybersecurity. Case Study 1: Sony  2014 Sony Pictures Cyberattack Overview: Sony Pictures Entertainment, a subsidiary of Sony, is one of the largest entertainment companies globally. Challenge: In November 2014, Sony Pictures was hit by a massive cyberattack , attributed to the North Korean hacking group Guardians of Peace (GOP). The attack resulted in the theft of sensitive data, including emails, intellectual property , and unreleased movies , leading to severe operational disruption and reputational damage. How It Worked: Spear-phishing emails with malware were sent to employees. The malware gave attackers remote access to Sony's network. They exfiltrated data and deployed wiper malware that destroyed internal files and systems. Outcome: Massive Data Breach: Confidential emails and unreleased films were leaked, causing financial and reputational damage. Increased Security: Sony invested in stronger intrusion detection systems (IDS), firewalls, and employee training to prevent phishing. Legal Fallout: The company faced lawsuits and had to rebuild its public image. Case Study 2: Microsoft  2020 Exchange Server Hack Overview: Microsoft is a global technology leader, providing services like Microsoft Exchange, widely used for email management. Challenge: In March 2021, a cyberattack exploited zero-day vulnerabilities in Microsoft Exchange Server. The Hafnium hacking group gained unauthorized access to email accounts and deployed malware. How It Worked: Attackers exploited four zero-day vulnerabilities to access email accounts. They used web shells for persistent access to affected servers. Stolen data included emails, contacts, and attachments. Outcome: Global Impact: The attack affected thousands of organizations worldwide, including businesses and government agencies. Quick Response: Microsoft released security patches and advised customers to change passwords and secure networks. Increased Focus on Security: Microsoft emphasized patch management and the importance of timely updates. Network security is the backbone of any organizations cybersecurity strategy. By understanding the fundamentals of network security, implementing essential security measures, and staying vigilant against evolving threats, businesses and individuals can protect their critical data and ensure operational continuity. ajith Apr 26, 2024 0 3592 Fathima Apr 19, 2025 0 366 Fathima Oct 16, 2024 0 1472 Fathima Apr 17, 2024 0 10864 Fathima Sep 18, 2024 0 4296 ajith Apr 18, 2024 0 3593 ",1583
https://guardiandigital.com/resources/blog/guide-on-phishing,Phishing Threats Explained: Detection and Prevention Strategies.,"Phishing attacks have shifted; its no longer about volume, its about precision. These sites may look harmless, but the emails delivering them still rely on a familiar formula. Urgent language. Faked sender details. Links like these are designed to pass through security filters, and many do. Thats why protection against phishing attacks in 2025 takes more than awareness training. Spotting red flags helps, but its not enough. You need to understand how phishing works now, how the tactics have changed, and why traditional defenses often miss them. Email is still the most straightforward way in. These attacks can lead to wire fraud, credential theft, malware infections, or full-scale business email compromise. In this guide, well break down how phishing attacks in emails work, the most common types targeting businesses, and the steps you can take to protect your users and your data. Subscribe to our Behind the Shield Newsletter. Phishing attacks now account for over 22 of all cybercrime. In 2025, they're not just common, they're constant. The FBI received 193,407 phishing-related complaints last year alone. Its important to demystify phishing attacks to better understand how they work. Phishing emails impersonate people you trust  vendors, coworkers, even your own boss  to get you to act before thinking. Maybe hand over a password, open a file you werent expecting, or send money to the wrong place. Most phishing campaigns are after sensitive information: financial details, login credentials, and company data. Some attackers still send generic spam to thousands of people, but more are shifting to targeted emails that feel personal and credible. Todays phishing attacks often use social engineering, and in many cases, AI. Messages are timed well, written clearly, and crafted to sound familiar. They dont feel like scams. They feel like routine communication. Thats the trap. It works because its cheap, fast, and hard to trace for attackers; launching a campaign costs next to nothing. For the targets, the damage can be lasting, including stolen data, compromised systems, weeks of downtime, and real reputational harm. Since 1987, phishing attacks have evolved into a set of highly targeted, professional-grade scams built to steal valuable data. Some of the most pervasive modern types of phishing attacks include: Want to know how to stop phishing attacks in emails before they reach your users? It starts with sharpening awareness and reinforcing habits that recognize the signs before theyre too late. Spotting phishing is less about following a checklist and more about noticing when something doesnt sit right. Familiar habits, slowing down, reading carefully, and checking sources, are your first line of defense. The image below is a spear phishing email identified and quarantined by Guardian Digital EnGarde Cloud Email Security. It closely mimics a legitimate FedEx shipment confirmation email. Can you spot the phish? Some indications that this is a fraudulent email include the following: There is more than one way to protect yourself from phishing attacks. You need to be aware of your users and have a security stack that checks all the points. This includes scanning links and attachments in real time, catching attempts to impersonate others, checking senders (yes, SPF and DMARC are still important), and keeping up with new threats as they appear. To prevent phishing attacks and scams in 2025, businesses need to combine training that you can do with tools that can change as threats do. Think about more than just surface screens. Think about finding malware, protecting against spoofing, and scanning that happens in real time. And your defenses need to stay just as smart as phishing techniques get smarter, especially since AI can now make fake websites and messages that look and feel real. Sender behavior, message structure, and embedded link or attachment content are just a few of the indications that advanced phishing protection technologies look for. Heuristic scanning, sandbox analysis, URL reputation checks, and artificial intelligence are some of the methods they utilize to identify dangers that are typically missed by standard filters. These phishing protection tools work by analyzing multiple signals  not just content, but behavior, link structure, domain reputation, and spoofing indicators in real time. Disconnect from the network, run a security scan, and alert your IT or security team immediately. Phishing attacks are so effective because they target the person, not the system. And while awareness is essential, protection against phishing attacks has to account for the moments when someone still clicks. Some phishing attacks in your inbox will still get through. A convincing message, a fake login page, a well-timed request. Thats all it takes. You need defenses built around the user. Real protection uses multiple controls working together. Not just one filter. Not just a warning banner. A strong email security platform can spot and block these threats as they happen. The good ones dont wait for a signature update. They learn, adapt, and react in real time. Prevention starts with seeing phishing attacks as a part of a system, not just a message. It is crucial to prioritize team email security training ; strengthen your filters, and assume some attacks will get through. Engaging in email security best practices is important, but this alone will not prevent a successful phishing attack, says Guardian Digital CEO Dave Wreski. A fully integrated email security solution that delivers total end-to-end control is critical to safeguard business email accounts. The right system doesnt just block spam. It catches the sophisticated threats. The quiet attacks. The zero-day lures. And it keeps evolving as the threats do. Get the Guide Join Our Community of Readers! Are Your Current Email Defenses Falling Behind? Ineffective Built-In Protection. Learn how to close the gaps. Subscribe to our Behind the Shield Newsletter ",945
https://cofense.com/blog,Phishing Prevention & Email Security Blog | Cofense,Request a Demo,3
https://www.phriendlyphishing.com/blog,Phishing Prevention & Security Blog - Phriendly Phishing,Stay up to date on the latest Phriendly Phishing  industry news. Phriendly Phishing Copyright  2025 Privacy Policy  Terms and Conditions,20
https://inspiredelearning.com/blog/phishing-protection-checklist/,Phishing Protection Checklist - Preventing Phishing,"Blog by David Bloxberg , Senior Global Marketing Manager, VIPRE Security Group Phishing, pronounced like fishing, is a method cybercriminals use to steal personal information. Its a widespread form of identity theft that can be difficult to detect. Scammers often disguise their attempts as legitimate emails or websites, tricking individuals into sharing sensitive details. These include credit card numbers, Social Security numbers, login credentials, passwords, and phone numbers. To protect yourself, its crucial to approach unexpected emails and suspicious links cautiously and know how to respond if you accidentally engage in a phishing attempt . Phishing attacks have become more sophisticated, making them one of the most effective tools for cybercriminals. Todays phishing emails are often from trusted sources, like your bank or a well-known company. They can include professional logos, convincing email addresses, and even advanced HTML designs. This high level of professionalism can easily fool people into clicking on links that lead to fraudulent websites, where scammers steal sensitive information like passwords or credit card numbers. One of the reasons phishing is so successful is that cybercriminals have evolved their tactics. In 2024, phishing attacks have expanded to target email users, mobile devices, and other communication platforms. According to recent reports : Scammers also use advanced technologies, including AI, to craft highly personalized and convincing phishing messages. AI-generated phishing attempts can be difficult to spot because they mimic human language and behavior so well. This technological shift makes it more challenging than ever for individuals and organizations to detect and prevent attacks. In 2023, nearly 50 of professionals encountered Business Email Compromise (BEC) attacks, with 35 of all cyberattacks resulting from BEC phishing . These sophisticated attacks aim to steal login credentials or financial information and have resulted in substantial financial losses: In 2024, phishing attacks have also become more diverse. Deceptive links remain the top strategy, accounting for 36 of phishing attempts, but attackers are now using multiple channels, including mobile apps and social media. Notably, the use of AI in phishing has created convincing fake login pages and emails that are nearly impossible to distinguish from the real thing. The sheer volume and sophistication of phishing attacks make it a serious threat to businesses and individuals alike. As attackers continue to innovate with new tools and tactics, vigilance and updated cybersecurity practices are critical to staying ahead of these ever-evolving threats. Understanding different phishing attacks can help businesses protect sensitive information and save money. You can gain peace of mind by guarding against cybercrimes and implementing phishing protection. Its especially valuable for business ownersallowing you to focus time, energy, and resources on growing your company instead of dealing with security breaches. Email remains a standard vehicle for phishing attacks . Cybercriminals send mass emails, hoping even a few recipients will fall for their scams. With 30 of phishing emails being opened, the scale can be staggering if emails are sent to thousands or millions of users. Spear phishing is a form of targeted phishing that involves detailed research. Scammers gather information about a specific persons contacts and customize a phishing email to make it appear as though its from a trusted colleague, friend, or family member. This personalization increases the likelihood of the victim sharing personally identifyable information or clicking on malicious links. Social media phishing occurs when scammers create fake profiles that mimic a users real friends. The attacker might send a new friend request, making it appear that the individual is starting over with a fresh account. This approach is designed to collect personal information or scam the victims contacts. Smishing involves sending fraudulent messages via SMS or text messaging. These messages often contain malicious links or ask for personal information, pretending to be from legitimate organizations such as banks or service providers. Many users are unaware that phishing attempts can come through text, making this an increasingly common tactic. Vishing uses phone calls to trick victims into revealing personal information or financial details. Scammers often impersonate trusted institutions, like banks or government agencies, using urgency or fear to manipulate their targets. The lack of visual cues over the phone can make it easier for criminals to deceive their victims. Whaling is a targeted phishing attack aimed at high-profile individuals, such as executives or government officials. The emails in whaling attacks are crafted to seem highly relevant and credible, often focusing on business or legal matters. The goal is to trick these high-value targets into transferring funds or disclosing sensitive information. Zishing, a relatively new form of phishing , targets users of video conferencing platforms like Zoom, Microsoft Teams, or Google Meet. In a zishing attack, scammers send fake meeting invitations or links to join a video call. These links often mimic legitimate meeting platforms, tricking victims into entering their login credentials or downloading malware. Given the widespread adoption of virtual meetings, this method has become increasingly popular, as many users are less vigilant about verifying meeting invitations, especially during a busy workday. Falling for a zishing scam can lead to compromised accounts and leaked sensitive information shared in virtual meetings. Let the experts at Inspired eLearning help safeguard your organization with comprehensive security awareness training . Our tailored phishing awareness programs empower your employees to recognize and respond to phishing threats effectively, reducing the risk of cyberattacks. By equipping your team with the knowledge and tools to identify suspicious emails, links, and other phishing tactics, we help keep your business secure, your data protected, and your reputation intact. Stay one step ahead of cybercriminalspartner with Inspired eLearning for a safer, more resilient organization. Talk to an Inspired eLearning representative  get a free trial.",940
https://en.wikipedia.org/wiki/SD-WAN,SD-WAN - Wikipedia,"A Software-Defined Wide Area Network ( SD-WAN ) is a wide area network that uses software-defined networking technology, such as communicating over the Internet using overlay tunnels which are encrypted when destined for internal organization locations.  1  If standard tunnel setup and configuration messages are supported by all of the network hardware vendors, SD-WAN simplifies the management and operation of a WAN by decoupling the networking hardware from its control mechanism. This concept is similar to how software-defined networking implements virtualization technology to improve data center management and operation.  1  In practice, proprietary protocols are used to set up and manage an SD-WAN, meaning there is no decoupling of the hardware and its control mechanism. A key application of SD-WAN is to allow companies to build higher-performance WANs using lower-cost and commercially available Internet access , enabling businesses to partially or wholly replace more expensive private WAN connection technologies such as MPLS .  1  When SD-WAN traffic is carried over the Internet, there are no end-to-end performance guarantees. Carrier MPLS VPN WAN services are not carried as Internet traffic , but rather over carefully controlled carrier capacity, and do come with an end-to-end performance guarantee.  citation needed  WANs were very important for the development of networking in general and for a long time one of the most important applications of networks both for military and enterprise applications.  2  The ability to communicate data over long distances was one of the main driving factors for the development of data communications, as it made it possible to overcome the distance limitations, as well as shortening the time necessary to exchange messages with other parties. Legacy WANs allowed communication over circuits connecting two or more endpoints. Earlier networking supported point-to-point communication over a slow speed circuit, usually between two fixed locations. As networking progressed, WAN circuits became faster and more flexible. Innovations like circuit and packet switching (in the form of X.25 , ATM and later Internet Protocol or Multiprotocol Label Switching ) allowed communication to become more dynamic, supporting ever-growing networks.  3  The need for strict control, security and quality of service (QOS) meant that multinational corporations were very conservative in leasing and operating their WANs. National regulations restricted the companies that could provide local service in each country, and complex arrangements were necessary to establish truly global networks. All that changed with the growth of the Internet , which permitted entities around the world to connect to each other. However, over the first years, the uncontrolled nature of the Internet was not considered adequate or safe for private corporate use. Independent of safety concerns, connectivity to the Internet became a necessity to the point where every branch required Internet access. At first, due to safety concerns, private communications were still done via WAN, and communication with other entities (including customers and partners) moved to the Internet. As the Internet grew in reach and maturity, companies started to evaluate how to leverage it for private corporate communications. During the early 2000s, application delivery over the WAN became an important topic of research and commercial innovation.  4  Over the next decade, increasing computing power made it possible to create software-based appliances that were able to analyze traffic and make informed decisions without delays, making it possible to create large-scale overlay networks over the public Internet that could replicate all the functionality of legacy WANs, at a fraction of the cost. SD-WAN combines several networking aspects to create full-fledged private networks, with the ability to dynamically share network bandwidth across the connection points.  1  Additional enhancements include central controllers, zero-touch provisioning , integrated analytics and on-demand circuit provisioning, with some network intelligence based in the cloud , allowing centralized policy management and security.  5  Networking publications started using the term SD-WAN to describe this new networking trend as early as 2014.  6  With the rapid shift to remote work as a result of lockdowns and stay at home orders during the COVID-19 pandemic, SD-WAN grew in popularity as a way of connecting remote workers.  7  WANs allow companies to extend their computer networks over large distances, connecting remote branch offices to data centers and to each other, and delivering applications and services required to perform business functions. Due to the physical constraints imposed by the propagation time over large distances, and the need to integrate multiple service providers to cover global geographies (often crossing nation boundaries), WANs face important operational challenges, including network congestion , packet delay variation ,  8  packet loss ,  9  and even service outages. Modern applications such as VoIP calling, videoconferencing , streaming media , and virtualized applications and desktops require low latency .  10  Bandwidth requirements are also increasing, especially for applications featuring high-definition video .  11  It can be expensive and difficult to expand WAN capability, with corresponding difficulties related to network management and troubleshooting.  1  SD-WAN products are designed to address these network problems.  6  By enhancing or even replacing traditional branch routers with virtualization appliances that can control application-level policies and offer a network overlay, less expensive consumer-grade Internet links can act more like a dedicated circuit. This simplifies the setup process for branch personnel.  12  SD-WAN products can be physical appliances or software based only.  13  The MEF Forum has defined an SD-WAN architecture consisting of an SD-WAN edge, SD-WAN gateway, SD-WAN controller and SD-WAN orchestrator.  5  The SD-WAN edge is a physical or virtual network function that is placed at an organization's branchregionalcentral office site, data center, and in public or private cloud platforms.  5  MEF Forum has published the first SD-WAN service standard, MEF 70  14  which defines the fundamental characteristics of an SD-WAN service plus service requirements and attributes. SD-WAN gateways provide access to the SD-WAN service in order to shorten the distance to cloud-based services or the user, and reduce service interruptions.  15  A distributed network of gateways may be included in an SD-WAN service by the vendor or setup and maintained by the organization using the service.  15  By sitting outside the headquarters in the cloud, the gateway also reduces headquarters traffic.  15  The SD-WAN orchestrator is a cloud hosted or on-premises web management tool that allows configuration, provisioning and other functions when operating an SD-WAN. It simplifies application traffic management by allowing central implementation of an organization's business policies.  16  The SD-WAN controller functionality, which can be placed in the orchestrator or in an SD-WAN gateway, is used to make forwarding decisions for application flows.  14  Application flows are IP packets that have been classified to determine their user application or grouping of applications to which they are associated. The grouping of application flows based on a common type, e.g., conferencing applications, is referred to as an Application Flow Group in MEF 70. Per MEF 70, the SD-WAN Edge classifies incoming IP packets at the SD-WAN UNI (SD-WAN user network interface),  14  determines, via OSI Layer 2 through Layer 7 classification, which application flow the IP packets belong to, and then applies the policies to block the application flow or allow the application flows to be forwarded based on the availability of a route to the destination SD-WAN UNI on a remote SD-WAN Edge. This helps ensure that application performance meets service level agreements (SLAs).  17  he Gartner research firm has defined an SD-WAN as having four required characteristics:  1  Features of SD-WANs include resilience, quality of service (QoS), security, and performance, with flexible deployment options; simplified administration and troubleshooting; and online traffic engineering. A resilient SD-WAN reduces network downtime. To be resilient, the technology must feature real-time detection of outages and automatic switch over (fail over) to working links.  18  SD-WAN technology supports quality of service by having application level awareness, giving bandwidth priority to the most critical applications. This may include dynamic path selection, sending an application on a faster link, or even splitting an application between two paths to improve performance by delivering it faster.  5  SD-WAN communication is usually secured using IPsec , a staple of WAN security.  19  SD-WANs can improve application delivery using caching , storing recently accessed information in memory to speed future access.  20  SD-WANs can incorporate artificial intelligence for IT operations (AIOps) for continuous troubleshooting and fixes to network issues.  21  Most SD-WAN products are available as pre-configured appliances, placed at the network edge in data centers, branch offices and other remote locations. There are also virtual appliances that can work on existing network hardware, or the appliance can be deployed as a virtual appliance on the cloud in environments such as Amazon Web Services (AWS), Unified Communications as a service (UCaaS) or as Software as a Service (SaaS).  22  This allows enterprises to benefit from SD-WAN services as they migrate application delivery from corporate servers to cloud based services such as Salesforce.com and Google apps.  13  As with network equipment in general, GUIs may be preferred to command line interface (CLI) methods of configuration and control.  23  Other beneficial administrative features include automatic path selection, the ability to centrally configure each end appliance by pushing configuration changes out, and even a true software defined networking approach that lets all appliances and virtual appliances be configured centrally based on application needs rather than underlying hardware.  1  With a global view of network status, a controller that manages SD-WAN can perform careful and adaptive traffic engineering by assigning new transfer requests according to current usage of resources (links). For example, this can be achieved by performing central calculation of transmission rates at the controller and rate-limiting at the senders (end-points) according to such rates.  24   25   26   27   28  SD-WAN is a core component of secure access service edge solutions (SASE) which incorporate network and security capabilities to more efficiently and securely connect distributed work environments (branch office, headquarters, home office, remote) to distributed applications located in data centers, cloud infrastructure, or delivered by SaaS services. With SASE, SD-WAN is combined with other network and security technologies including cloud access security broker (CASB), Secure Web Gateway , Data Loss Prevention (DLP), Zero Trust Network Access ( ZTNA ), Firewall, and other capabilities to connect and protect users and applications. In December 2021, Gartner research firm estimated that by 2025, 50 of SD-WAN purchases will be part of a single vendor SASE offering.  29  There are some similarities between SD-WAN and WAN optimization , the name given to the collection of techniques used to increase data-transfer efficiencies across WANs. The goal of each is to accelerate application delivery between branch offices and data centers, but SD-WAN technology focuses additionally on cost savings and efficiency, specifically by allowing lower cost network links to perform the work of more expensive leased lines, whereas WAN Optimization focuses squarely on improving packet delivery. An SD-WAN utilizing virtualization techniques assisted with WAN Optimization traffic control allows network bandwidth to dynamically grow or shrink as needed. SD-WAN technology and WAN optimization can be used separately or together,  30  and some SD-WAN vendors are adding WAN optimization features to their products.  20   31  A WAN edge router is a device that routes data packets between different WAN locations, giving enterprise access to a carrier network. Also called a boundary router, it is unlike a core router, which only sends packets within a single network.  32  SD-WANs can work as an overlay to simplify the management of existing WAN edge routers, by lowering dependence on routing protocols.  6  SD-WAN can also potentially be an alternative to WAN Edge routers.  12  SD-WANs are similar to hybrid WANs, and sometimes the terms are used interchangeably, but they are not identical. A hybrid WAN consists of different connection types, and may have a software defined network (SDN) component, but doesn't have to.  33  Cloud-based SD-WAN offers advanced features, such as enhanced security, seamless cloud, and support for mobile users, that result naturally from the use of cloud infrastructure. As a result, cloud-based SD-WAN can replace MPLS, enabling organizations to release resources once tied to WAN investments and create new capabilities.  34  An overview discussing three typical reasons to compare MPLS with SD-WAN. Specifically where IT teams need to retain MPLS due to contract commitments and where the Enterprise migrates from MPLS to an Internet-based SD WAN.  35  As there is no standard algorithm for SD-WAN controllers, device manufacturers each use their own proprietary algorithm in the transmission of data. These algorithms determine which traffic to direct over which link and when to switch traffic from one link to another. Given the breadth of options available in relation to both software and hardware SD-WAN control solutions, it's imperative they be tested and validated under real-world conditions within a lab setting prior to deployment.  citation needed  There are multiple solutions available for testing purposes, ranging from purpose-built network emulation appliances which can apply specified network impairments to the network being tested in order to reliably validate performance, to software-based solutions.  citation needed  Network World IT website divides the SD-WAN vendor market into three groups: established networking vendors who are adding SD-WAN products to their offerings, WAN specialists who are starting to integrate SD-WAN functionality into their products, and startups focused specifically on the SD-WAN market.  1  The global SD-WAN market stood at 3.25 billion in 2021 and the market is expected to grow 30 in 2022. According to SD-WAN market Report Datavagyanik, North America accounted for more than 77 of the market.  36  Alternatively, a market overview by Nemertes Research groups SD-WAN vendors into categories based on their original technology space, and which are ""Pure-play SD-WAN providers"", ""WAN optimization vendors"", ""Link-aggregation vendors"", and ""General network vendors"".  30  While Network World's second category (startups focused specifically on the SD-WAN market), is generally equivalent to Nemertes' ""Pure-play SD-WAN providers"" category, Nemertes offers a more detailed view of the preexisting WAN and overall networking providers.  citation needed  Additionally, Nemertes Research also describes the in-net side of the SD-WAN market, describing the go-to-market strategy of connectivity providers entering the SD-WAN market. These providers include ""Network-as-a-service vendors"", ""Carriers or telcos"", ""Content delivery networks"" and ""Secure WAN providers"".  citation needed  MEF 70 standardizes SD-WAN service attributes and uses standard IPv4 and IPv6 routing protocols. SD-WAN services also use standard IPsec encryption protocols. Additional standardization for other SD-WAN functions and related security functionality not covered in MEF 70 are under development at the MEF Forum. There are several opensource SD-WAN solutions and opensource SD-WAN implementations available. For example, the Linux Foundation has three projects that intersect with and help the SD-WAN market: ONAP , OpenDaylight Project , and the Tungsten Fabric (formerly Juniper Networks ' OpenContrail).",2424
https://www.cisco.com/site/us/en/learn/topics/networking/what-is-sd-wan.html,What Is SD-WAN? - Software-Defined WAN (SDWAN)  - Cisco,"The traditional WAN (wide-area network) function was to connect users at the branch or campus to applications hosted on servers in the data center. Typically, dedicated Multiprotocol Label Switching ( MPLS ) circuits were used to help ensure security and reliable connectivity. This doesn't work in a cloud-centric world. Times have changed. As businesses adopt the use of software-as-a-service ( SaaS ) and infrastructure-as-a-service (IaaS) applications in multiple clouds, IT is realizing that the user application experience is poor. That is because WANs designed for a different era are not ready for the unprecedented explosion of WAN traffic that cloud adoption brings. That traffic causes management complexity, application-performance unpredictability, and data vulnerability. Further, opening the enterprise to the Internet and the cloud exposes major threat and compliance issues. It is extremely challenging to protect the critical assets of an enterprise when applications are accessed by a diverse workforce, including employees, partners, contractors, vendors, and guests. Enabling broadband on the WAN makes the security requirements more acute, creating challenges for IT in balancing user experience, security, and complexity. New business models drive the need for a new network model. SD-WAN addresses the current IT challenges. This new approach to network connectivity can lower operational costs and improve resource usage for multisite deployments. Network administrators can use bandwidth more efficiently and can help ensure high levels of performance for critical applications without sacrificing security or data privacy. The traditional WAN architecture was limited to enterprise, branch, and data center. Once an organization adopts cloud-based applications in the form of SaaS and IaaS, its WAN architecture experiences an explosion of traffic accessing applications distributed across the globe. These changes have multiple implications for IT. Employee productivity may be compromised by SaaS-application performance problems. WAN expenses can rise with inefficient use of dedicated and backup circuits. IT fights a daily, complex battle of connecting multiple types of users with multiple types of devices to multiple cloud environments. With SD-WAN, IT can deliver routing, threat protection, efficient offloading of expensive circuits, and simplification of WAN network management. Business benefits can include the following: Read IDC report SD-WAN evolved from MPLS technology, which has powered private connectivity for more than two decades. In many ways, SD-WAN can be seen as a software abstraction of MPLS technology that's applicable to wider scenarios: It brings secure, private connectivity that's agnostic to all kinds of links and providers and is cloud-aware. While MPLS handled failure scenarios with backup links, SD-WAN handles them with real-time traffic steering based on centralized policy. Also, since SD-WAN unifies the entire WAN backbone, it delivers comprehensive analytics across the network globally. This wasn't possible before, because of disparate pieces of infrastructure and policy. SD-WAN can be seen as software defined networking (SDN) for the WAN. It represents, arguably, the most popular and widely deployed use case in SDN. The SDN model became popular for abstracting network infrastructure in the data center and other sections within the enterprise perimeter. SD-WAN played a similar role but needed to abstract infrastructure elements that were diverse in terms of link types, providers, and geographies. Since it crossed the enterprise perimeter, it needed a robust security component as well. Extend intent-based networking across the branch, WAN, and cloud. Learn more For lean IT teams, Meraki simplifies branch management and integrates threat management. Learn more",555
https://www.fortinet.com/resources/cyberglossary/sd-wan-explained,What is SD-WAN (Software-Defined WAN)? Benefits and Components | Fortinet,"Watch this demo to see how FortiManager enables centralized management with automation-driven network configuration, visibility, and security policy management of FortiGate Secure SD-WAN devices.",24
https://support.apple.com/guide/remote-desktop/welcome/mac,Apple Remote Desktop User Guide for Mac - Apple Support,for Mac,2
https://en.wikipedia.org/wiki/Remote_desktop_software,Remote desktop software - Wikipedia,"In computing , the term remote desktop refers to a software - or operating system feature that allows a personal computer 's desktop environment to be run remotely from one system (usually a PC, but the concept applies equally to a server or a smartphone ), while being displayed on a separate client device . Remote desktop applications have varying features. Some allow attaching to an existing user's session and ""remote controlling"", either displaying the remote control session or blanking the screen. Taking over a desktop remotely is a form of remote administration. Remote access can also be explained as the remote control of a computer by using another device connected via the internet or another network. This is widely used by many computer manufacturers and large businesses help desks for technical troubleshooting of their customer's problems. Remote desktop software captures the mouse and keyboard inputs from the local computer (client) and sends them to the remote computer (server).  1  The remote computer in turn sends the display commands to the local computer. When applications with many graphics including video or 3D models need to be controlled remotely, a remote workstation software that sends the pixels rather than the display commands must be used to provide a smooth, like-local experience. Remote desktop sharing is accomplished through a common clientserver model. The client, or VNC viewer, is installed on a local computer and then connects via a network to a server component, which is installed on the remote computer. In a typical VNC session, all keystrokes and mouse clicks are registered as if the client were actually performing tasks on the end-user machine.  2  Remote desktops also have a major advantage for security development, companies are able to permit software engineers who may be dispersed geographically to operate and develop from a computer which can be held within the companies office or cloud environment. The target computer in a remote desktop scenario is still able to access all of its core functions. Many of these core functions, including the main clipboard , can be shared between the target computer and remote desktop client. Following the onset of COVID-19 , the shift to remote-work environments has led many to work from home with devices without enterprise IT support. As a result, these workers were reliant on remote desktop software to collaborate and keep their systems available and secure.  3  A main use of remote desktop software is remote administration and remote implementation. This need arises when software buyers are far away from their software vendor. Most remote access software can be used for "" headless computers "": instead of each computer having its own monitor, keyboard, and mouse, or using a KVM switch , one computer can have a monitor, keyboard, mouse, and remote control software, and control many headless computers. The duplicate desktop mode is useful for user support and education. Remote control software combined with telephone communication can be nearly as helpful for novice computer-users as if the support staff were actually there. Remote desktop software can be used to access a remote computer: a physical personal computer to which a user does not have physical access, but that can be accessed or interacted with.  4  Unlike servers , remote computers are mainly used for peer to peer connections, where one device is unattended. A remote computer connection is generally only possible if both devices have a network connection. Since the advent of cloud computing remote desktop software can be housed on USB hardware devices , allowing users to connect the device to any PC connected to their network or the Internet and recreate their desktop via a connection to the cloud. This model avoids one problem with remote desktop software, which requires the local computer to be switched on at the time when the user wishes to access it remotely. (It is possible with a router with C2S VPN support, and wake on LAN equipment, to establish a virtual private network (VPN) connection with the router over the Internet if not connected to the LAN , switch on a computer connected to the router, then connect to it.) Remote desktop products are available in three models: hosted service, software, and appliance. Tech support scammers use remote desktop software to connect to their victim's computer and will often lock out the computer if the victim does not cooperate. Remote desktop protocols include the following: A remote access trojan ( RAT , sometimes called creepware )  6  is a type of malware that controls a system through a remote network connection. While desktop sharing and remote administration have many legal uses, ""RAT"" connotes criminal or malicious activity. A RAT is typically installed without the victim's knowledge, often as payload of a Trojan horse , and will try to hide its operation from the victim and from computer security software and other anti-virus software.  7   8   9   10   11   12 ",818
https://www.fortinet.com/solutions/enterprise-midsize-business/network-access/application-access,Zero Trust Network Access (ZTNA) to Control Application Access | Fortinet,"Zero Trust is all about trusting users and devices only after they have been verified. Watch the video to learn how to achieve simple, automatic secure remote access that verifies who and what is on your network. Fortinet ZTNA secures application access no matter where users are located.",48
https://www.zscaler.com/resources/security-terms-glossary/what-is-zero-trust-network-access,Zero Trust Network Access (ZTNA)  Benefits & Overview | Zscaler," What Is Zero Trust Network Access (ZTNA)? Zero trust network access (ZTNA) is a set of technologies that enable secure remote access to internal applications. Trust is never granted implicitly, and access is granted on a need-to-know, least-privileged basis defined by granular policies. ZTNA gives users secure connectivity to private apps without placing them on the network or exposing apps to the internet. The future of work is distributed, and remote workforces and cloud workloads demand secure remote access. However, traditional remote access solutions like virtual private networks (VPNs) are not flexible or granular enough for distributed environments, increasing breach risks. This is a key reason 65 of enterprises recently reported plans to replace their VPNs with a solution such as ZTNA. ZTNA provides secure remote access to internal applications for any user, from anywhere, without putting critical resources at risk. To accomplish this, it starts with an architecture that's fundamentally different from a network-centric solution. Relying on a software-defined perimeter (SDP) , ZTNA enforces secure, identity-based access controls. This helps organizations replace their VPNs while reducing dependence on tools like DDoS protection, global load balancing, and firewalls. Following four core principles, ZTNA: VPN VPNs give users access to a network and its resources through an encrypted, private tunnel. For many years, they were sufficient for users who worked remotely on occasion. However, cloud and remote work trends in the mid-to-late 2010s began to highlight shortcomings in the VPN approach. ZTNA ZTNA provides secure least-privileged access. Instead of granting trust based only on credentials, it verifies users based on a breadth of context, including device, location, and identity, for every access request. Once verified, users receive direct application access rather than network-wide access. With VPNs creating serious compliance and security risks, more and more organizations are discovering the advantages of ZTNA. Here are some of the top reasons to make the switch: ZTNA helps organizations strengthen their overall security posture and agility by delivering: While ZTNA has many use cases, most organizations start with one of these four. VPN Alternative VPNs are inconvenient and slow for users, difficult to manage, and offer poor security. More than half of organizations cite security and poor user experiences as the top challenges of VPN solutions. Reduce Third-Party Risk Most third-party users receive overprivileged access, and they largely use unmanaged devices, both of which introduce risks. ZTNA significantly reduces third-party risk by never providing direct network access and enforcing least-privileged access to apps. Accelerate MA Integration MA integrations can span multiple years as organizations converge networks and deal with overlapping IPs. ZTNA can provide direct app access with no need to converge networks or resolve IP overlap, significantly simplifying and speeding up MA value capture. Secure Multicloud Access Securing hybrid and multicloud access is the most popular place for organizations to start their ZTNA journey. As more companies adopt the cloud, the vast majority are turning to ZTNA for security and access control for their multicloud strategies. How Does ZTNA Simplify Multicloud Access? ZTNA simplifies multicloud access by providing secure, direct connections between users and specific apps, wherever they are. It eliminates the need for complex network-level configurations or redundant VPNs, using identity-based authentication and granular access controls to unify security across clouds. Implementing ZTNA follows a phased approach designed to ensure smooth adoption, enhance security, and reduce risks: In today's crowded marketplace, it's important to consider several other key criteria when evaluating ZTNA solutions against your unique needs: Keep these things in mind as you look for the vendor that complements your goals and vision . Zscaler Private Access is the worlds most deployed ZTNA platform, built on the unique Zscaler zero trust architecture. As a cloud native service, ZPA can be deployed in hours to replace legacy VPNs and remote access tools with a holistic zero trust platform. Zscaler Private Access delivers: Is ZTNA More Secure Than VPN? ZTNA is more secure than VPNs because it gives access only to specific apps instead of entire networks. This reduces risks like lateral movement, hiding sensitive systems from attackers, and shrinking the attack surface for better protection. Which Industries Need ZTNA the Most? Industries like healthcare, finance, and tech may gain the most from ZTNA. However, for any organization that depends on remote teams, strict rules, or large networks, ZTNA helps them keep data and apps safe with least-privileged access. How Hard Is ZTNA to Deploy and Manage? ZTNA is simple to set up and oversee. It works with cloud-based systems, so it deploys in days, not weeks. Its portals offer quick control of policies, instant user insights, and easy scaling for growth. Can ZTNA Improve Cybersecurity in Hybrid Work Environments? ZTNA boosts security for hybrid work by limiting access to apps, stopping lateral movement, and changing policies based on device and location. It guards systems without slowing down or complicating user access. Is ZTNA a Good Alternative to Legacy Network Segmentation? ZTNA is ideal for replacing network segmentation. It uses identity-based app permissions instead of complex network setups, removing over-access risks while simplifying security for workflows and cloud setups. SD-WAN vs. MPLS: What's the Difference? What Is Trusted Internet Connections (TIC) 3.0? Whats the Difference Between SDP and VPN?",866
https://www.efax.com/,"Fax Online with eFax | Secure, Scalable, Enterprise Cloud Fax"," Easily connect with millions of providers, process direct secure messages, query for patient data, and streamline clinical faxes all from a single, HIPAA-compliant platform. eFax  allows you to easily download files from popular cloud storage services like Dropbox, iCloud and Google Drive so you can quickly grab files from the cloud, attach them to your virtual fax, and send online faxes. Choose from two convenient signing options for your electronic faxes: sign your faxes online by swiping your finger across the screen of your mobile device, or simply drag and drop a saved signature onto your fax document. Securely store and easily access all inbound and outbound faxes online for the life of your account. Tag your faxes with keywords for easier search and retrieval. Unleash the power of compliant fax. eFax Protect, our highly encrypted online fax solution enhances the security of your fax communications and maintains compliance with applicable requirements under HIPAA, GLBA and SOX regulations. Now you can be more efficient, fax online from anywhere, and close deals on the go. Tap on the app to receive, sign and send online faxes right from your phone or tablet. Online File Sharing eFax  allows you to easily download files from popular cloud storage services like Dropbox, iCloud and Google Drive so you can quickly grab files from the cloud, attach them to your virtual fax, and send online faxes. Electronic Signatures Choose from two convenient signing options for your electronic faxes: sign your faxes online by swiping your finger across the screen of your mobile device, or simply drag and drop a saved signature onto your fax document. Free Online Storage Securely store and easily access all inbound and outbound faxes online for the life of your account. Tag your faxes with keywords for easier search and retrieval. Compliance with HIPAA Unleash the power of compliant fax. eFax Protect, our highly encrypted online fax solution enhances the security of your fax communications and maintains compliance with applicable requirements under HIPAA, GLBA and SOX regulations. Free Mobile Apps Now you can be more efficient, fax online from anywhere, and close deals on the go. Tap on the app to receive, sign and send online faxes right from your phone or tablet. Achieve HIPAA compliance in regulated industries with eFax Protect or eFax Corporate HITRUST certified enterprise fax solutions. Our AES secure transmission maintains adherence to HIPAA, SOX, GLBA, and PCI regulations, backed by 256-bit TLS encryption and Tier-3 secure servers. eFax is the trusted choice for individuals and businesses seeking secure and compliant faxing solutions. If you can send an email, you can fax with eFax. Compose a new email message and address it to your recipients fax number followed by efaxsend.com. Attach the document you want to fax. Click Send, and youre done! Your document will be delivered as a fax. To receive faxes with eFax  , just check your email inbox. Incoming faxes will be delivered there as PDF attachments. You can also send an online fax using the eFax web portal or our convenient mobile app. Receive Faxes Online, by Email or Mobile App Receiving faxes online, by email, or through a mobile app with eFax offers numerous benefits including convenience, flexibility, efficiency  accessibility. A solution to scale with your business Send a Fax From Anywhere  Safe Processing  Robust Integration  Receive Faxes Electronically eFax  protects your documents with advanced encryption and privacy measures. Rest easy knowing your data is safe wherever it goes. Maximize cost savings without compromising on quality. eFax provides outstanding value with an affordable monetary investment. Select from certain service solutions that utilize features that are consistent with applicable regulations. Send and receive sensitive documents safely with our trusted electronic faxing service. Get prompt, reliable fax delivery with instant online access. Seamlessly integrate eFax with your existing communication systems. Add cloud faxing capabilities to your existing online workflow. Receive dedicated support from a personal account manager. Get help with our system via technical customer assistance. Integrates with third party solutions to optimize your workflows and enhance productivity. Experience smooth document exchange and automate tedious processes. Discover why eFax  is the preferred choice of clients and trusted partners spanning diverse industries. Our reliability and commitment to excellence make us a top-notch fax solution. Send faxes online globally from 46 countries with ease Fax worldwide from 46 countries and 3,500 cities with eFax  . Our online fax service simplifies international faxing, allowing effortless use of dialing codes. Access local fax numbers and toll-free fax numbers in these regions from our extensive database. Construction McCabe Group significantly improved its business processes by switching from paper-based faxing to eFax Corporate fax-by-email solution. Insurance National Insurance Company  Customer Success Story  Cloud Faxing helps reduce liability and streamlines administrative communications for independent agents. Banking  Finance Regional Bank  Customer Success Story  Cloud Faxing helps maintain information security. Legal eFax Corporate helped law firm Duane Morris LLP make faxing among its 24 offices much more efficient and helped them remove costly fax servers. Send and Receive Faxes in Minutes eFax provides a host of convenient ways to send a fax online: via email, smartphone , with the mobile app, or using your online account on the eFax website. eFax works with all major computer files, including PDF , TIFF, DOC, and PNG. Getting started with your new eFax account is free and easy. You dont need to buy any special equipment or a fax number .Our innovative online fax service offers key features to help you accomplish essential tasks for your business. Sign up today to get started. Online faxing, particularly with platforms like eFax, is highly secure as compared to fax machines , be it for sending tax forms or any other confidential documents. eFax employs robust encryption measures to ensure the confidentiality and security of transmitted documents. Furthermore, strict access controls, including two-factor authentication, are in place to limit access to unauthorized users. Millions of users rely on eFax for their digital faxing needs, drawn by our two-decade legacy as the worlds leading online fax service. Our reputation is solidified through the trust of Fortune 500 corporations and thriving small businesses globally. eFax facilitates efficient online faxing and provides HIPAA-compliant plans tailored to regulated industries. Effortlessly manage documents on-the-go. Embrace the convenience of paperless solutions for efficient workflows. See how eFax stacks up next to competing electronic fax solutions and what sets the worlds trusted cloud fax software apart. See your entire fax history and document history in an auditable, reliable digital database.",1084
https://sign.dropbox.com/products/dropbox-fax,Send and Receive Fax Online by Phone and Computers - Dropbox Fax,"Send faxes without a fax machine. With Dropbox Fax, you can send a fax from a computer or mobile deviceno need to waste paper using a clunky fax machine. Send your fax online, with all transmissions fully encrypted for your security. Cancel anytime during trial. No paper means no sensitive information is potentially exposed. All transmissions are encrypted for your security. Set up as many fax numbers and users as needed, and route inbound faxes any way you like. Within minutes, everyone in your organization can send and receive faxes. When you receive a fax, it arrives as a PDF. To send a fax, upload the file, enter the fax number or email address, and click Send. That's it. No paper involved. Send, retrieve, and manage your faxes in the cloud. Dropbox Fax integrates with Google Drive, Dropbox, Box, OneDrive, and Evernote for your convenience. Incoming faxes go directly to your inbox, and outgoing faxes are sent from your computer. No fax machine needed. Your customers can still send faxes to your number the same way they always have. Transfer your number to Dropbox Fax and start receiving faxes electronically, without any downtime or risk of losing faxes. This service is available in the US and Canada. Setup takes less than a minute: no fax machines to hook up, phone companies to deal with, or fax servers to configure. Choose a plan, add your users, and assign fax numbers. Dropbox Fax accommodates almost any volume of faxes, numbers, or users. Online faxes arrive as PDFs in Dropbox Fax, where you can view, download, and share themwith unlimited file storage. Sending a fax is just as easy. You can send it to multiple fax numbers at the same time, and even sign and edit the fax electronically. How do I receive a fax online? With a Dropbox Fax paid account, your fax number works like a fax line, and you can receive faxes from physical machines as well as other computer fax services. Your account is accessible from anywhere via the cloud, so you can receive faxes on a computer, tablet, or mobile device. Each fax will arrive as a PDF in your email inboxjust download with a few clicks. Dropbox Fax integrates with Google Drive, Dropbox, Box, OneDrive, and Evernote, allowing you to easily store and share documents received via online fax. How do I fax from my computer without using paper? Faxing from a computer is simpler, quicker, and more environmentally friendly than a traditional fax machine. The sender enters the recipient's fax number (or email address if the recipient is also a Dropbox Fax customer). The fax is then sent electronically from the sender's computer and arrives at the recipient's fax machine (or email inbox). What documents can I fax online? Documents that are typically transmitted via faxsuch as sales contracts , leases, NDAs, and tax formscan be sent using Dropbox Fax. Accepted payment methods Dropbox Sign electronic signatures are legally binding in the United States, European Union, United Kingdom, and in many countries around the world. For more information, please view our Terms and Conditions and Privacy Policy",521
https://www.fax.plus/,Fax.Plus - Best Online Fax Service | Send Fax Online Securely,"Fax.Plus is an online fax solution trusted by over 4,000,000 customers worldwide. Seamlessly send and receive faxes using computer, mobile, or email. Effortlessly send and receive fax from computer , mobile and other supported devices and platforms while enhancing productivity through seamless integration with your preferred apps. Sending faxes directly from your email is as simple as composing a message, ensuring easy access to incoming faxes for maximum convenience. Get a local, toll-free, or international fax number from an array of countries to receive faxes online. You can even keep your existing fax number by porting it into our platform, unlocking the full potential of the best online fax service. Elevate your fax communication by sending cover pages along with your messages. Customize cover pages with your identity, subject line, or message details. Attach files from your computer, Google Drive, or Dropbox effortlessly. Streamline faxing with our email-to-fax feature. Easily send faxes directly from your email and receive incoming faxes. Keep track of sent faxes and their status right in your mailbox. Effortlessly manage multiple fax numbers and team members with our advanced corporate admin panel. We ensure rigorous security and compliance for your peace of mind. Enjoy seamless integration with your software, high-volume faxing, and more. Sign documents digitally before faxing, no more printing, signing, or scanning. All Fax.Plus paid plans include 30-day free access for Sign.Plus. Streamline your document and signature workflow today. Fax.Plus revolutionizes online faxing by combining unbeatable security with unmatched convenience.  Every fax you send and receive is safeguarded, ensuring your information remains protected and private. Access Fax.Plus across multiple platforms and devices, including desktop, Android, iOS, email, Google, and multi-function printers. Integrate effortlessly with Zapier or leverage the programmable fax API for enhanced convenience. Exceed global standards for a secure online faxing experience. Send and receive fax both locally and internationally. Seamless online faxing experience across multiple platforms. Send fax online to over 180 countries Create an account to send faxes online across multiple platforms to anywhere in the world. It's secure, compliant, and easy to use.",343
https://comfax.com/reviews/free-fax/,"Free Fax Review - Top 7 Choices Reviewed and Tested, 2025 Updated","Table of Contents Most online fax services cost money, but there are some completely free fax services, and others which offer a free trial to users, in case you need to send a fax without paying anything. We have reviewed the best ways to fax for free below! Faxes were sent, but not a penny was spent in the making of this article. The good news is that there are ways to send a free fax. The bad news  its hard, and it took a lot of looking. There are many apps that include tricks like saying ad free, or free download in the title  plenty of apps look free on the app store, until you download them and realize its not a free fax app at all, you need to sign up and pay once youve installed it! Read on to discover how to send a fax completely free or jump straight to our final scores ! We found a few different ways to send a free fax, which can be broken down into the two categories below: For the test, we used each service to fax a sample PDF document we found online  it has a good mix of text, graphics and color, so well be able to see and compare how well each fax sends. We sent the exact same file using each free fax service. We have ranked every free fax service out of 10, with reviews that cover the following areas: Before we begin, as a disclaimer  it is not recommended to use a free fax online service to send and receive faxes containing sensitive information or confidential data. If you are dealing with taxes , insurance, healthcare , or anything else which is very important  I recommend signing up with a more premium paid service which can offer more customer support and security features than a free fax service. See our online fax services review for all options, both free and paid instead. Our final scores for the services weve reviewed are listed above  lets go into each one below in more detail! eFax is a well-established fax services provider founded in the 1990s, which has been at the forefront of digital faxing ever since. eFaxs free trial period allows users to test the capability of eFax, and send faxes completely free. eFax offers a website with a faxing portal, but also mobile fax apps for Android and iPhone  giving you a huge amount of flexibility with your free trial. Read our full eFax review here. Heres the image quality of the fax Ive received from eFax: eFax has an excellent reputation in the industry for top-tier security and regulatory compliance  they can even advise you on the regulatory limitations of a region you are faxing to. eFax is incredibly secure and one of the best online fax services for sending information you want to keep private. However, this free trial does not include HIPAA compliance, and so you will need to pay to get that protection from eFax using one of their HIPAA-compliant plans, in case you need to send or receive sensitive medical information. eFax scores consistently highly as a paid fax service, and since this is essentially a free trial, you get all the benefits of being a fully-paid user for a limited amount of time. eFax gets very strong reviews from businesses and regular users, and is widely regarded as a leading fax service. For example, the Apple Store eFax app has a 4.7 average rating from over 28,000 reviews  a very good score. eFax is an outstanding service which is relied upon by large businesses for its clear and reliable faxing. The free trial was easy to set up, and more importantly, easy to cancel, and it provided the best quality fax on this list. If you dont mind handing over credit card information, this is a top recommendation. Our final scores for the services weve reviewed are listed above  lets go into each one below in more detail! CocoFax is a popular fax service used by individuals and enterprises, and includes a totally free trial which requires no commitment or credit card information. All you need is an email address to create a free account and start sending free faxes online. CocoFax will give new users a free fax number (however you wont be able to receive faxes until you pay for a subscription), and they claim to offer you 10 free fax pages to send, after which point you must sign up to a plan. The features you can use when sending a new fax are limited compared to being on a paid plan, however you benefit from all the security that CocoFax has to offer, making this free option a strong proposition for people who dont want to give any payment information away. CocoFax is without a doubt the best option for free, secure faxing without giving any payment information away. You get totally free HIPAA compliant faxes , and benefit from all the top data security measures such as 256-bit AES encryption, 2FA and firewall protections, as well as HIPAA, GDPR and PCI-DSS compliance. This is a very secure option. CocoFax is consistently well reviewed on G2 , with a 4.7 out of 5 rating  this is better than fully paid fax services like HelloFax and Documo! Its especially popular with business users, but regular users on GetApp also have good things to say about it, with a 4.3 out of 5 rating. If youre looking to simply send a free fax, whilst providing no payment details and getting the best security and service out there  CocoFax is what wed recommend. Unfortunately we cannot give it 1010 due to it not actually being misleading about the number of fax pages you can send, but if you only want to send a few pages for free, wed go with this! GotFreeFax is a free online fax service which allows users to send a limited number of free faxes per day within the US and Canada. You get 2 free faxes per day, and 3 pages per fax, but you can send more with some paid plans. The website gets straight to the point  you simply fill in your details, the details of the fax recipient, type a message for a cover page if you like, and then upload files straight from your device. Click send, and youre done! This is a quick way to send a short free fax online, without signing up for anything at all. GotFreeFaxs privacy policy mentions a few measures they take on their side to keep their internal systems and data safe, but as far as fax transmission goes, there is no mention of security features like encryption, or compliance with HIPAA or any other regulations. GotFreeFax is therefore not a recommended option for secure faxing. GotFreeFax does what it says  itll send a quick free fax, without a fax machine needed, at a pretty average quality. It gets reviews to match that  TechRadar gave it a solid 4-star review which you can read for more detail. The fax quality isnt excellent, but its totally free, so you cant really complain. In case youre wondering, theres nothing malicious about it and it isnt a scam  just a helpful free fax service. GotFreeFax ticks all the boxes as a quick, free and easy online fax service you can use from your computer or phone. Unless youre faxing sensitive information or need more pages than the free service offers, then this is a really good free fax option, and it gets a strong recommendation. Read our full GotFreeFax review here. FaxBurner is an online fax service with an iPhone or Android app, as well as the option to use email-to-fax with your preferred email account. A paid service, FaxBurner has a Free plan which users can sign up to and use without ever paying a penny, or even providing any payment details. The free plan with FaxBurner lets users send and receive faxes  however there are a few big limitations to each. For sending faxes, you can only send 5 fax pages in total before youll have to upgrade  it does not reset each month. For receiving faxes, you can receive up to 25 pages per month, forever, for free. However, you cannot keep your own fax number. Whenever you expect to receive faxes, you can receive a temporary fax number from FaxBurner  this number will be yours to receive faxes on for 24 hours, and then you will have to receive a new (and different) temporary fax number. FaxBurner is not advised as a way of sending and receiving confidential or sensitive faxes  it is not HIPAA compliant (even under its highest paid plan), and very little detail is provided about the security FaxBurner does offer, it doesnt even claim to encrypt transmissions, which would make it less secure than the average online faxing service. What Others Are Saying FaxBurner has a very positive score on the Apple Store, with a 4.95 rating . They also frequently respond to good and bad reviews in a unique and engaging way  we even found one bad review which led them to refund a customers annual charge because they locked themselves out of their account. People are generally very satisfied with using FaxBurner as a low-cost or free online fax option. If youll never need to send many faxes, but want a quick and easy way of occasionally being able to receive some  and you dont mind the relatively low level of security  then FaxBurners free plan is one of the best value offers in all of online faxing. FaxBurner is a totally free way of receiving up to 25 regular fax pages each month. Heress our full FaxBurner review FaxZero is a free online fax service which can be used on a computer or mobile device. This is a totally free service which requires none of your personal information, or payment details  just verify your email address and youre good to go. FaxZero offers 5 free faxes per day, with a 3-pages limit on each fax, as well as an almost free option which allows you to buy more faxes and send larger faxes. Similar to GotFreeFax, FaxZero is totally free and only makes money from ads, so you arent getting the highest security here, and there is no HIPAA compliance. You should only send faxes that are not confidential and sensitive using this service. On the plus side, FaxZero are very committed to not sending you any spam or junk mail, and keep secure servers, and claim to delete your fax data 3 days after you send your fax. FaxZero is well-liked by the tech industry as a basic free fax provider, with TechRadar giving it 4-stars and PCMag giving it 3-stars , the latter saying if you refuse to pay for a fax, its the best option. FaxZero is a good alternative to GotFreeFax, standing out for offering more free faxes, and for encouraging people to participate in politics. However, we wouldnt recommend it above GotFreeFax as an all-round fax service, due to the fax quality, branding, the inability to receive faxes, and some other factors. That said, its very useful as a free fax service if you need to quickly fire off a fax to a friend! Read our FaxZero review here. Fax.Plus is an online faxing service from Alohi, and one of the top faxing apps on the Apple and Google Play stores. As a paid subscription, Fax.Plus is a good choice, and they have a page on their website promising a simple process to send a free fax online. Heres the image quality for our Fax.Plus test: Whilst Fax.Plus lacks the more advanced features of eFax, it is still considered a very secure service to use, and a free trial includes the benefit of the security on offer. This is a safe service to send important documents with, however the free trial is not HIPAA compliant (only Fax.Plus most expensive option provides this), and so we wouldnt recommend using it to send or receive sensitive medical information, either to healthcare providers or insurance companies. Fax.Plus is a well-reviewed and leading online fax service, with a popular score of 4.7 on the Apple Store. Its one of the leading faxing apps across multiple platforms, and consistently gets above average reviews. Ultimately, Fax.Plus is a great service if youre paying for it, however as a free fax service it does fall short compared to others. You only get 10 pages in total, and the website does lead you to think that the free service is more than 10 pages, only revealing the details once you have signed up. PamFax is an online fax service offering a free trial of sending 3 fax pages, with no payment details needed. You can then purchase a plan to get your own fax number, and start sending and receiving more faxes. In their privacy policy, there is no mention of any advanced faxing security features such as E2E encryption, regulatory compliance, or data protection  just some very standard security features that most of the internet has. This is not recommended for faxing confidential information. Were not the only ones underwhelmed by PamFax  TechRadar reviewed their paid service and gave it 2.5 stars , finding that it missed key features and didnt offer basic security features. PamFax is not a top suggestion when you search the internet for free faxing options, and we would suggest using an alternative. As we can see, there are a few half-decent ways to send a fax for free online, whether its no-strings attached, or a free trial you need to cancel after the fact. However, there are pretty clear limitations on the choices we could find: Theres also a few limitations they all have in common, one being page numbers  they all have a limit. The other limitation seems silly to say, but well, theyre free . This means youre not a paying customer, so how can you expect to be treated like one? Faxing usually involves very important, sensitive, and private information being sent in stressful times of life  filing your taxes, arranging healthcare, signing a will, etc., all still widely use faxing. You might be better off using a service which offers flexibility, security, and which treats its customers with the care they deserve. Ultimately, you get what you pay for  take a look below at a side-by-side zoom-in between the fax from GotFreeFax, and Municorns Fax App , a mainstay on the Apple business charts as the most popular and well-reviewed fax app on the app store, with a 4.85 average from over 326,000 reviews. You can see the difference in detail, and clarity of the scan  you risk losing this important quality when using a free service. Whenever you fax anything remotely important (which is anything I fax!) , using Municorn gives you the following things that free services just cant offer: On top of that, Municorns app also gives you a free test fax so that you can see for yourself. Whether youre just faxing your local congressperson using a free fax service, or sending important information via fax with a top service like Municorn, you should now know all the best ways you can start faxing today! reviews By Connor O'Grady  October 1, 2025 FaxBurner's fax app and email-to-fax offerings, low-cost model, and rare 'totally free' reviews By Connor O'Grady  August 11, 2025 iFax is a very polished and user-friendly online fax service, with lots reviews By Connor O'Grady  August 8, 2025 Humble Fax is an online fax service which offers unlimited faxing to",2620
https://nytlicensing.com/latest/trends/content-marketing-best-practices-2022/,16 Best Practices for Content Marketing in 2024 | NYTLicensing,"Brands need to be able to connect with customers digitally. The content a business produces needs to reach customers in a way that feels organic and intentional. Content marketing provides an exceptional way of doing this; a robust content marketing strategy can make all the difference between a brand that resonates with its target audience and one that has trouble with conversions. In short, content marketing helps you grow your business and tell your brands story. It is the entire process behind creating, developing, producing, sharing and distributing content to your target audience. Your content can be as versatile as youd like, from blog posts and landing page copy to podcasts, videos, infographics and social media blurbs. Content marketing can also support social media and other digital marketing efforts, such as lead generation and nurture programs. However, the content marketing landscape is a complex and competitive marketplace. While it is an effective way to drive business results and encourage conversions, a strong strategy needs to be in place to see the best results. Here are some content marketing best practices that will allow brands to tell their stories with ease. How exactly can content marketing help you meet your digital marketing goals? High-quality content marketing can help companies amplify their overall marketing strategies without putting too much of a strain on budgets. CMI found that content marketing generates three times as many leads as traditional outbound marketing but costs 62 less. Use these content marketing tips when building your content marketing strategy. In order to make your content marketing work for you, an adequate strategy will need to be established. It helps to take some time to brainstorm and think carefully about what you want from your content marketing efforts. Do you want to raise awareness about your brand as a whole, or are you looking to highlight a new product or service? Do you want to stand out as a thought leader in your industry and boost your competitive advantage? The answers to these questions will inspire your strategy and plan going forward. During your brainstorming and content ideation processes, take the time to develop achievable goals. Every piece of content you produce should be based on research  meaning similar content has had a successful track record with others. But it is essential to keep in mind that your goals need to be attainable, not far-fetched and unrealistic. Depending on your needs, some examples of content marketing goals can be:  Improve revenue  Generate great leads  Increase conversions  Boost brand awareness and authority within your industrys niche  Attract strategic partners  Enhance your customer engagement  Build rapport with both new and returning customers  Stand out within your local market Need some inspiration? Look at your competitors and other brands you admire to get some ideas for your content themes and formats. From there, create an editorial calendar to keep your content production consistent. Learning about your audience is essential in making informed decisions about what content you create for your audience. It is all about meeting their needs and digging deep into their motivations, behaviors, challenges and goals. Creating buyer personas or writing briefs can help facilitate this process. By conducting research, you will ultimately be able to create empathetic content marketing campaigns that resonate with your audience on another level. Before you start generating new content, youll want to take a look at the content you have already produced. You can use the fact that you already have content to your advantage. Take a step back to examine what is already good about your content and what you can do to improve it. For example, are you active on social media, or do you have a blog with consistent and unique content? How are they performing, and do they get any interaction from your consumers? A content audit doesnt have to be too challenging to complete, and chances are, youll already have a good idea of what is working for your brand and what is not. Additionally, sometimes you may be able to pause new content creation and instead focus on refreshing older content. A simple content refresh or optimization can help breathe a new life into an existing piece of content, instead of having to draft up something brand new. You should target all the content you produce to the specific demographic you want to reach. Remember that consumers want content theyve never seen before. So, create unique content that consumers wont be able to find anywhere else. Plus, exclusivity is key. Behind-the-scenes content, interviews with company members and product how-tos are wonderful options for standing out in the crowd. When creating your content, ask yourself the following questions:  What types of content would my ideal customer want to see? Are they looking for product tutorials, informational guides or broader thought leadership pieces?  What kind of content will inspire consumers to keep coming back? Are the customers more likely to react to videos , blog posts or podcasts?  What sets your business apart from your competitors? What makes you different?  Are there topics or content pieces I can outsource to an industry expert or thought leader? The answers to these questions will help inspire your content creation process. In the realm of content marketing, evergreen content is content that is not time-sensitive. This type of content will always stay fresh, meaning it will always be relevant for your readers. There are plenty of benefits to investing in evergreen content, including:  Providing a lot of value to audiences. The topics of evergreen content tend to stay relevant long after the initial publication date of the piece. No matter what season and year the reader finds the content, the information will be beneficial and informative.  Continuing to drive traffic to the site months and years after publishing, since the piece still sparks interest and clicks.  The ability to be updated when needed because of industry trends . This saves a lot of time for business owners in the long run, as they wont have to constantly create new content. Standard evergreen content formats include listicles, tips and tricks articles, informational how-to product videos, product reviews and videos. Although evergreen content articles provide value to readers, prospects will also want to understand industry news and trends. By curating news from valuable sources or sharing expertise from the C-suite, companies can help their readers stay ahead of big shifts in their industry. A combination of these kinds of assets will help readers navigate best practices while demonstrating how new trends or developments in technology will influence their decision-making processes. Remember that your overarching content marketing goal is to make sure you know your audience and what they want from you. Creating and curating the right mix of content requires a good understanding of the target audience and their pain points. For example, would your audience appreciate specific industry insights from trusted, third-party sources? Or would it help to put your business in perspective by incorporating news stories and photography within your cross-platform content strategy ? Personas, or detailed profiles of possible consumers, are a great tool for determining what would interest audiences. When brainstorming these personas, establish each target audiences age, demographics, interests, jobs, income and lifestyle. Since you will have many different potential consumers, youll need to have multiple audience personas. Make sure you differentiate your content, either through the topic, format and presentation or through balancing a mix of original content and licensed news articles , for each audience. This way, each persona is appropriately targeted. There are many free tools available online, such as Google Analytics , that will give you a glimpse into your websites performance. Taking a regular look into your websites content performance will help you see if your content is performing to the best of its ability, as well as guarantee that consumers can easily access it. Search engines are run by algorithms, which dictate how search engines crawl, index and present your websites information. These algorithms can change rapidly, and if your website is not technically sound, you may lose all the search engine optimization momentum youve already gained. So, its essential to use analytics to ensure that all your web pages are performing correctly. Additionally, analytics can provide insight into well-performing content topics and themes. Look at your content, and see which pieces got the most traffic, performed the best and created the most conversions. Look at which headlines got the most clicks and pay attention to the length of time readers stayed on the page. Take note of the common threads between your successful pieces of content and use this information to optimize both new and existing pieces. There is immense value in content marketing , but only if the content you create adds value to your audience. The content you are creating is paramount in answering your audiences questions and building trust. Deliver value by educating your audience through blogs, infographics, podcasts, and interviews. Creating story-driven content tends to perform better than authoritative content by positioning yourself as a curator of knowledge. Diversifying your content strategy means creating different kinds of content and expanding the types of topics and themes covered in previous assets. You are more likely to keep your audience interested if you keep things fresh. The following are great ways to expand your content: Demonstrating thought leadership starts with choosing the best content for your desired topic. If you are looking for content written by world-class writers and journalists, licensed content can help. Using licensed content takes the hard work out of creating content that you know your audience will enjoy. With licensed content, business owners will:  Save time: Curating external content will increase your output while freeing up time to devote to developing your original content , start to finish. Additionally, by getting a comprehensive copyright license , businesses won't need to waste time navigating getting copyright permission individually for articles that would interest their audiences.  Diversify content: You want to stand out online, and when you consistently publish content with varying themes and topics, you will draw your audience back to you.  Establish brand credibility: Harnessing the worldwide journalistic expertise of NYTLicensing solutions will work to help you stand out in your industry. We are all aware of how important content creation is when it comes to boosting your visibility and saving you copious amounts of time and money. Many companies do not have the time to maintain an editorial calendar that aligns with their business strategy nor one that manages to produce consistent fresh content. This is why outsourcing your content development and outsourcing your blog posts is the best way to maximize your content marketing efforts. In fact, 57 of the most successful companies in terms of content marketing are outsourcing at least some of their content efforts. Content promotion is the process of distributing content via both paid and organic channels. This may include platforms like Facebook, Instagram, Linkedin, social media, industry publications, and email marketing. The goal of content promotion is to get the content out in front of as many people as possible. A strong content promotion strategy includes a multi-channel approach that connects with audiences, generates leads, cultivates loyalty, and drives awareness. Consider leveraging social media, curated content newsletters , industry publications, and your company website. It is no secret that repurposing content is the easiest way to save time and resources, drive traffic to your brand and grow your business and brand. Repurposing content just means reusing assets and content pieces in new formats across different channels. This can include turning blogs into podcasts, turning interviews into ebooks or repurposing content with a copyright license . Repurposing content should not be overwhelming, but if it is, content licensing is the easiest way to repurpose already successful content. Showcasing industry news is a great way to establish your brand as a thought leader . Relevant news information can also help your audience make better decisions, as they navigate changes in their industry. 71 of industry leaders note that less than 50 of the thought leadership they read is delivering insights. By highlighting relevant news stories, your team can better connect with business leaders and decision-makers, who matter most to your business. However, many brands struggle to produce this kind of content regularly. With conflicting deadlines resulting from product launches or end-of-year sales goals, it can be difficult to dedicate the right team to researching industry news content, especially since most of it is time-sensitive. By partnering with reputable publications and licensing their content, your team can still showcase news and establish your brand as a thought leader with fewer resources. Since content is increasingly found behind a paywall, news curation is an effective strategy for brands to leverage. Since only 20 of Americans have a subscription to digital news, your team will be able to showcase unique content to your audience to build trust. It has now been proven that content marketing enhances your business and plays a significant role in the success of a company. It is difficult to maximize opportunities if there are no goals or strategies in place. Without proper methods of tracking progress, teams will have a harder time determining what tactics are effective and why. To successfully take advantage of content marketing, you need to set a clear attainable plan. By establishing clear content marketing goals and KPIs , your company can track insights like the number of leads, impressions, and conversions all of which will help you analyze and in turn, make informed smart decisions. Creating a content marketing plan is the key to remaining consistent in your strategy. So how do you create this plan and stay consistent? The answer: start an editorial calendar . The effectiveness and benefits of having an editorial calendar are endless. In fact, 80 of the most successful companies in content marketing are using a content calendar. As content marketing trends continue to evolve every single year, it is important for your business to stay up-to-date and relevant. 2024 will continue to push the boundaries and techniques of marketing. Lets dive into some trends you should consider leveraging as we move into the new year! Connection and building trust with potential consumers has never been harder, considering how much content is floating around on media channels, flooding social media, and overwhelming peoples inboxes. If you feel like your marketing campaigns are not resonating with your audience, you are likely to be missing empathy-based marketing . During the pandemic, AdvisorStream noted that its health and wellness articles were among its best-performing assets, although they are a financial marketing platform. Even in B2B, its important to go beyond mere personas and data to foster those connections. Trustworthiness and credibility continue to be large problems in the media ecosystem. For healthcare content marketers, this distrust is especially important. One study in Singapore showed that misinformation led to people regularly rinsing their noses with saline and garlic to combat the COVID-19 pandemic, instead of the regulations related to social distancing. Additionally, in another survey, 36 of patients noted that they do not trust pharmaceutical companies. Due to the circulation and impact of misinformation and the lack of consumer trust, content marketers must be hyper-vigilant that their content is accurate and credible. Video content marketing continues to be a great marketing format that helps drive your message and tone forward. High-quality video content helps you tell a story with visuals while developing a connection with your customers. Video allows businesses to show off their products and services with customer testimonials, product demonstrations, and behind-the-scenes footage content. 75 of the companies semRush surveyed are conducting a content audit once a year. 65 of those that are most successful are conducting these audits at least twice a year. For companies looking to outpace their competition, its important to regularly monitor content performance, track goals, and audit performance. Your team should then adjust its approach based on your teams findings. The above best practices will ensure that your content works for  not against  you. With some consistency and time, these tips will amplify your brand and improve your content marketing efforts , which will help with customer conversions, leading you to ultimately grow your business . Effective content marketing advertising normally includes relevancy, consistency, and authenticity. To be relevant, the content must be tailored to meet the specific audiences needs. Second, content must be consistent to create a reliable presence for marketers. Lastly, authentic content helps build genuine followers and helps customers connect on a personal level with a brand. Creating a framework for your content strategy establishes a game plan for content goals, plans for content distribution, understanding the target audience, and following branding guidelines. We and our vendors use cookies and similar methods to recognize visitors and remember their preferences, for analytics, to measure our marketing effectiveness and to target and measure the effectiveness of ads, among other things. To learn more about these methods, view our Cookie Policy and Privacy Policy . By clicking 'Accept all,' you consent to the processing of your data by us and our vendors using the above methods. You can always change your preferences by clicking on Manage Privacy Preferences in the footer of nytimes.com or in your app Privacy Settings. Your preferences here are unrelated to Apple's App Tracking Transparency Framework.",2893
https://copyblogger.com/content-marketing/,The Complete Content Marketing Guide For 2025 - Copyblogger,"Content marketing is an excellent strategy to make potential customers aware of your brand. The content in content marketing could be a video, blog post, podcast, or social media post. As most potential customers often do some preliminary research before purchasing products or services, theyll likely find your content before making a purchase decision. If your content is helpful, those potential customers are more likely to trust your brand and buy your products or services when theyre ready to make a purchase. The problem is that not all content marketing strategies are equally effective. You need to know what problems your potential customers are searching, what makes a piece of content convert, which content platforms theyre using, and how to work with platform algorithms to get in front of your potential customers. To help you implement an effective content marketing strategy, heres a complete content marketing guide for 2024. Specifically, youll learn: Our Academy only costs one dollar to join for your first month. That means you can give it a try and learn a ton with zero risk. It was already the best place on the internet to learn content, copywriting, and online sales. Now its extremely affordable to get in. Well make it 300 eventually, so get in at a dollar while you still can. Content marketing is a form of inbound marketing that attracts users to your brand by providing useful or entertaining content  usually in the form of text, video, or audio. Content marketing is valuable to companies because it helps them build relationships and trust with their potential customers and existing customers at scale. As a result, its easier to sell your products faster. The ROI of content is notoriously difficult to measure as its often just one step in the customer journey, but brands with strong content marketing strategies tend to have lower customer acquisition costs and generate compounding returns. Content marketing also has a snowball effect, as those who use content marketing to build an audience see higher returns for each additional piece of content they publish. Effective content marketing attracts people to your brand. You might publish a video, podcast episode, or blog post, and then people interested in the topic consume it and become acquainted with your brand voice . Once you have that persons attention, you can build a trusting relationship with them. As a result, you can sell them products and services. If youre looking for content marketing and SEO services , check out Copybloggers agency Digital Commerce Partners . We specialize in delivering targeted organic traffic for profitable businesses. Companies with excellent content marketing strategies have an unfair advantage over their competitors for several reasons. Below well discuss just a few of them. Quality content creation isnt cheap, but youll see a stronger ROI from each piece of content you produce because your audience will grow. Its a snowball effect. The first video, blog post, or social media post you publish might only be seen by a few people, but as more and more people find your content and become followers, each sequential piece of content you publish will be seen by more people and produce a stronger ROI. So unlike paid ads, where you and your competitors can earn roughly the same ROI for each dollar spent, brands with strong content marketing strategies and a large audience can earn significantly more for each piece of content published. Another benefit of content marketing is that you can filter the type of customers you attract based on the content you produce. For example, if your target audience is exclusively CMOs, you can discuss only topics that a CMO would be interested in, like hiring great talent. You might also offer access to exclusive reports on industry benchmarks that would interest a CMO. In contrast, paid ads force you to rely on the platforms to accurately identify your target audience. With privacy concerns on the rise and less accurate audience targeting, these platforms are producing lower returns. Content marketing has a flywheel effect and produces higher returns over time  especially if you produce evergreen content. With evergreen content (content that is relevant for years), you can continue to generate returns from it even years after it was published. So even if you stop producing content for a period of time, youll still likely have a steady pipeline of leads thanks to your evergreen content. Content marketing is essentially a cheat code to build trust with your potential customers at scale. The more they become familiar with your brands viewpoints and identity, the easier it is to trust your brand and the more likely they are to continue purchasing from your brand. Content marketing can be any type of media across a variety of platforms, though the most common forms of content marketing include: Below well discuss each of these types of content in detail and when you should use them. Blog posts are the bread and butter of the content marketing strategy for most B2B and even many B2C companies and local businesses. Blogging is valuable because it can help you rank in search engines for keywords that your ideal customers may search. For example, if you sell CRO software, ranking first in Google for the term best CRO software will help you drive valuable leads because those searchers are clearly looking to purchase a product like yours. The process of optimizing blog posts to rank at the top of Google is called SEO (search engine optimization) . While blog posts are excellent at generating organic traffic to your website, effective marketers know that they need to also provide a next step to move the visitor through the buyer journey and eventually convert them into a customer. Check out our guide to simple SEO and content marketing. Therefore, savvy content marketers often include a call to action in the blog posts to download a lead magnet, like a white paper or research study, in exchange for their email address. Once you have a website visitors email address, you can retarget them with other valuable content to move them through your marketing funnel. Another major benefit of long-form content like blog posts is that they often produce compounding results (assuming the content is evergreen or updated every few years). Social media content is excellent for generating brand awareness, and many brands (particularly those in the B2C space) rely heavily on social media for audience building. Social media marketing is also becoming increasingly popular among B2B brands as more and more people turn to individual thought leaders for professional advice and industry news. LinkedIns revenue alone is an excellent reflection of the rise of B2B social media, as the platform grew 26.2 in 2022 to 14.5 billion  the highest percentage of growth it has seen in the past three years. The benefit of social media marketing is that you can develop relationships with your audience much more quickly, as its a very personal form of content marketing. The downside is that social media content isnt evergreen, and the key to winning with social media marketing often comes down to publishing a high volume of high-quality content. This can be tricky as its important to publish high-quality content readers want to consume. Video content is also becoming increasingly common in B2B and B2C content marketing strategies, as its now easier than ever to record a high-quality video on even a simple iPhone. Its also easier to quickly build a relationship with your audience if they can see and hear you, which is likely because body language makes it easier to trust a person. Video content is also excellent for content repurposing, as you can turn a single video into podcast episodes, social media clips, emails, or blog posts. The downside with video content is that the best video content usually features a person, so it might not be a great option if there isnt anyone within the company who enjoys being on camera. In addition, the person on camera will likely become the face of the brand. If that person later leaves the company, the audience might leave as well. There are more podcast listeners (and podcasters) than ever before. But even with the competition, starting a podcast is an effective way to grow your audience . When people hear your voice and stories repeatedly, its easy to quickly build a deeply loyal following. Podcasts also have very high retention as, unlike other forms of content marketing, the audience can passively consume your content. So, unlike videos or blog posts that require the listeners undivided attention, they might multitask while listening to your podcast. Your podcast will also likely become part of that persons routine, which makes the audience even stickier. For example, they might always listen to your podcast while driving to work or working out at the gym. Like video content, the downside of podcast content is that youll likely lose your audience if the podcast host decides to leave your company. Email marketing is arguably one of the best content formats because its the only platform you own entirely. Email marketing is also an essential part of e-commerce performance marketing . For example, a social media platform might change its algorithm, causing you to lose access to your audience, or a Google algorithm update could cause your blog content to drop in the search results, and youll lose organic traffic. However, after someone gives you their email address, you own that list and can retarget them until they unsubscribe because you arent at the mercy of a platform. Another benefit of email marketing is that the people on your email list have demonstrated interest in your company by giving you their email addresses, making them higher-quality prospects. Many content marketing efforts fail because they lack a solid content marketing strategy to attract the right prospects and nurture them through the buyer journey. If you randomly begin publishing content on different platforms without a thoughtful approach to which channels youll focus on, how youll position your brand, and how each piece of content moves the customer through the user journey, youll likely be disappointed by the ROI from your content marketing efforts. To solve these problems, heres a step-by-step approach to creating a successful content marketing strategy . Content marketing only works if you attract the right customer. Otherwise, youll have low conversion rates or convert customers who are a poor fit for your product or service, creating unnecessary customer support headaches and high churn. To identify your ideal target customer, ask yourself these questions: Once you answer those questions, youll have a good sense of your ideal buyer persona, and the rest of your content strategy will become clear. Most customers dont make a purchase the first time they visit your website, and thats okay. Content marketing aims to build a relationship with prospects to eventually lead them to make a purchase. There are several stages of the content marketing funnel, from awareness (the customer is just learning about the pain point and potential solutions) to the purchase decision phase (the customer is solution aware and ready to purchase a product to solve the pain point). Source For example, if your product automates accounting processes, heres what the customer journey might look like: Creating content for each of these phases of the customers research process is important so that you can lead them through the funnel to ultimately purchase your product or service. If you pitch your product too soon, you can lose trust. Yet if you never pitch your product, theyll never convert. Youll also notice that this marketing funnel has multiple different content formats. So how do you choose the best content format for your marketing funnel? It comes down to two variables: Some audiences gravitate more towards specific platforms than others. For example, most people dont go to TikTok to hire a lawyer or marketing agency. However, TikTok would be an excellent place to sell beauty products. The good news is that you can quickly identify the most effective platforms by analyzing your competitors platforms. Even if you know that all of your competitors are producing video content, dont try to create video content unless you know you can consistently publish high-quality video content. The key to winning with content marketing is consistency, so selecting a form of content you enjoy is important. Now that you know what content youll produce, you can map out the top, middle, and bottom-of-funnel content. Its also worth noting that you dont necessarily need a different form of content for each funnel stage. For example, you can create TOFU, MOFU, and BOFU content with just blog posts. The reason its important to map out your marketing funnel at this stage is to ensure you have a clear call to action at each step to move the visitor forward in the buyer journey. An effective content marketing plan is about more than just mapping out the types of content that it will take to produce. You have to actually have something unique and interesting to say to get people to pay attention to your content. So the next step is to figure out how to consistently generate content ideas that are unique and appealing to your ideal audience. We created an entire blog post on generating content ideas , but a simple framework you can use to consistently curate interesting content ideas is this: With the rise of AI writers flooding social platforms with me-too content, thought leadership content with a unique and contrarian viewpoint will continue to stand out, and youll actually find it easier to build an audience. So before you publish any content, ask: If you cant authentically say yes to both of those questions, dont publish the content. If you consistently publish content with an authentic brand voice and dont regurgitate the same ideas that have already been published, youll gain trust much more quickly, as people will look to you as an industry leader. Your content marketing strategy will only scale if you publish new content consistently. In fact, the formula for a great content marketing strategy is pretty simple: If you do these three things, youll find that your content marketing strategy is highly effective. The problem is that most people give up too quickly or dont publish consistently. As a result, the audience you build forgets about your content and youll have to restart the relationship from zero. The good news is that implementing a simple content calendar and workflow process can reduce inconsistencies. To get started, adopt a project management platform, like Trello , Basecamp , or Asana , and then break down each content marketing campaign into various tasks that you can assign to your marketing team members with due dates. Heres a great sample editorial calendar in Trello: Once youve created a workflow process, its pretty easy to then ensure each piece of content is published consistently. The final step is to measure your results. This is tricky as content marketing is a long-term play, and you probably wont see any immediate returns on your investment. However, some early content marketing metrics you can track to make sure your strategy is heading in the right direction include: In addition to tracking these general brand KPIs, be sure to also track specific campaigns so that you can assess what content performed the best and double down on producing more of those content formats and ideas. Most marketers track the majority of their content marketing efforts in Google Analytics, though you can also use third-party tools like SEMrush or Ahrefs to measure these metrics. The content marketing strategy established above is the process you need to get an effective content marketing program off the ground. Once you have established systems and processes in place, here are a few more advanced content marketing tips to consider. Audience research is important, but instead of just observing them from afar, interact with potential customers to learn more about their pain points and build genuine relationships. You can do this by joining Slack groups, Facebook groups, and other online communities to learn about the pain points these people face. For example, if you sell to Airbnb hosts, this might be a great community to join. While you shouldnt sell your products or services in these groups, you can answer questions and use members questions as inspiration for new content ideas. While content marketing should educate potential customers, it also does need to sell them at some point  otherwise it wont be a profitable marketing strategy. The good news is that there is a way to tastefully pitch your product or service. Heres an excellent example. This blog post targets the keyword how to create an online course and the brand that published this blog post, LearnWorlds, is an online course platform. As you can see, one of the steps is learning where to host your course. They first provide several options such as self hosting and online course marketplaces: Then, they provide a third option, which is using an online course platform like LearnWorlds. Then, they explain how it works and specific features that you should know about. For someone executing the steps of creating an online course, this is helpful information and can drive conversions for the brand. The key to tastefully pitching your productservice is: Most businesses dont have the capacity to produce unique content for YouTube, social media, the blog, and a podcast. The good news is that you dont have to create unique content for each platform. Content repurposing allows you to take one piece of content and rework it into different platforms. For example, if you have a long form video, you can take clips from it to post on social media and hire a writer to rework the video transcript into a blog post. This is a great example of content repurposing from the Pilot Institute. They published this video: Then they converted it into a blog post: They also occasionally repurpose clips from their videos on Instagram : This allows you to reach more people as each potential customer has their own platform preferences. The key is to make sure that each piece of content is formatted to the platform. For example, hire a writer to rework the transcript into a blog post rather than just publishing it as a plain transcript. Additionally, you can see that the clips posted on Instagram from the Pilot Institute are well optimized for the Instagram platform as each one has subtitles and the clips themselves are cut well for social media with each scene only lasting a second or two. Many content marketers are excellent at attracting their ideal audience, though far fewer know how to keep them engaged and eventually convert those visitors into customers. Unfortunately, if your customers never convert, your content marketing wont be effective. To solve this problem, include a helpful resource, like a cheat sheet or a template that the audience can download. Then, ask for their email address in exchange for the free download. Once you have their email address, you can send them a nurture email sequence to continue remarketing to them and eventually convert them into a customer. HubSpot is a master at capturing leads. For example, they have a guide on conversion rate optimization and then offer a CTA to download a CRO planning kit: When you click on Download the free planner, they ask for your email address. Once they have your email, they can remarket to you through email and eventually convert you into a customer. We already mentioned that analyzing your competitors content marketing strategies is a great way to get a basic understanding of what types of content and topics resonate with your audience. However, a pro content marketing tip is to analyze your competitors ads and use them as inspiration for your organic content marketing strategy. Specifically, look at your competitors longest running ads as those are probably generating the most sales (otherwise, they would have stopped running them). To track your competitors ads, you can use a paid tool like Ahrefs and look at the keywords theyre paying to rank for. These are all excellent keywords to write SEO content for: You can also look at the Meta Ads library to analyze your competitors ads. It also tells you how long the ad has been running for, so take note of the ones that have been running the longest. LinkedIn also has an ads library you can use to track your competitors ads: For the first time, were bringing the Copyblogger methodology to clients. As the agencyproduction arm of content marketing pioneer Copyblogger, Digital Commerce Partners works with you to deliver the prospects you need to succeed. We build profitable digital commerce products and businesses for ourselves and those we work with. For us, providing content marketing and SEO services to clients was the last step, not the first. Lets explore how we can help your business win . To inspire your content marketing strategy, here are a few excellent examples of outstanding content marketing. As one of the most popular SEO tools on the market, its no surprise that Ahrefs has plenty of in-depth blog posts with actionable information. From their detailed beginners guides to more specific blog posts around advanced SEO topics, they always deliver original ideas with thought leadership authority. Heres an example of an original research blog post they wrote on how long it takes to rank in Google: They also tastefully pitch their product in many blog posts by showing readers how to use it to actionably solve the keyword theyre searching for with the product. Source While blog content isnt typically a go-to form of content marketing in B2C, it can be an excellent tool for any product where education is necessary before the customer purchases. The company Levels is a glucose monitor that does an excellent job of creating helpful and authoritative advice about glucose and healthcare. They do a great job of breaking down complex topics and have doctors and other authorities writeedit the posts to ensure they provide accurate information. Source So even if youre in the B2C market, blog content might be a viable option depending on the customer journey. Case Study: Heres how we help ADD.org reach 114,548 more people per month (in a hyper-competitive market)using content marketing . GoPro is one of very few companies that expertly leverages user-generated content. Rather than just creating content themselves, they consistently run social media contests where users can submit their own content recorded on a GoPro to win a new GoPro. This kind of content performs incredibly well because, rather than just sharing a branded post, contestants share their best social media content with the GoPro hashtag. As the content itself is already the creators very best work, it naturally earns tons of engagement, which multiplies the reach of the GoPro hashtag. Source While GoPro has an advantage as their audience is mostly creators, any brand can use the contest blueprint. Instead of asking contestants to share a branded post, ask them to create their own content. B2B brands are beginning to realize that the best way to win on social media is to boost the executives presence. Justin Welsh is an excellent example of a B2B influencer who has amassed a substantial following by consistently publishing high quality content on Twitter and LinkedIn. In fact, he now has an entire course on his process and the heart of his strategy is: Even if youre a member of the marketing team and trying to discover methods to level up the companys brand awareness, building your own social media presence or the social media presence of executives is a great way to then communicate the brands messages to a loyal audience. Most B2B brands assume that creating a video content marketing strategy means you must produce YouTube video content. However, Ocho is an excellent example of a brand that creates full video courses for its customers. They also collaborate with other industry influencers to create adjacent courses. For example, they collaborated with angel investors, tax strategists, and other experts who then helped them promote the content. This is an interesting YouTube channel that covers everything you could possibly want to know about Disney. Unlike most consumer YouTube channels that show off the creators personal life, the host, AJ, never even shows her face on the channel and instead provides detailed descriptions of her experiences at various Disney restaurants, theme parks, and hotels. She even has a team of people who go to various Disney locations to try out different foods and rides and then report back to her to deliver authoritative content for the YouTube channel. Its an outstanding collection of truly expert insider tips that you cant find elsewhere, and its packaged in well-organized videos (theres usually a list of tips or rankings for each topic covered) that she narrates. Source This is also a very scalable business model as she doesnt have to personally show her face or test out the various theme park amenities herself. My First Million is a B2B podcast hosted by Sam Parr and Shaan Puri, both of whom have successfully built and sold multi-million dollar companies. However, the podcast is popular not just because theyre successful entrepreneurs, but because they deliver unique perspectives through entertaining stories that most people have never heard of before. With over 100,000 listeners, its one of the top business podcasts, but its actually owned by the HubSpot podcast network. So even if youre a B2B brand, you can elevate some of your executives to start a podcast and then use the ad space to promote your own company. This is a popular consumer podcast about relationships and dating that has succeeded largely thanks to the hosts entertaining stories about their personal experiences. They also have interesting guests on the podcast, though its their raw authentic stories that seem to keep the audience hooked. So if you have a podcast and are talking to a consumer audience, the best way to build trust and remain entertaining is sharing your own personal stories and being vulnerable about past experiences and challenges. Danny Miranda The Danny Miranda Show is only a few years old, though Danny has interviewed some of the biggest content creators podcasters on the scene, including Gary Vaynerchuck, Alex Hormozi, and others. He also recently sat down with the team at Copyblogger to discuss how to grow a successful podcast . While video and audio content is on the rise, text based content is still very popular and is still critical for blog writing, email marketing, and even a lot of social media content. So while there is a difference between copywriting and content marketing , many copywriters are content marketers and its a valuable skill to acquire. Therefore, learning how to be a copywriter is one of the fastest and most effective ways to improve the results of your content marketing. Its the difference between a reader getting bored or frantically sharing your content with everyone they know. Theres no way Ill be able to cover everything you need to know about copywriting in this blog post. Its simply too broad and deep of a topic. However, I can share some of the essential elements of good copy that you can use to start improving your content right away. Good copywriters know that headline writing is important. Great writers obsess over their headlines. Its the one thing that determines whether or not your content gets read. You could have the most incredible content in the world, but if your headline is boring or weak, it wont matter. A good headline is clear, specific, and intriguing. It should both tell the reader what to expect while also teasing them about whats inside. Your headline should also qualify your reader, meaning that it should attract your target audience. If its too vague, a reader will start reading  thinking that the article applies to them  only to discover it has nothing to do with them. Theyll feel tricked. This is critical. You arent just trying to get anyone and everyone to click to read your article. That becomes meaningless. You want the right person reading your article, someone who you know will get value from it. So spend the extra minutes, hours, even days getting your headline right. Copywriting is all about understanding the emotional and psychological state of the reader. You have to be able to get inside their heads and join the conversation. One way to do this is to write to someone very specific. This could be an avatar of your ideal customer that youve created, or it could be a real person who fits the bill of your target audience. Either way, picture this person as you write. What do they struggle with? What are there experiences? How would you talk to them if you were sitting on the couch at a coffee shop together? Once youre clear on that, write to them. Ignore all of your professionalism and grammar rules. Just write like youre there at the coffee shop with them, or like youre writing an email to them. Your writing will become more personal and youll form stronger connections with your readers, which is key to building a loyal audience . They will feel like youre talking right to them because you are, to some extent. Thats the kind of writing your audience will read, share, and buy from. One of the cardinal sins of copywriting is too much complexity that makes your message confusing. Good copy is all about breaking things down so that your reader can easily and quickly understand what youre talking about. This means not using complicated words, insider speak, technical jargon, and long, perfectly structured sentences. Thats like a death warrant for your copy. Instead, break up your sentences. State your point simply. Find the easiest, simplest way to say what youre trying to say. Otherwise, your reader will have to work hard to sift through what youre writing and get confused. As a result, they dont do anything. They dont read, they dont share, they dont buy, nothing. Thats not what you want. So keep your writing simple and to-the-point. Hopefully you can see the value of content marketing, but if you want some additional proof that its one of the most effective long term marketing strategies, here are some statistics. Yes, content marketing is effective as about 62 of B2B buyers will read at least 3-7 pieces of content before theyll agree to talk to a salesperson, making content marketing essential for your marketing funnel. About 73 of B2B marketers and 70 of B2C marketers incorporate content marketing into their overall digital marketing strategies. Content marketing costs range, but about 39 of companies spend between 1,000 and 5,000 per month on content marketing, 33 spend over 5,000 per month on content marketing, and about 27 spend less than 1,000 per month on content marketing. A recent study by SEMrush broke it down: In addition, most companies (69) increased their content marketing budgets in 2023, while only 3 planned to decrease spend. According to data from Statista, the most popular social media platform is Facebook, with over 2.9 billion monthly active users . YouTube is the second most popular social media platform with over 2.5 billion monthly active users . Surveys show that about 93 of marketers worldwide use social media marketing in their businesss marketing strategy. According to statistics from SEMrush , the most popular form of content promotion is publishing organic social media content (73). Heres a full breakdown of the most popular content promotion strategies: Studies show that 91 of companies use video marketing in their marketing strategies, which is the highest its ever been! Yes, about 77 of internet users still actively read blog content. Statistics show that 61.4 of marketers have used AI in at least one of their marketing campaigns, and 44.4 have used AI to aid their content creation process. Source For those who are not yet using AI, a lack of understanding of AI (41.9) was cited as the top reason for not incorporating it into their workflow. Paid costs continue to rise, and as targeting becomes less accurate due to privacy concerns, the ROI of paid ads will likely continue to decline. Therefore, its likely that more and more companies will invest in content marketing. In addition, the introduction of artificial intelligence, from AI content writing tools to AI video editing tools, has made it easier than ever before for any company to increase its content output. As the volume of content increases, B2B and B2C content consumers gravitate more toward content that reflects personal experiences and unique and original ideas. Therefore, its likely that individual content creators will be critical to any brands content marketing strategy over the next several years. If you want to be one of the creators at the forefront of content marketing, consider joining the Copyblogger Academy .",5523
https://www.twilio.com/en-us/blog/insights/content-marketing-best-practices,40+ Content Marketing Best Practices in 2025 | Twilio,"Time to read: Content marketing best practices don't change too much from year to year, but it's always a good idea to check in every once in a while. Sticking to tried-and-true tips and tactics will help maximize your time, efficiency, and outputit's worth a 5-minute read. Content marketingit's like trying to stand out at a rock concert while everyone else is shouting just as loud as you are. With millions of blog posts, videos, and social media updates flooding the internet daily, how do you make sure your content cuts through the noise? Well, by following the latest-and-greatest content marketing best practices (of course). Plus, we've collected all the tips and tactics into a single (downloadable) content marketing best practices checklist. You can find it at the bottom of this post, but resist the urge to skip to the endyou'll get the most benefit from digging in top-down. Before we get into the content marketing best practices, let's get on the same page about why all this matters. Content marketing isn't too complicated, right? Create content, and people will come to consume it. Not quite. Take a look at these statistics: Mind-boggling, right? With all that new content emerging daily, how in the world will your audience find your contentand why should they? You have something special to share: something your audience needs. However, they'll never find it if you don't follow the content marketing best practices outlined below. Here are a few ways content marketing best practices help improve your overall content program: While these content marketing best practices aren't necessarily in order of importance, its best to follow them sequentially. Start at the top and work your way down. Content marketing starts with your audience. Start somewhere else, and you're destined to build amazing things that nobody wantsCheetos lip balm, anyone? First, choose the buyer persona you want to target. Don't have that yet? Start with lead nurturing and the customer lifecycle . Your content strategies might target different audiences and buyer persona, and that's OK. Just ensure you have a specific reader in mind when writing an article. Take this blog post, for example. Twilio SendGrid caters to marketers and developers . However, developers don't care much about content marketing best practicesthat's why I wrote this for you, marketers. You likely have a fictional customer journey in mind for your customers: the customer reads your tweet, laughs, follows your brand, sees more content, then buys your product. In reality, it's rarely that straightforward (or linear). Customer journey mapping helps you learn the real path your buyers take, from becoming completely unaware to brand ambassadors of your products. Plus, customer journeys tend to follow the same stages: Understanding what each stage looks like for your customers will help you make optimizations to improve it. Don't have a customer journey yet? Follow our how-to guide to get started . Without a well-defined content marketing strategy, you're just throwing darts at the board and hoping something sticks. While that can score you some short-term wins, it's not a recipe for long-term success. Successful content marketing campaigns start with a plan. You need a reliable, scalable strategy you can trust. And a solid content marketing plan ensures that every piece of content has a purpose and that every purpose aligns with a greater organizational goal. Read How to Create a Content Marketing Strategy in 11 Steps to start building your plan. Top-notch content requires a world-class team, so focus on building a flexible, resilient content marketing team. Find folks with a wide variety of specialties: Don't be afraid to find freelancers and contractors to supplement your content needs. They can be great at filling skill gaps or keeping up with fluctuating demand. From the get-gonot lateryou need to decide what business goals will be crucial to your team. You can't do everything, so get hyper-focused on a handful of metrics you want to tackle: Ensure your content aligns with your marketing goalsnot the other way around. For example, content teams often make the mistake of coming up with ""good ideas"" before creating goals. This leads to amazing content that nobody wants or results your business doesn't need (or care about). Before you start thinking of new content you want to create, take a look at your existing library. You'll likely find heaps of great articles, videos, and graphics that just need a bit of tender loving care to perform well. For example, you might find a 3,000-word blog post getting little-to-no traffic. Identify keywords it might rank for on page 2 or 3 of Google's search engine results pages (SERPs), and optimize it to try and rank for page 1. It'll take you 10 of the time of creating a new pieceand itll start ranking faster too. While auditing your existing content library, look for gaps. What potential topics have you not covered yet? Do competitors create content you don't have? Understanding your content gaps gives you an excellent place to start when researching new pieces. For example, do you lack how-to tutorials for your products? Do you need a starter video for the onboarding process? You can likely repurpose every piece of content you create. Whether an article, video, or podcast, there are dozens of ways you can repurpose your content in different formats. Let's take a podcast, for example. Here are a few ways you could repurpose a podcast episode: Need more ways to repurpose content? We've got 20 of them. Check out 20 Simple Ways to Repurpose Content to Boost Your Traffic . Every piece of content you create can be multipurpose. For example, you might create a product-focused blog post about a new feature you're releasing. That's fineyour current audience will love that. However, you'll likely need to optimize this piece for search engines if you ever want anyone outside your existing customers to learn about it. Get comfortable doing basic keyword research and finding your users' search queries. Basic SEO best practices can take your content the extra mile. Sometimes, content teams get stuck in a rut of producing the same content, whether blog posts, guides, or social media campaigns. Think outside the box and branch out. There's a whole wide world of content opportunities experiment every once in a while to see if something clicks. Here's a quick list of different content formats you could produce: Your site's backlinks and domain authority will impact how well it ranks on SERPs. Fortunately, content creation and backlink building go hand in hand. Look for ways to use content to create high-quality backlinks. Here are a few content-creation strategies for building backlinks: When you find something that works, scale it. For example, if you have a handful of articles that outperform all the rest (which is often the case), decipher any similarities and what makes them perform well. Do the articles follow a certain format? Does the writing center on specific topics? Once you find the keys to success, turn them into a replicable template . For example, you might discover listicles perform best on your website or find top-of-funnel ""what is"" content works best. Scale your successes and juice them for all you can. A content calendar (or even an editorial calendar) will keep your content production and publishing schedule on track. Managing handfuls of writers and projects simultaneously can get messyespecially if you don't use a task management system. Without a content calendar, you'll end up with some weeks where you publish an overwhelming amount of content and others that experience content droughts. You want consistency. A content calendar ensures every new piece of content gets the time and space it deserves. That means you might publish 1 piece every day or 2 a week. Use a content calendar to stick to whatever cadence you decide on. You want the content you create to solve problems. Think about questions your customers might have or issues your products help solve. Once you identify the pain point, solve it with content. Your solution might not always be the primary answer, and that's OK. For example, if you sell fitness equipment, you might create motivational content to inspire your community to work out. Or if you sell email services, you might create content marketing best practice articles to help your customers understand how email works together with content marketing. See what I did there? Content teams get pressured to create, create, create. With a never-ending to-do list, getting pulled into the publish, publish, publish mindset is easy. However, it's vital to take a step back every once in a while and ask: Questions like these will help you discover if your content is valuable or just busy work. Frequency isn't so much about quality over quantity (though we'll get into that soon). Its more about how often you publish on different channels. More (even if it's quality) isn't always better. For example, your customers might love your monthly email newsletter, but that doesn't mean they'd love it more as a weekly newsletter. The same goes with any medium. Just because you can publish a YouTube video every day doesn't mean you should. Your audience leads busy lives. They have work, family, and personal ambitions to go after. Keep that in mind when you produce content. Don't overwhelm your customers to the point where they can't consume all your content (even if they want to). Believe it or not, not everyone wants to consume your content. Shocking, right? Yet, they won't always get to choose, especially when you use traditional media, video advertisements, or pay-per-click ads to get in front of them. However, on channels they do get to choose, ensure you get permission before marketing to them. For example, email and SMS are opt-in marketing channels. Just because you have your customer's email address from a purchase order or delivery update request doesn't mean you have permission to send them marketing messages. They need to give you "" unambiguous consent ."" Follow these opt-in options to learn more about getting subscribers (the right way). Also, brush up on General Data Protection Regulation (GDPR) laws to ensure your email program is compliant. Content marketing is an ever-changing field. Trends come and go, algorithms change, and new channels flare up and perish months later. It's up to you to stay on top of things to capitalize on shifts. I remember when I started listening to podcasts about 8 years ago. Even then, I thought I had already missed the podcast bandwagonand look where we are now. Even if it doesn't go according to plan, dont be afraid to try a new tactic and channelit's a learning experience. Plus, it's a solid excuse to secure your brand's name and tag on possible digital channels. You might think a channel might not align with your brand, but you'd be surprised. Just about any company can find success on platforms ranging from Instagram to TikTok to Reddit. There's a good chance your audience uses these different platforms, and that means there's an opportunity for you to reach them there. The challenge comes from creating relevant content for each channel that your audience wants . That's no small feat (and definitely beyond the scope of this article). Here are a few channels to consider experimenting with (if you haven't already): Good content doesn't get the love it deserves if the user experience (UX) suffers. Everything from your site's user interface (UI) to the page's color scheme to accessibility concerns can impact the user experience, and it's a shame when these elements destroy quality content. Work with your UIUX team to improve these factors on your website. Test how different layouts affect bounce rates and completion rates. Then, keep working to improve your content's experience to increase the likelihood that customers consume, enjoy, and share it. I told you we'd get here eventually. When it comes to content, quality is always better than quantity. Often, you don't need 5 small blog postsyou just need one big comprehensive one. The same is true for almost all content you produce. Don't worry about how much of it you createinstead, measure each piece's impact. Push back against management if they set content creation goals. Content creation isn't your end goalit's results. And who cares if you drive results with 3 videos or 15 videos? While its cool to jump on new trends, never forget about evergreen content. Evergreen content is always relevant. It might not get increased attention or features in headlines, but it's something your audience will always want. Let's look at email, for example. Right now, everyone cares about artificial intelligence (AI) assisting with email creation. That's fine and relevant, but do you know what email marketers will always search for? Interest in topics like AI-based email marketing and Brand Indicators for Message Identification (BIMI) will rise and fall, but evergreen topics will always be important to your community. You can stretch the life of every piece of content you produce by looking for ways to combine it with other content types. For example, you might mix and match your content by adding a video to a blog post or using a new e-book in a webinar presentation. Its always best not to make claims unless you can back them up with data. For example, I can't just say email marketing is the best distribution channel without also including a statistic like, ""Email marketing produces a high return on investment with a 38 return on every dollar spent ."" Look for any claims you make in your writing, and find data to support them. Dig deep down the research rabbit hole to ensure it's an accurate, legit statistic and not a regurgitated hoax without any original research. Ideally, before you create it, connect every piece of content to a specific business goal. Will this content drive traffic or help build leads? Do we want this content to build brand awareness or drive sales? If you can't find a business goal to support your desired content, put it in the backlog. You might find a purpose for that content idea later, but stick with content creation that supports your immediate KPIs and metrics. AI writers and graphic generators are emerging. These tools can help create original content, build outlines, answer questions, and write articles. However, these are still in the infancy stage, and you should avoid over-relying on them. Don't be afraid to use AIjust don't abuse it. Let it inspire and give you ideas, but don't think it can replace your content marketing team. It can't. Need ideas for using AI? Try these AI-based email marketing use cases . It's easy for your content marketing team to become a silo. With so much going on and never-ending demand for content, collaboration often gets pushed aside. Think of teams you could partner with to bolster your effective content marketing efforts. For example, you might work with product marketing or sales to identify content to support their needs or get help from your developers to write more technical-focused content. Old content can start to pile up. While often a vanity metric, lots of underperforming, outdated content just takes up space and accumulates cobwebs. If you cant revive, optimize, or repurpose a piece, it's time to get rid of it. It'll be hard. You might tear up a bit, and that's OK. If you can't do it yourself, work with a partner who can identify content pieces that need to go objectively. You can do this. We believe in you. The 8020 content rule suggests you spend: When you publish new content, give it the promotional love it deserves. Just because you post something doesn't mean your audience will read or watch itthey likely won't know it exists. Use the following promotional channels to distribute every piece of content you produce better: Around 1.3 billion people live with some visual impairmentthat could be a massive part of your audience. And even if it's not, creating accessible content is just the right thing to do. Think about accessibility design best practices , and ensure you add the small touches that make your content widely consumable. For example, add descriptive alt text to your images, and consider providing American Sign Language (ASL) interpretation online when hosting virtual events . ""Hey Alexa, how do I optimize my content for voice search?"" Voice search isn't just coming...it's already here, and it's changing how people find your content. With smart speakers in millions of homes and voice assistants built into virtually every smartphone, optimizing for voice search isn't negotiable anymore. Voice searches are fundamentally different from typed queries. They're conversational, question-based, and typically longer. When someone types, they might search ""best email marketing platform."" But when they speak, it becomes ""What's the best email marketing platform for small businesses?"" Here's how to make your content voice-search friendly: Gone are the days when content was just a one-way street. Static content? Boring. Today's audience doesn't want to just read your stuff. They want to play with it, manipulate it, and make it their own. Interactive content flat-out performs better. Quizzes, calculators, polls, and interactive infographics don't just capture attention; they hold it hostage (in the best possible way, of course). Think about it: Which would you rather consume: a 2,000-word article about email deliverability rates or an interactive tool that analyzes your specific sending patterns and gives you personalized recommendations? Yeah, me too. Create calulators, add quizzes, ask for feedback, enable comments, incorporate sliders and toggles. This is where you go all in on whozits, whatzsits, and thingamabobs. Your blog has some deadweight. It doesn't take an SEO expert or outside consultant to see that. Don't panic, though. You're not alone. We all get to that point sometimes, and it's okay. Well, as long as you do something about it, that is. For example, we've deleted, archived, and redirected hundreds of blog posts over the last year or so (and we plan to do a lot more). Yes, the vanity metric of number of posts surely takes a hit, but you know what doesn't? Our traffic. Now, you know those posts: the ones gathering digital dust in the corners of your site, bringing down your averages, and making Google question your content quality. It's time for some tough love. By removing underperforming content, you're actually helping your best stuff rank higher. Think of it like thinning out seedlings to let the strongest plants thrive. The 8020 rule applies perfectly here: roughly 20 of your content likely drives 80 of your traffic. The rest? It's just taking up space and diluting your site's authority. Ouch, but true. We get it. Getting over your emotional attachment to content you worked hard to create. That post from 2019 about email trends might have been your baby, but if it's getting two visits a month and contains outdated advice, it's time to let it go. Your content strategy has a serious middle-child syndrome. Let me guess: tons of top-of-funnel awareness pieces, a decent chunk of bottom-funnel conversion content, but that middle section? Crickets. You're not alone. Most content marketers are addicted to vanity metrics like page views (hello, top-of-funnel) or obsessed with conversion rates (bottom-funnel), leaving the critical consideration stage abandoned like a shopping cart on a discount website. Your audience isn't ready to buy after reading one ""what is"" blog post, and that case study isn't going to magically appear in front of someone who doesn't know they have a problem. The content journey is real, folks. Your funnel needs content at every stage: Unfortunately, here's where most companies mess up: they create these pieces in isolation, with no clear path from one stage to the next. You need deliberate content pathways that guide readers logically through the buyer's journey. Think of it like a Netflix serieseach episode should leave viewers wanting the next one. Your awareness piece should naturally lead to consideration content, which should make the case for conversion content. You're either using AI tools for content creation or you're falling behind. There's no middle ground anymore. The initial response to AI was predictable: ""But it can't match human creativity!"" True...and also completely missing the point. AI isn't meant to replace your creative processit's meant to accelerate it, handle the grunt work, and let your team focus on what humans do best: strategic thinking and emotional connection. The key is finding the right human-AI balance. The best content teams use AI as a superpower, not a replacement. They feed the AI their brand voice guidelines, provide specific prompts with context, and then edit the output with their human expertise. The quality gap between AI early adopters and laggards is widening faster than most marketing leaders realize. Yes, there are ethical considerations. Yes, you should disclose AI usage when appropriate. And yes, you should have clear guidelines about fact-checking and quality control. But sitting on the sidelines isn't an option anymore. Remember when your content operation was just you and a WordPress login? Those were simpler times. Now you've likely got freelancers, agencies, subject matter experts, and that intern who keeps publishing things without approval. Content chaos isn't just annoyingit's expensive. Without proper governance, you're practically begging for inconsistent messaging, compliance nightmares, and the inevitable ""who approved THAT?"" moment during the executive review. Think of content governance as the guardrails that keep your content machine from driving off a cliff. It's not about bureaucracy. It's about creating systems that scale without sacrificing quality. Here's what a solid content governance framework looks like: Not everyone has time for your 3,000-word epic guides. There, I said it. Speaking of which, this post is getting kind of long, isn't it? Huh. We're living in the TikTok era, where attention spans are measured in seconds, not minutes. And while there's absolutely still a place for comprehensive content, ignoring micro-content is like ignoring that half your audience is scrolling on their phones during meetings. Micro-content isn't just ""short content""it's strategically bite-sized pieces designed for immediate consumption and high shareability. Think of it as content snacking between the full meals of your longer pieces. It fits perfectly into the gaps of your audience's daythe elevator ride, the coffee line, the three minutes before a meeting starts. When someone doesn't have time for your 45-minute webinar, they might still have time for your 60-second tip video. Plus, micro-content is content marketing on easy mode. That statistic that took you hours to research? Turn it into a shareable graphic. That key insight buried on page 12 of your whitepaper? Make it a standalone social post. Your customers are creating content about your brand whether you like it or not. The question is: are you going to leverage it or ignore it? User-generated content isn't just free materialit's authentic social proof that outperforms your polished marketing copy every single time. When Nielsen reports that 92 of consumers trust peer recommendations over advertising, they're basically telling you to stop talking and let your customers do it for you. The smartest brands don't just collect UGC: they actively shape it by providing creative frameworks. Starbucks' White Cup Contest didn't just ask for random photos. It gave clear parameters that resulted in on-brand artistic expressions. UGC creates a virtuous cycle. When customers see you featuring their peers, they're more likely to contribute their own content, creating a sustainable ecosystem of authentic marketing material. That ""universally appealing"" content you're so proud of? It's probably alienating half your global audience. True content localization goes way beyond running your blog posts through Google Translate and calling it a day. It's about recognizing that different markets have fundamentally different needs, references, pain points, and cultural contexts. When your American case study references baseball metaphors and Super Bowl ads, you're losing your international audience faster than you can say ""cultural imperialism,"" (and that's a mouthful already). Localization isn't just for enterprise companies. Even if you're a small business, your digital content reaches global audiences. Google Analytics probably shows international traffic you're not effectively serving. Start small if needed. Identify your top international markets and localize your highest-performing content first. Then expand as you see results. Just please, for the love of global commerce, stop assuming everyone gets your references to ""American as apple pie"" or understands your payment processor that only works with US banks. By the time a keyword shows decent volume in Ahrefs or SEMrush, you're already too late to the party. The competition has arrived, the difficulty has spiked, and you're fighting an uphill battle for rankings. Elite content marketers don't chase keywordsthey predict them. They identify emerging topics before they hit the research tools and establish authority while everyone else is still wondering if there's an opportunity. The content teams that master this approach build massive authority while competitors are still waiting for ""sufficient search volume"" to justify creating content. By the time everyone else jumps on the trend, you're already ranking 1 with established backlinks and engagement signals. Take ""conversational commerce"" as an example. Brands that created definitive content when it was just a concept mentioned at tech conferences dominated the SERP by the time it became a high-volume search term. This approach requires confidence and strategic risk-taking. You'll occasionally invest in topics that never take off. But when you're right (which you will be if you're truly connected to your industry), the payoff is fantastic. We've covered a lot, so we decided to help you out by condensing everything into a quick checklist. Access the content marketing best practices checklist (no download or email address necessary). Whether email is your content creation or distribution channel (or both), Twilio SendGrid has all the tools you need for world-class content marketing. Get started now. Sign up for a free account to explore everything SendGrid has to offer your content marketing program. Twilio Docs From APIs to SDKs to sample apps API reference documentation, SDKs, helper libraries, quickstarts, and tutorials for your language and platform. Resource Center The latest ebooks, industry reports, and webinars Learn from customer engagement experts to improve your own communication. Ahoy Twilio's developer community hub Best practices, code samples, and inspiration to build communications and digital engagement experiences.",4371
https://www.akkio.com/beginners-guide-to-machine-learning,The Complete Beginner's Guide to Machine Learning,"Machine learning is a branch of computer science that allows computers to automatically infer patterns from data without being explicitly told what these patterns are. These inferences are often based on using algorithms to automatically examine the statistical properties of the data and creating mathematical models to represent the relationship between different quantities. Let's contrast this with traditional computing, which relies on deterministic systems, wherein we explicitly tell the computer a set of rules to perform a specific task. This method of programming computers is referred to as being rules-based. Where machine learning differs from and supersedes, rules-based programming is that it's capable of inferring these rules on its own. Say you're a bank manager, and you'd like to figure out whether a loan applicant is likely to default on their loan. In a rules-based approach, the bank manager (or other experts) would explicitly tell the computer that if the applicant's credit score is less than a threshold, reject the application. A machine learning algorithm, however, would simply take in historical data on the credit scores of customers and their loan outcomes and figure out, on its own , what this threshold should be. In doing so, the machine is learning from historical data and creating its own rules . This is just an introduction to machine learning, of course, as real-world machine learning models are generally far more complex than a simple threshold. Still, it's a great example of just how powerful machine learning can be. Any organizational KPI can be optimized as long as you have the relevant data. Given a historical customer dataset, for example, you could predict which of your current customers are in danger of leaving, so you can stop churn before it happens. Modern approaches to machine learning have made great strides and can accomplish a lot more than just that. From self-driving cars to voice recognition to the automated email filtering systems that flag the spam in your inbox, machine learning algorithms form the basis of many of the advances in technology that we've come to depend on today. Next, let's consider the different types of machine learning algorithms and the specific types of problems they can solve. Machine learning algorithms are often divided into three general categories (though other classification schemes are also used): supervised learning, unsupervised learning, and reinforcement learning. Supervised machine learning refers to classes of algorithms where the machine learning model is given a set of data with explicit labels for the quantity we're interested in (this quantity is often referred to as the response or target). Semi-supervised learning uses a combination of labeled and unlabeled data to train AI models. If youre dealing with unlabeled data, youll need to do data labeling. Labeling is the process of annotating examples to help the training of a machine learning model. Labeling is typically performed by humans, which can be expensive and time-consuming. However, there are ways to automate the labeling process. A great example of supervised learning is the loan applications scenario we considered earlier. Here, we had historical data about past loan applicants' credit scores (and potentially income levels, age, etc.) alongside explicit labels which told us if the person in question defaulted on their loan or not. Supervised learning algorithms can be further subdivided into regression and classification . This difference refers to the type of quantity our target is. If the target is a choice between a few discrete categories  for example, will the applicant default or not, is this a picture of a cat, a dog, or a human, etc.  then the problem is referred to as classification , as we're trying to determine the class that a given data point belongs to. If, however, our target variable is continuous, then the problem is referred to as regression . For example, predicting the price of a house given the number of bedrooms and its location. In unsupervised learning problems, the data we're given has no labels, and we're simply looking for patterns. For example, say you're Amazon. Given customers' purchase history, can we identify any clusters (groups of similar customers)? In this scenario, even though we don't have explicit, definitive data on what a person's interests are, just identifying that a particular group of customers purchase similar items can allow us to make purchase recommendations based on what other people in the cluster have also purchased. Similar systems are what power Amazon's ""you might also be interested in"" carousel. K-means clustering is a type of clustering model that takes the different groups of customers and assigns them to various clusters, or groups, based on similarities in their behavior patterns. On a technical level, it works by finding the centroid for each cluster, which is then used as the initial mean for the cluster. New customers are then assigned to clusters based on their similarity to other members of that cluster. Additionally, once we've identified the clusters, we could then study their characteristics. For example, suppose we see that a given cluster is buying many video games. In that case, we can make an educated guess that this group of customers are gamers, even though no one actually told us so. Once we've done this form of analysis, we could potentially even use the labels from unsupervised learning to create supervised learning models that may, for example, allow us to predict how much money a 25-year-old gamer is likely to spend with us compared to a 50-year-old fishing enthusiast. Reinforcement learning is a class of machine learning algorithms where we assign a computer agent to perform some task without giving it much guidance on precisely what to do. Instead, the computer is allowed to make its own choices and, depending on whether those choices lead to the outcome we want or not, we assign penalties and rewards. We repeat this process multiple times, allowing the computer to learn the optimal way of doing something by trial and error and repeated iterations. Think of this as the carrot-and-stick approach to machine learning. It's almost like the computer is playing a video game and discovering what works and what doesn't. Interestingly, playing games is precisely the application where reinforcement learning has shown the most astonishing results. Google's infamous AlphaGo model, which trounced even the highest-ranked human players of Go, was built using reinforcement learning. Google has since extended the same technology to AlphaZero, a successor to the original AlphaGo used as a reference by chess players to determine the best strategies. If you've seen machine learning in the news, you almost certainly have also heard about deep learning. And you might be wondering at this point where deep learning fits into the above paradigm. And the answer is all of them. Deep learning is a subset of machine learning that breaks a problem down into several 'layers' of 'neurons.' These neurons are very loosely modeled on how neurons in the human brain work. This class of machine learning is referred to as deep learning because the typical artificial neural network (the collection of all the layers of neurons) often contains many layers. While deep learning was initially used for supervised learning problems, recent advances have extended its capabilities to unsupervised and reinforcement learning problems. And they have shown tremendous results. Many of the latest advances in computer vision, which self-driving cars and facial recognition systems depend on, are rooted in the use of deep learning models. Natural language processing, which allows computers to understand natural human conversations and powers Siri and Google Assistant, also owes its success to deep learning. Today's AI boom is largely thanks to the pioneers of deep learning: Geoffrey Hinton, Yann LeCun, and Yoshua Bengio. These AI engineers were awarded the Turing Award for their breakthrough advancements in deep neural networks. If you've ever looked at a tech company's website or watched the keynote for Apple's latest iPhones, you might have seen terms like artificial intelligence (AI) and machine learning (ML) popping up everywhere. These ""buzzwords"" are often treated interchangeably, though there are subtle and important differences between them. So, let's look at what both of these terms imply, exactly, and how they all relate to each other. To start off, let's first define each of these terms and then circle back to the question of how they're related. While it's possible to write a book on AI covering computer science, history, philosophy, and the very nature of intelligence, let's keep things simple. The easiest and most accessible way of defining artificial intelligence is simply looking at the words: it's an attempt to create intelligence. The discipline of AI studies the theory and practice of intelligent systems, especially automated decision making and learning. In less abstract terms, it's an attempt at allowing computers to mimic both humans' perception of the world as well as our ability to reason with it. That is a tall order, of course, but it sums up the ultimate goal of AI research rather well. Consider the Terminator. This was an imaginary machine perfectly capable of navigating our world, incorporating new information about its surroundings and the very dynamic nature of both the world and its inhabitants, and making independent decisions without needing any instructions from a human. This definition also makes it abundantly clear that we are a long, long way away from achieving true artificial intelligence. Still, the contributions of todays AI are almost limitless. The benefits of AI are already being felt in many industries, including medicine, agriculture, manufacturing, or simply sales and marketing. AI is changing the way we work, play, and engage with one another, from the tools we use to the ways we communicate to the organizations we form. But while a genuinely independent machine perfectly capable of handling itself in all situations is the holy grail of research in this field, we have already made significant progress in allowing computers to exhibit human-like capability when performing at least very specific tasks. To distinguish between these different levels of intelligence, researchers in the field often divided artificial intelligence into two or three types: ANI is often referred to as weak AI , as it is designed to exhibit ""intelligence"" or human-like ability in performing a specific task. One of the next frontiers in ANI is maximizing the efficiency of models. This includes optimizing training, inference, and deployment, as well as enhancing the performance of each. AGI or strong AI refers to systems that are capable of matching human intelligence in general (i.e., in more than a few specific tasks), while an artificial super intelligence would be able to surpass human capabilities. For now, these comparisons are largely relegated to schools of thought, as all deployed AI models are examples of Artificial Narrow Intelligence (not AGI or ASI). There are a number of factors that are accelerating the emergence of AGI, including the increasing availability of data, the development of better algorithms, and progress in computer processing. The AI in the movie ""Her"" is a cultural example of an AGI. Samantha, the artificial intelligence character in the movie, has her own thoughts and opinions. She's not a subservient robot, but rather an independent being. Samantha is capable of using voice and speech recognition, natural language processing, computer vision, and more. These are good examples of artificial narrow intelligence, as they show a machine performing a single task really well. However, the beauty of general AI is that it's capable of integrating all of these individual elements into a single, holistic system that can do everything a human can. And while we haven't achieved the latter, we have achieved remarkable progress with the former. Consider self-driving cars, for example. They're an example of ANI, as they excel at a specific task (navigation), and are generally quite capable of identifying elements in their environment (other cars, pedestrians, etc.) and incorporating that information into a decision (e.g., how to make a turn or when to use the brakes to avoid a collision). Virtual assistants like Siri and Google Assistant are examples of the great strides we've made in creating robust ANI systems that are capable of creating actual value for businesses and individuals. These assistants use speech recognition, an AI-enabled technology that allows an individual to input voice commands and receive a response. This is achieved through a machine learning model which learns and understands the structure of language by processing sound waves. In any AI system, data is collected and processed in order to make predictions. This data is then cleaned and converted into a format that can be used by the model. The model will then generate a prediction, which can be viewed as a response to some input. The input may be a question or task, and the response can be considered an answer or a solution. Other examples include facial and image recognition systems, speech-to-text, machine translation (Google Translate), and recommendation engines (how Amazon or Netflix know which products you'd like). And this is also where machine learning comes in, as the majority of these advances have been made possible thanks to machine learning (and deep learning). Whether or not AGI emerges, AI of the future will be embedded everywhere and will touch every part of society, from smart devices to loan applications to phone apps. With the rapid growth of AI, practically all industries are exploring how they can take advantage of this new technology. As we discussed in this guide's introduction, ""machine learning is a branch of computer science that allows computers to automatically infer patterns from data without being explicitly told what these patterns are. "" As such, machine learning is one way for us to achieve artificial intelligence  i.e., systems capable of making independent, human-like decisions. Unfortunately, these systems have, thus far, been restricted to only specific tasks and are therefore examples of narrow AI. In the last two decades, many of the most exciting machine learning applications have come from a subset of the field referred to as Deep Learning . As discussed in the deep learning section of this guide, deep learning algorithms have achieved state-of-the-art performance in image recognition and natural language processing problems. They have also shown incredible promise in forecasting and reinforcement learning problems. Let's circle back and look at how AI, ML, and DL relate to each other. The following graphic explains the relationship between artificial intelligence, machine learning, and deep learning rather well. AI is the most general of the three and could almost be thought of as the overarching goal of this field of research: creating systems capable of mimicking human decision making. A common misconception is that AI is learning. In reality, AI is programmed by humans to complete tasks and offer predictions. AI can mimic intelligence, but it cannot independently learn like a person. The goal of AI engineers today is to make machines think more like humans and less like machines. Another goal of AI researchers today is to make AI behave more like humans. This is particularly challenging, as behavior is thought of as the joint product of predisposition and environment, which are entirely different concepts between people and machines. Machine learning is one way of achieving artificial intelligence, while deep learning is a subset of machine learning algorithms which have shown the most promise in dealing with problems involving unstructured data, such as image recognition and natural language. Machine learning is commonly used as a part of hybrid systems. Hybrid systems are a mix of human and machine intelligence that seeks to combine the best of both worlds, such as machine learning models that send predictions to humans to be analyzed. It is important to distinguish between machine learning and AI, however, because machine learning is not the only means for us to create artificially intelligent systems  just the most successful thus far . In the early years of research into this field, for example, researchers focused on building Symbolic AI systems  also referred to as classical AI or good old-fashioned AI (GOFAI) . This approach to creating intelligent systems focuses on representing the world as a collection of symbols, translating real-world problems into symbolic propositions, and then allowing the computer to use propositional logic to solve these problems. These efforts were based on the observation that humans (and our languages) use symbols to represent both objects in the real world and how they relate to each other. ""John"" and ""pizza"" are symbols, while ""eat"" is the relationship between these two objectssymbols. Suppose we could represent the entire universe (or at least, all of the information pertaining to a specific domain, such as medicine) into such symbols and relations. In that case, a computer could then solve these problems using logic. We could also link different propositions together using if-then rules. For example, IF HUNGRY(John) THEN EAT(John, Pizza). This is an example of an extremely simple rule-based symbolic AI. Of course, while this simplistic example only uses a few symbols and a single rule, a real computer system can store billions of such symbols, propositions, and rules. Such rule-based systems formed the basis for what are known as expert systems , AI tools that rely on a hierarchy of rules to provide solutions to problems. For example, consider a doctor diagnosing a patient. These diagnoses are often also rule-based: i.e., if the patient has X and Y symptoms, if their blood sugar is greater than Z, then they have disease A. As a result, AI has had a big impact on cancer diagnosis, treatment, and prevention. Researchers have shown that algorithms are better than humans at classifying cells as cancerous or not. Or consider the loan application problem that we discussed in the machine learning article. A panel of experts could easily represent this problem into a series of symbols and rules (e.g., IF credit score  X AND loan amount  Y THEN approve the loan). This could then be used to create an AI expert system that could potentially replace a doctor or a loan officer for making these decisions. Symbolic AI enjoys several advantages over machine learning. While machine learning systems practice pattern recognition on historical data, symbolic systems only require an expert to define the problem space in terms of symbols, propositions, and rules. Thus, it requires next to no training data. Additionally, since symbolic AI systems comprise a hierarchy of human-readable rules, they're much easier to interpret than, say, deep neural networks, which are famously opaque and difficult to interpret. Lastly, an ideal symbolic AI, with all the knowledge of the world that a human possesses, could potentially be an example of an artificial general (or super) intelligence capable of genuinely reasoning like a human. With that said, while it theoretically makes sense to argue that we could potentially express all knowledge as symbols, the reality is that our understanding of the world is incredibly complex and explicitly stating all of human knowledge and common sense as a series of symbols and relations would be a Herculean task. Some pieces of information may also be difficult to represent as symbols. For example, consider image classification. How does one describe a '2' in image form as a symbol? While neural networks excel at these tasks, simply translating the problem into a symbolic system is difficult. This was one of the major limitations of symbolic AI research in the 70s and 80s. These systems were often considered brittle (i.e., unable to handle problems that were out of the norm), lacking common sense, and therefore ""toy"" solutions. These limitations were among the primary drivers of the first AI winter, a period of time when most funding into AI systems was withdrawn, as research failed to satisfactorily address these problems. As a result, aside from some niche applications, symbolic AI has generally fallen out of fashion in favor of machine learning, which focused on specific tasks (i.e., narrow AI) but provided far more robust solutions. Advances in computing power and the proliferation of data in the internet era have also been a significant boosting factor in enabling machine learning systems, whose performance is often limited by the amount (and quality) of the data available to them. In recent years, however, researchers have started looking at combining machine learning systems, especially neural networks, with symbolic AI in an attempt to capitalize on the strengths of both these approaches to AI. This is referred to as neural-symbolic computing . Many business applications require predicting a continuous quantity . For example, what is the lifetime value of a customer with a given age and income level?, or, what is the probability of customer churn? These are generally referred to as regression problems . In this article, we will go over several machine learning algorithms used for solving regression problems. While we wont cover the math in depth, we will at least briefly touch on the general mathematical form of these models to provide you with a better understanding of the intuition behind these models. The most common method for solving regression problems is referred to as linear regression . Say youre given the following data about the relationship between pH and Citric acid to determine wine quality. You can clearly see a linear relationship between the two, but as with all real data, there is also some noise. Since the relationship is linear, it makes sense to model this using a straight line. where We can extend this to multiple predictors as follows, which is also the general form of linear regression: where But we could potentially draw many straight lines and because of the noise, its not entirely clear which one is the best line. For example, of the three lines below, which is the better one? This requires us to define a criterion for what is, mathematically, considered good vs. bad. Since were using this model to predict quantities, it makes sense to use the error of our predictions as our yardstick, where the error is defined as the difference between the actual value and our prediction. A line that minimizes the overall prediction error is good, while a line that has a large overall error is bad. There are different ways of calculating errors. For our purposes, well use the sum of squared errors (SSE) . As a simple example of this, consider the following example of predicting the weather: At this point, you might be wondering why were taking the square of the errors, and not just the actual value. Thats because we dont want negative and positive errors to cancel each other out. If we just summed the error values in the above example, wed get 4 - 3 - 1  0. This would suggest the model is perfect and give us a false sense of confidence in our model. Using squared errors prevents this from happening. where Thus, of all the possible lines we can draw, we would select the line with the lowest SSE. This is referred to as an objective function  i.e., some value we want to either minimize or maximize. In this case, we want to minimize the SSE. While we wont go into the mathematical details here, this problem can easily be solved using optimization theory , thereby allowing us to find the best line which minimizes the sum of squared errors. Once we have found the best-fit line, we can make predictions for any new input point by interpolating its value from the straight line. For example, while none of our data points have a citric acid of 0.8, we can predict that when citric acid value is 0.8, the pH is 3.  While the above example was extremely simple with only one response and one predictor, we can easily extend the same logic to more complex problems involving higher dimensions (i.e., more predictors). Real-world regression problems are often nonlinear . There are many ways to deal with such problems, either by extending the linear regression model itself or using other modeling constructs. For example, say the data we have looks like this: While theres some noise, you can see that this resembles a quadratic curve. Lets say we know that the true relationship is given by the equation: We could easily extend the linear regression model to this problem by simply taking the square of the dependent variable and adding it as another predictor for the linear regression model. We could do the same for higher-order terms, and this is referred to as polynomial regression . Other, more complex methods include the use of splines . While we wont go into the theory or the math behind this in any detail, at a fundamental level, splines allow us to fit different nonlinear functions to different parts of the input space, while ensuring that the functions are smooth (i.e., connected) at the boundaries between these regions. The result is a highly flexible model that can fit nonlinear data more closely. However, this may come at the expense of overfitting as the model may be fitting to random noise instead of the actual patterns. As a result, splines and polynomial regression should be used with care and evaluated using cross-validation to ensure that the model we train can be generalized. We may also use nonparametric methods for regression problems. The simplest of these may just be K-nearest neighbor regression . In this method, given historical data and a new data point we want a prediction for, we simply find the k data points closest to this new point and predict its value to be the mean of these k points. We can also use decision trees for regression problems. Here, we split the data into different subsets based on a set of criteria. We may then assign a fixed value to each leaf node as its prediction (e.g., the mean of all the data points belonging to that leaf node). See the example below of using decision tree regression for predicting the number of hours played based on different weather conditions: Alternatively, we could also fit a separate linear regression model for each of the leaf nodes. As with many other machine learning problems, we can also use deep learning and neural networks to solve nonlinear regression problems. Lets extend the idea of predicting a continuous variable to probabilities. Say we wanted to predict the probability of a customer canceling their subscription to our service. Since probability is a continuous variable, it naturally extends itself to regression. However, its a continuous variable capped by two constraints: a probability can neither be negative nor greater than 1. Regular linear regression is incapable of abiding by these constraints, and thus the logistic model was born. Logistic regression is an extension of linear regression, which straddles the line between regression and classification. It works on the same principle as linear regression but with a key difference: the response is the natural log of the odds of an event occurring . Odds , in statistics, refers to the ratio of the probability of an event occurring to the probability of it not occurring: For example, say the probability of Barcelona winning their next match is 30. Then, the odds for their victory are 37 or 3:7. This is also the nomenclature used in gambling, though gambling sites often show odds against an event and not odds for. The odds against Barcelona, in this case, would be 7:3. Statistically, the most salient aspect of using the natural log of odds is that while the output of the regression model is still unconstrained, when we convert the log odds back to probabilities, these are capped to between 0 and 1, thus solving our problem! While we wont go into the mathematical details of why that is the case, you can see below a graph of the output probability p as the value of the independent variable changes: Thus, weve successfully extended the linear regression model to predict probabilities. Once we have an estimate for the probability of an event occurring, classification is just one step away. If we set a certain probability as a threshold , we can classify each data point (e.g., each customer) into one of two classes. Choosing this threshold is largely dependent on the application. For example, a luxury carmaker that operates on high margins and low volumes may want to be highly proactive and personally check in with customers with even a 20 probability of churn. If churn is not mission-critical or we simply dont have the resources to handle individual customers, we may want to set this threshold much higher (e.g., 90) so we are alerted to only the most urgent prospects. In the previous section, we dealt with examples of regression problems , where we want to predict a continuous variable. The second major type of supervised learning problem is classification, where we want to assign each sample into one of two (or more) categories . For example, a bank may want to determine if a loan applicant will repay their loan or not. Or an email provider might want to build a system that filters out spam from your inbox. In both these cases, we have only two possible classescategories, but its also possible to handle problems with multiple options. For example, a lead-scoring system might want to distinguish between hot, neutral, and cold leads. Computer vision problems are often also multi-class problems , as we wish to identify multiple types of objects (cars, people, traffic signs, etc.). In this article, well examine some of the algorithms used for classification problems. However, the focus here will be on building intuition, and so we wont be covering the math behind these algorithms in any detail. Well also focus on only binary classification problems (i.e., those with only two options) for simplicity. One of the simplest classification algorithms is KNN classification . Say we have historical data with labels and a new point whose label we want to determine. In this method, we simply find the k points closest to the new point and assign its label to be the mode (the most commonly occurring class) of these k points. For example, consider the image below. If k3 , then the label of the green point is a red triangle because, among the three points closest to it, the majority ( ) are red triangles. As we discussed in the regression section , the KNN algorithm can also solve nonlinear regression problems. Another commonly used classification algorithm is SVM. Consider the following example where we want to filter out spam emails. The x-axis is the number of times the word buy appears in the email, and the y-axis is the number of other people who have received the same email. When plotted, the data looks like this: The blue points are legitimate emails, and the red points are spam. Spam emails presumably want you to buy things and are sent to more people, so it makes sense that emails sent out to a large number of people with many mentions of the word buy are spam. More importantly, we see that we can clearly separate the two classes using a straight line, but as with linear regression, this raises the question: which line is the best? As shown below, we can draw many possible lines, all of which perfectly separate between the two classes. We may want to, thus, think about defining what makes one line better than another. This is somewhat dependent on the problem were trying to solve, and well revisit this point later on. For now, though, a reasonable criterion may be to choose the line which maximizes the margin between the two classes  that is, the line which is as far away as possible from the most extreme examples of either class. This raises another question: how can we translate this into a mathematical problem instead of just doing it by eye? Consider the following diagram: We can find the best line by first drawing two lines that only touch the outermost points of each class. Note also that both of these lines are parallel to each other. These lines are called support vectors ; hence the name of the algorithm. The best line is then a line that is parallel to both of these lines and also equidistant from them (i.e., its the same distance from each). The distance between the support vectors and the classifier line is called the margin , and we want to maximize this. This is the most common (or default) way in which SVM selects the best classifier line. This may not always be the ideal way of doing things, however. For example, say we were working on determining if a tumor is benign or malignant. In this case, the cost of making a mistake is not the same for each class. If we classify a malignant tumor as benign, it could potentially cost the patient their life, while mistaking a benign tumor as malignant might only require further testing. Clearly, one mistake is worse than the other. Depending on the application and how careful we want to be, we may choose to assign a greater weight to either type of mistake. As such, we may decide to move the line further away from one class or even deliberately mislabel some of the data points simply because we want to be extremely cautious about making a mistake. Next, lets consider scenarios where the two classes cannot be cleanly separated via a straight line. Sometimes, it may not be possible to perfectly classify points using a straight line. We could, then, resort to nonlinear methods (discussed later), but for now, lets stick to only straight lines. In that case, we may be willing to take an imperfect classifier. This is also called a soft classifier , as it does not classify all points correctly. On the other hand, a hard classifier would refer to the examples weve discussed thus far, which perfectly classify all data points. Consider the following example: In the above image, we see that the soft classifier weve selected misclassifies three points (highlighted in yellow). At the same time, we also see two blue points and two red points (circled in blue) that are extremely close to the line and are near-mistakes. Thus, our classifier has a very small margin between the two classes. Consider a second possible classifier we could draw for the same data: In this case, we have five misclassified points (compared to three before), but the line has a wider margin and very few points that are near-misses or extremely close to the line. This demonstrates an inherent tradeoff with soft classifiers. We can choose to either minimize errors or maximize the margin between the two classes. While we wont show the mathematical details here, we can assign different weights to either of these options depending on how important higher accuracy is compared to having a cleaner, less ambiguous boundary. This is an example of a model hyperparameter : a variable that we specify for the algorithm and which defines or in some way constrains the form that our model will take. Now, consider the following example: In this case, we see that while a straight line cannot separate these points, a circle can. How can we solve this problem? As weve seen above, one option may be to use nonlinear methods like KNN classification or classification trees. Since these are nonparametric methods and dont specify a particular form for the model (e.g., that it needs to be a straight line), they are particularly well-suited for nonlinear problems. However, SVM can also be extended to solving this problem by transforming the data to achieve linear separation between the classes. For example, we can see that all the points within a circle of radius 2 are red and those outside it are blue. In a simple case like this, if we convert the data from Cartesian to polar coordinates. The resulting plot is shown below, where the x-axis is the radial distance from the origin, and the y-axis is the angle in radians: As can be seen, the classes are now easily separated using a straight line. Thus, we would simply feed the SVM algorithm this transformed version of the data. In more complex scenarios, especially when we have multi-dimensional problems and dont know that the ideal classifier is, for example, a circle, we may not know which transformation to use. In other cases, the transformation may be computationally inefficient. In these cases, we can transform the problem by adding more dimensions to it. This is referred to as the kernel trick or Kernel SVM and allows us to create nonlinear classification boundaries like the one below: An explanation of the mechanics or the math of how and why kernel SVM works is beyond the scope of this article. Still, its an important detail to know in order for you to have a comprehensive understanding of the kinds of problems the SVM algorithm can solve. Kernel methods should be used with SVM with caution, however. By adding more dimensions to the problem and allowing for nonlinear boundaries, we are creating a more flexible model . This can easily lead to overfitting . Another means of solving classification problems  and one thats exceptionally well-suited to nonlinear problems  is the use of a decision tree . Since decision trees can be used for both classification and regression problems (see the regression section), the algorithm is sometimes referred to as CART (Classification and Regression Trees) . In this method, we divide the data into smaller and smaller subsets based on a series of binary (yesno) questions. Consider the following decision tree for deciding if we should play football or not, based on how the weather affected past games: The balls at the leaf nodes indicate whether we were able to successfully finish a game (blue) with the given weather conditions or whether the game had to be interrupted due to poor weather (red). We see that on most rainy days with wind, we were forced to cancel our games. As such, the mode of this leaf node is red, and we would classify any future rainy and windy days as red (i.e., we probably shouldnt play on those days). Note that decision trees are also an excellent example of how machine learning methods differ from more traditional forms of AI. You might recall that in the What is the difference between machine learning and AI section, we discussed something called expert systems , which are a hierarchy of ifelse rules that allow a computer to make a decision. A decision tree is also a hierarchy of binary rules, but the key difference between the two is that the rules in an expert system are defined by a human expert. On the other hand, decision trees figure out what the splitting criteria at stage (i.e., the rules) should be by themselves  which is why we say that the machine is learning . How does it do that? You might have noticed that each of the leaf nodes consists mostly of one class  for example, the Sunny  Normal Humidity node is mostly blue, while the Rainy  Windy node is mostly red. Thats by design. At each stage of building the decision tree, the computer will look at all of the possible options it has and choose the splitting criterion that minimizes the impurity of the subsequent nodes  that is, it tries to ensure that each of the nodes has points belonging to only one class, if possible. Of course, if we allow the computer to keep splitting the data into smaller and smaller subsets (i.e., a deep tree), we might eventually end up with a scenario where each leaf node only contains one (or very few) data points. This might lead to overfitting . Therefore the maximum allowable depth is one of the most important hyperparameters when using tree-based methods. Deep learning is another excellent example of a classification method. In fact, deep learning models are great at solving problems with multiple classes. Theyre also particularly effective at dealing with nonlinear relationships and unstructured problems as theyre able to tease out the more abstract interactions between different terms. In the What is Machine Learning section of the guide, we considered the example of a bank trying to determine whether a loan applicant is likely to default or not. This is an example of a problem where we have relatively structured data. We know, for each applicant, specific values of different metrics that we think are important and relevant to solving their problem (e.g., their income, credit score, etc.). These metrics are often referred to as features or predictors. But what about a facial recognition problem? Say we have two pictures of the same person looking in different directions. If we simply fed these two images as a string of pixels to a classical ML algorithm, it might not recognize that they are the same person because the string of pixels that it received might be quite different based on lightning conditions, the direction in which the person is looking and so on. Instead, it would make far more sense for us to try and extract useful features from the image first and then feed these as the inputs to the algorithm. For example, we might want to determine what the colour of their skin is, the shape of their face, the length of their nose, the colour of their eyes and so on. Since these will remain the same regardless of lighting conditions or the orientation of their face, this might be a far more robust solution. This, however, raises another problem as we might need another machine learning algorithm to, for example, distinguish between the person's face and hair. Once we've identified the hair, we may then need a second machine learning algorithm to distinguish between the different types of hair colours (since hair colours aren't discrete and 'red' hair can be many different colours in reality). As such, we may need to break down the problem into 'layers' of smaller sub-problems (also solved using machine learning) to first extract the relevant, structured features before we can feed them to the final algorithm which actually classifies faces. Deep learning, on the other hand, tries to circumvent this problem as it doesn't require us to determine these intermediate features. Instead, we can simply feed it the raw, unstructured image and it can figure out, on its own, what these relevant features might be. In doing so, it presents two significant benefits compared to classical machine learning algorithms: This is also why deep learning algorithms are often considered black boxes. The complexity of their structure and the large number of layers in them means we can't precisely extract information about specific features as we might do with a linear regression model, where the coefficient for each feature imparts direct and easily interpretable information about the linear relationship between the features and the response. As we've discussed before, a neural network is 'deep' when it contains multiple layers. While different practitioners might differ on exactly what the threshold for a 'deep' neural network is, a neural network with more than three layers is often considered as being 'deep'. This begs the question, however, why do neural networks need to be deep? To answer this question, recall how, in the previous section, we discussed that solving a facial recognition problem may require the creation of a pipeline with multiple layers of sub-problems in order to use classical ML algorithms. Well, it turns out that that's more or less also how deep learning algorithms work. For example, in an image classification problem, research has shown that each of the layers (or a group of them) will tend to specialize toward extracting specific pieces of information about the image. For example, some layers might focus on the shapes in the image, while others might focus on colors. Adding more layers can, therefore, allow neural networks to more granularly extract information  that is, identify more types of features. Deeper layers also allow the neural network to learn about the more abstract interactions between different features. For example, the impact credit score has on a person's ability to repay a loan may be very different based on whether they're a student or a business owner. In a regression setting, the data scientist would need to manually specify any such interaction terms. But as we discussed before, we may not always know which interaction terms are relevant, while a deep neural network would be able to do the job for us. Its prowess with unstructured data has allowed deep learning to produce massive advances in the fields of computer vision, object detection, and natural language processing, all of which involve unstructured data and classification (for example, classifying the different objects in an image as a car or a pedestrian). Machine Learning works by recognizing the patterns in past data, and then using them to predict future outcomes. To build a successful predictive model, you need data that is relevant to the outcome of interest. This data can take many forms - from number values (temperature, cost of a commodity, etc) to time values (dates, elapsed times) to text, images, video and audio. Fortunately the explosion in computing and sensor technology combined with the internet has enabled us to capture and store data at exponentially increasing rates. The trick is getting the right data for any particular problem - most businesses capture this in their existing technology stacks, and a lot of this data is available for free online. Structured versus unstructured data is a common topic in the field of data science, where a structured dataset typically has a well-defined schema and is organized in a table with rows and columns. Unstructured data, on the other hand, is often messy and difficult to process. Structured and unstructured data can both be the fuel for successful machine learning models. Lets dive into the details of structured versus unstructured data, including data formats, data storage, data sources, analysis, and more. Structured data is quantifiable and easy to search and analyze, and comes in predefined formats such as CSV, Excel, XML, or JSON, while unstructured data can be in a variety of less well-defined formats including PDFs, images, audio, or video. Structured data is typically a result of a well-defined schema, which is often created by human experts. It's easy for people to add or change the schema of structured data, but it can be very difficult to do so with unstructured data. In short, structured data is searchable and organized in a table, making it easy to find patterns and relationships. Its also possible to analyze and gain value from unstructured data, such as by using text extraction on PDFs, followed by text classification, but its a much more difficult task. Many popular business tools, like Hubspot, Salesforce, or Snowflake, are sources of structured data. Akkios sample datasets, which are in CSV format, are also examples of structured data. More broadly speaking, any well-defined CSV or Excel file is an example of structured data, millions of examples of which are available on sites like Kaggle or Data.gov. For the purpose of predictive modeling, the most common type of unstructured data is text. This includes text forms, like customer feedback forms, as well as emails, comments on social media sites, product reviews, or even notes taken during sales calls or business meetings. As weve highlighted, unstructured data goes beyond text, and includes audio and video. For example, YouTube reviews are another source of unstructured data. YouTube videos also include AI-generated transcriptions or speech-to-text. Given that text data, text classification could be used to mine those reviews for insights. Structured data is often stored in data warehouses while unstructured data is stored in data lakes. A warehouse stores structured datasets and typically relies on more traditional databases like SQL Server and Oracle for storage, while a data lake stores less well-defined datasets. Some of the most well-known machine learning models in use today are fueled by structured data. For example, Amazon uses its database of customer purchasing patterns and preferences to recommend items that are likely to be of interest to a particular customer. Other machine learning models are fueled by unstructured data. Tesla uses its fleet of self-driving cars to collect data about driving patterns and conditions. The data is used for teaching self-driving cars how to avoid collisions and navigate through varying driving conditions. Another example is seen in Google Photos. When you take a photo, Googles machine learning models scan the image, an unstructured data type, to find what category it falls into. Then, users can search their own, previously unlabeled photos by categories like Nature or People. Most analytics tools are designed for structured data, making it easier than ever to analyze and gain value from structured data. With Akkio , for instance, you can upload structured data to build and deploy AI models in minutes. In the background, machine learning algorithms scan and digest the tabular data to find patterns, creating a model that can be deployed to find those patterns in new data. Unstructured data analysis is a less-common task, but its still highly important for businesses looking to gain value from their PDFs, image and audio data, and so on. Analyzing unstructured data is a complicated task, which is why its ignored by many businesses. Unstructured data can be difficult to process and understand because it's messy and in a variety of formats. Unstructured data may also be qualitative instead of quantitative, making it even harder to analyze. One use-case for unstructured data is to analyze reviews and comments on social media, both from your own company and from competitors, to inform competitive strategy. Another use-case is market analysis to find new opportunities. By analyzing unstructured market data, such as social media posts that mention customer needs, businesses can uncover opportunities for new products and features that may meet the needs of these potential customers. Quantitative data is a numerical set of information, such as the height and weight of each person in a group, alongside the size of the group. Quantitative data can be further divided into two sub-categories: Discrete and continuous data. Discrete data does not include measurements, which are along a spectrum, but instead refers to counting numbers, like the number of products in a customers shopping cart, or a count of financial transactions. Continuous data, on the other hand, refers to data that can meaningfully be broken down into smaller units, or placed on a scale, like a customers income, an employees salary, or the dollar size of a financial transaction. Qualitative data is non-numeric, such as whether or not a transaction is fraudulent, whether a review has positive or negative sentiment, or whether a sales deal has a high or low likelihood of being closed. Qualitative data is largely categorical, but it also includes things like text, whether its a tweet, a customer support ticket, or documentation. By the very meaning of the word, categorical data is simply data relating to categories, while quantitative data relates to quantities. Lets dive more deeply into the differences between quantitative and qualitative data, with the latter focusing on categorical data. It can be difficult to determine if your data is categorical or quantitative, but there are a few steps you can take to find out. If your data has a numerical range of values, like income, age, transaction size, or similar, its quantitative. If, on the other hand, there are categories, like Yes, Maybe, and No, its categorical. You should also consider the type of answers you're expecting from your data. Are you expecting an answer that has a range of values, or just one set of values? If you're expecting one set of values, like Fraud or Not Fraud, then its categorical. If youre expecting a range of values, like a certain dollar amount, then its quantitative. Quantitative data can be used to fuel a wide range of AI models. Lets explore a few examples. Quantitative machine learning algorithms can use various forms of regression analysis, for instance, to find the relationship between variables. To give a simple example, if one variable is the weight of a patient and the other variable is the height of a patient, then the relationship between these variables can be found by running regression analysis on a set of patients. Categorical data can also fuel a wide range of AI use-cases. Here are just a couple of examples. Categorical machine learning algorithms including clustering algorithms are used to identify groups within a dataset, where the groups are based on similarity. The technical algorithm names include Nave Bayes and K-nearest neighbors. Understanding the intricacies of these complex algorithms used to be a prerequisite to AI modeling, but you can now build and deploy these models in minutes, with no technical expertise needed. There are pros and cons to each type of data, and which data type to use depends on the situation. Quantitative data is inherently more precise than categorical data, as theres greater granularity in quantitative data. For example, a height of 72.5 inches is a lot more precise than the category tall. An income of 12,000 is a lot more precise than the category poor. By using categories, some information can be lost. For instance, one American with an annual income of 0 and another with an annual income of 12,000 are both classified in the same legal categorypovertyeven with significant differences in living situations. Similarly, someone with a net worth of 30 million and someone with a net worth of 100 billion are both classified as Ultra-High-Net-Worth Individuals, even while there are tens of thousands of individuals in the former category and just a few in the latter category. One disadvantage of quantitative data is that its harder to make sense of and model than categorical data. Categorical data inherently simplifies data by reducing the number of data points. Theres no simple answer as to whats the more common data type. Categorical data is often easier to collect. For example, given someones Facebook profile, you can likely get data on their race, gender, their favorite food, their interests, their education, their political party, and more, which are all examples of categorical data. On the other hand, you probably wouldnt be able to find out their exact income, their weight, their spending habits, or other exact quantitative metrics (with some exceptions like age). Under the hood, however, the situation is quite different, as Facebook collects vast amounts of data on each of its users, much of which is quantitative, such as the amount of time spent viewing a post, the number of posts viewed, the number of profile views, the number of link clicks, the number of application opens, and so on. Ultimately, we create large amounts of both data types every day, with virtually every action we take. When you pick up a new smartphone, sensors recognize that it was picked up, by tracking the exact spatial location of your phone at any point in time, which is an example of quantitative data. Then, as it recognizes that your phone was picked up, it may change a variable like Status to be Active instead of Inactive, causing your phones lock screen to light up. Time series data is a type of data that records events happening over time, which is especially useful in predicting future events. To give a very simple example, heres a time series dataset with three data points: In 1975, Earths global surface temperature was anomalous by 0.0 degrees Celsius, in 1995 it was 0.5 degrees Celsius higher than normal, and in 2015 it was 0.9 degrees Celsius higher than normal. One of the key tenets of time series data is that when something happens is as important as what happens. In marketing, for example, the time it takes a customer to go through the steps of the marketing funnel is an important predictor of revenue. One of the most important uses of time series data is forecasting. This is because the past is the best predictor of the future. Lets explore some common applications of time-series data, including forecasting and more. Marketing is a journey, and the customer's journey through the marketing funnel can seem unpredictable. However, there are many ways to predict the customer's journey and reach them at the appropriate time to increase customer engagement and conversion rates. By understanding customer journeys, marketers can also create a more relevant and compelling content experience for each stage of the journey. For example, if you are running a marketing campaign on Instagram and want to know how many clicks your advertisements will receive, you could forecast clicks based on historical data. To give another example, time series forecasting can be used to predict when customers will make their next purchase. This allows companies to make decisions about when to launch new products and when to send emails or other consumer messaging. Revenue run-rate is predicting revenue based on what has happened in the past. This is an important metric for companies because it helps them plan for future revenue needs. Revenue run-rate is an annual metric, which is traditionally calculated by multiplying the average revenue per month by 12, or the average revenue per quarter by 4. This will give a rough estimate of how much revenue the company will have per year. That said, this is a very rough method of estimating revenue, which can be highly inaccurate. For example, businesses like fitness centers typically out-perform in January, due to New Years resolutioners, so they wouldnt be able to accurately forecast revenue with traditional means. The opposite situation holds true for a landscaping company, which likely wont see much business in January. A number of other variables impact revenue as well, from dynamic budgets to new competitors or new product innovation. Traditional calculations, which are based purely on multiplying historical revenue, are ignoring all these other factors. Using Akkios forecasting, you can accurately predict revenue run-rate based on any number of complex variables in your data. Predicting stock and crypto prices is notoriously difficult, especially considering the technical difficulties of manually building and deploying forecasting models. That said, for investors who are interested in forecasting assets, time series data and machine learning are must-haves. With Akkio, you can connect time series data of stock and crypto assets to forecast prices. It's important to remember that stocks and crypto are different types of investments, as crypto markets are much smaller and more volatile. Investors should be wary of their own emotions when investing in stocks and crypto. Manufacturers are using time series AI for predictive maintenance and monitoring equipment health. The AI systems are able to identify when changes need to be made to improve efficiency. They are also able to predict when equipment will break down and send alerts before it happens. These technologies are saving manufacturers money by not having to spend on unexpected repairs or urgently replace machinery when it is no longer working. For non-experts, finding high-quality time series datasets is a challenge. Fortunately, there are a huge amount of free, high-quality time series dataset sources available online. Lets explore a couple of time series dataset sources. The UCI repository features 48 time-series datasets, ranging from air quality to sales forecasting data. Most of the data is offered in CSV format, so its easy to read with tools like Akkio, with no manual pre-processing needed. Just connect a dataset, and youre good to go! The World Bank provides a wildly extensive databank featuring 79 databases for 264 countries with data as far back as 1960. The World Development Indicators database, for example, includes over 1,440 data columns to pick from, ranging from high-level indicators like percent access to electricity to very niche indicators like rural population living in areas where elevation is below 5 meters. The Education Statistics database includes almost 4,000 data columns. Theres no easy answer to how many time-series datasets are offered, but if you treat each potential time-series dataset as a univariate problem, then there are millions of datasets from this source alone (79 databases across 264 countries with an average of 2,000 data columns). Time series data can be a particularly tricky data type to work with, for a number of reasons. Weve highlighted some special considerations to keep in mind when working with time-series data. In a time-series dataset, the temporal aspect is crucial, but many machine learning algorithms dont use this temporal aspect, which creates misleading models that arent actually predictive of the future. For example, a random walk model is a stochastic process, which means that its simply not possible for it to accurately predict future outcomes from historical data. To give another example, basic regression models ignore temporal correlation in the observed data and predict the next value of the time series based merely on linear regression methods. Moreover, many time series models can easily overfit to the data, by finding spurious correlations, instead of causal variables. For example, theres a positive correlation between ice cream sales and murder, but obviously not because eating ice cream makes you want to murder people. This is whats known as a spurious correlation. In the case of ice cream sales and murder, whats happening is that ice cream sales increase in the summer, which is when more people go outside, causing a natural increase in crime (fewer crimes are committed when everyones bundled up inside during the winter, versus, say, when theres a sports events in the summer with 50,000 attendees packed in a stadium). Modeling time series data is an intensive effort, requiring pre-processing, data cleaning, stationarity tests, stationarization methods like detrending or differencing, finding optimal parameters, and more. Doing this manually requires a high degree of technical expertise, not to mention a large time commitment. With Akkio, these complex processes are automated in the back-end, so you can forecast data effortlessly. If youve ever considered investing, youve likely read a financial disclaimer along the lines of: Past performance is no guarantee of future results. Its actually a legal requirement for asset management firms to give such a disclaimer, because, well, theres really no way to know what the future holds. The best we can do is assign probabilities to certain values. Indeed, even generating accurate probabilities is immensely challenging, as the world is constantly changing. Predicting COVID-19 cases is a great example of the challenges of time series forecasting, as virtually all forecasts failed . Even now, accurate forecasts are extremely difficult, considering that much past data is no longer relevant for the future, given new vaccines, new strains, and ever-changing regulations around travel, social distancing, quarantines, and so on. Feature engineering is the process of creating new features from existing data. One challenge with time series data is that its often not stationary. Stationarity means that a time series is a sequence of observations of the same variable, taken at equally spaced times. If the observations are equally spaced in time and do not contain any trends or seasonality, then its stationary. Creating stationary data is a form of feature engineering, and the two most common techniques for transforming time series into stationary data are differencing and transforming. That said, with no-code AI tools like Akkio, you can build and deploy time series models without any manual feature engineering needed, as this is all done automatically after a dataset is connected. Data is the fuel that makes machine learning tick. For the most part, the more data you have, the more accurate your model will be, but there are many cases where you can get by with less. Machine learning models are pattern matching machines. They can only capture and predict patterns that have been seen before. This is the one big catch with machine learning. If you want to predict what happens with new data, the model has to have seen similar data before. It's also important to note that there's no golden rule for how much data you need. For example, while Akkios lead scoring demo dataset has over 40,000 rows of data, the text classification demo dataset has just 1,000 rows of data, and both achieve roughly 90 accuracy. Meanwhile, the credit card fraud demo dataset has nearly 300,000 rows of data! It's best to explore the modeling process for your dataset and see what it takes to get high accuracy. Accurate machine learning models can be made with as little as a few hundred rows of data. If you truly have extremely little data, say less than a few hundred rows, you can try a few things. One is data augmentation: A process where data is generated by adding in fake data examples. You can also merge in other datasets, whether internal or external, on shared columns to increase the overall dataset size. For example, suppose youre building a model to classify customer support tickets based on urgency. If you need more data, youll want to ensure that you have a pipeline in place thats generating this data for you. In such a case, your support teams should be tagging the urgency of incoming tickets, so you can later export this data to fuel your machine learning model. Depending on the use-case, you can even turn to crowdsourcing platforms like Amazon Mechanical Turk. These platforms allow you to hire people from all over the world to do small tasks for you at low prices, like collecting and labelling data. You may not want to do this if you're a small company with limited resources, but if you're a large company and want more data quickly, this may be a good option for you. Yet another method is to scrape data from the Internet, which is again use-case dependent, but potentially an easy way to boost your dataset size, given the open nature of a lot of Internet data, such as social media posts. There are instances when it feels like you could have too much data. If your dataset is too large, it becomes difficult to explore and understand what the data is telling you. This is particularly the case with big data in the order of many gigabytes, or even terabytes, which cannot be analyzed with regular tools like Excel or even typical Python Pandas code. Given that its possible to make high-quality machine learning models with much smaller datasets, this problem can be solved by sampling from the larger dataset, and using the derived, smaller sample to build and deploy models. A good example of a massive AI model is Googles latest language model , which is an incredible 1.6 trillion parameters in sizetoo large for us to practically comprehend, though for comparison, there are just 86 billion neurons in the human brain. At the same time, its possible to build machine learning models that are around 10 orders of magnitude smaller than Googles language model. For example, the perceptron is a classifier that was developed in the 1950s. These single-layer neural networks are trained by assigning inputs to different outputs, with the network adjusting its weights until it can correctly predict the output for new inputs. The perceptron is limited by its lack of memory and by not being able to extrapolate relationships between data points that it might not have seen, but at its core, it can be the basis of a functioning model with just a few parameters. It's important to remember that quantity isn't everything when it comes to data. Even if you have a lot of data, your model may not work well. In order to have high quality models, you need high quality data. This means that your data needs to be clean and easy to work with so that it can be used effectively. In other words, its better to have a small, high-quality dataset thats indicative of the problem that youre trying to solve, than a large, generic dataset riddled with quality issues. After all, not all data is valuable. As Nate Silver, Founder of FiveThirtyEight, says : Every day, three times per second, we produce the equivalent of the amount of data that the Library of Congress has in its entire print collection, right? But most of it is like cat videos on YouTube or 13-year-olds exchanging text messages about the next Twilight movie. Machine learning is getting easier and faster. There's no need to waste a lot of time on preparation, as a huge dataset isnt a prerequisite. As Adam Savage puts it: In the spirit of science, there really is no such thing as a failed experiment. Simply experiment and see how much data you need. In the last few years, machine learning and AI tools have been getting simpler and faster. The days of waiting weeks or months for building and deploying models are over. With Akkio, you can build a model in as little as 10 seconds, which means that the process of figuring out how much data you really need for an effective model is quick and effortless. With traditional machine learning, you typically need a large dataset in order to get sufficient training data. But with Akkio, it's possible to create compelling models with as little as 100 or 1000 examples. As weve explored, if you find that youre not getting great results with a small dataset, you can always try merging on new data, data augmentation, crowdsourcing platforms, or simply turning to online dataset sources. Preparing your data for the training of a machine learning model can range from simply connecting your existing business operations technology platforms (Salesforce, Marketo, and Hubspot, etc) and data-stores (Snowflake, Google Big Query, etc) to business wide data hygiene programs that take months but yield clean data for optimum performance. You also need to narrow down the dataset used for training so it only has the information available to you when you want to predict a key outcome. We have designed Akkio to work with messy data as well as clean - and are firm believers in capturing 90 of the value of machine learning at a fraction of the cost of a data hygiene initiative. To learn more about preparing your data for machine learning click here . The performance of a machine learning model is primarily dependent on the predictive accuracy of its training dataset with respect to the outcome of interest. If you were able to know everything about a system (quantum physics aside) you would be able to perfectly predict its future state. In reality most datasets contain a small subset of information about a system - but that is often more than enough to build a valuable ML model. That said, adding in additional data can often help improve predictive performance. This is called data augmentation. To learn more about data augmentation for machine learning click here . One very important thing to be aware of when using machine learning is that biases in the dataset used to train the model will be reflected in the decision making of the model itself. Sometimes these biases are not obvious in your data - take for example zip or postal codes. Location information encodes a lot of information that might not be obvious at first glance - everything from weather to population density to income, housing, to demographics information like age and ethnicity. These patterns can be helpful, but also have the potential to be harmful when the models are used in ways that reinforce unwanted discriminatory outcomes (both ethically and legally). Click here to learn more about bias in machine learning and how to minimize it. Machine learning is a subset of artificial intelligence that is focused on systems that can learn from data. While well explore some of the top applications of machine learning across a number of industries, the academic world is also using AI, largely for research in areas such as biology, chemistry, and materials science. Renewable energy is one of the fastest-growing sources of power generation worldwide. In 2020, it accounted for 80 percent of new power capacity globally. AI is critical for successful adoption. AI can balance electricity supply and demand needs in real-time, optimize energy use and storage to reduce rates, and help integrate new, clean sources into existing infrastructures. AI can also predict and prevent power outages in the future by learning from past events. For example, when a grid is overwhelmed by demand, AI can forecast the trajectory for that grids flow of energy and power usage, then act to prevent a power outage. AI can also predict when a power outage will occur in the future, so utilities can take proactive measures to minimize the outages effects. Additionally, AI can even help with wind energy. The power of the wind is ever-present, but harnessing it is not easy. Windmills have been used for centuries to capture wind power, but this process is difficult and costly. But now AI can change the game. AI can calculate how wind turbines should be rotated so that as few turbines as possible are in the wind shadow of the other. Using data collected from the terrain, the height and size of the turbines, and meteorological data, AI can work out how wind turbines should be rotated to harness the wind. The insurance industry is highly competitive. The simple fact is that if you are not consistently profitable, you will be driven out of the market. To maintain profitability, insurance firms must be able to accurately predict high-risk, high-cost individuals. Indeed, data shows that 70 percent of new North American insurance companies fail within 10 years. This is the status quo, as insurance firms often cannot accurately price their plans, leading to tremendous losses. AI has been shown to be highly accurate when it comes to predicting future claims costs. This accuracy allows you to assess the risk of insuring an individual based on their past claims history and use this information to correctly price your premiums. This is crucial because it will allow you to stay profitable in a high-risk industry where you are always at risk of being driven out of business by adverse selection. With Akkio, AI-powered cost modeling can be done in clicks, enabling insurers to leapfrog competitors that are stuck using traditional, laborious, and inaccurate cost models. This cost modeling solves one of the biggest problems insurers face today: Choosing who to insure, and at what rates. In the insurance industry, it's all about risk management. And when you're making predictions about risk, you want to do it right. In the past, the industry relied on outdated modeling techniques that often led to under- or over-pricing claims. That led to higher premiums for consumers and a host of other problems. But AI is solving this problem. With these new machine learning techniques, it's possible to accurately predict a claim cost and build accurate prediction models within minutes. Not only that, but insurers can even build models to predict how claims costs will change, and account for case estimation changes. That means insurance companies can price their policies more accurately and offer lower premiums for consumers, leading to lower costs of coverage for everyone. It also helps insurers be more competitive and attract more customers, which is especially important as the industry faces stiff competition. Akkios platform makes this possible by enabling users to create models based on their own data, and then deploy them across any number of environments with just a few clicks. This reduces the need for costly and time-consuming custom development work, and translates into lower costs for the company overall. It also enables insurers to respond faster to a changing insurance market, which provides a critical edge against competitors that are still relying on outdated techniques like regression modeling in Excel. The result is an improved customer experience that translates into higher sales volume and happier shareholders. Claims are a major expense for insurance companies and a frustrating process for policyholders. At the same time, insurance claims are extremely common , as by the age of 34, every person driving since they were 16 are likely to have filed at least one car insurance claim. The inefficiencies in processing claims is bad for both parties: the customer wastes time and the insurance company spends more on processing than they could have spent on settling the claim. Akkio's no-code machine learning can model when it's best to pay off claims automatically, so that you can minimize wait times for customers and maximize ROI for your business. Predicting when a customer will make a claim is not simple. Your risk profile changes over time, and so does the competitiveness of your market. Given the right historical data, Akkio's machine learning models take all of this into account, making it easy to find the optimal solution for your specific needs. Simply upload your data, and let Akkio do the heavy lifting, giving you more time to focus on what really matters: running your business. Insurance companies are always searching for new ways to attract new customers, and they need to optimize their marketing efforts to help them grow. A key problem that many insurance companies are struggling with is how to make accurate pricing decisions. Given that insurance is sold by quoting a policy, accurately estimating the conversion rate from quote to policy is essential. Akkio allows you to gather historical data, make estimates about the probability of conversion, and then use those predictions to drive your pricing decisions. Accurately modeling insurance conversion is key because it is an important determinant of insurance company profitability. A key benefit of an AI-based approach is that it allows insurance companies to adjust prices for customer segments without manually creating and testing a wide range of pricing variants. This ensures that marketing dollars are spent effectively and efficiently on segments where there is the greatest chance of conversion. With over 40 billion in insurance fraud in the US alone, according to FBI statistics, it's no wonder that insurers are looking for ways to reduce fraudulent payouts. One solution is to use machine learning to create models that can predict the probability of a claim being legitimate or not. Fraudulent claim modeling is an excellent example of how predictive modeling can be used to analyze fraud in the insurance industry. Using a model built on past payouts, an insurer could, for instance, apply a scoring system to claims and automatically reject or flag those with high probability of being fraudulent. Fraudulent claims dont just reduce the bottom-line for insurers, they can even lead directly to corporate bankruptcy, as research indicates . Moreover, fraud hurts consumers, who pay up to 700 a year in the form of increased premiums, in the US. The traditional means of detecting fraud are inefficient and ineffective, as its impossible for humans to manually analyze vast amounts of data at scale, which lets fraud slip through the cracks. Akkio's potential in this area goes beyond the insurance industry. Modeling fraud is a popular use-case in the financial sector as well, for example to help eliminate fraudulent credit card applications and transactions. Many life insurance companies do not underwrite customers who suffered from some serious diseases such as cancer. This is because it requires them to spend a long and expensive medical assessment process on the customer. In insurance, the term impaired refers to applicants who dont meet the standard criteria to obtain a very affordable rate. As a result, impaired applicants are often un- or under-insured. It's a wise business decision to increase the coverage for impaired customers and Akkios AI is able to provide that capability. While many who suffer from a serious disease can be accurately identified through a questionnaire, Akkio can achieve an even higher degree of accuracy by integrating the applicant's medical history and conditions. AI-driven predictive models use these factors to predict the risk of underwriting a serious disease survivor. The model predicts the risk of death, which is the ultimate impairment in insurance. For insurers, its possible to build the model in just minutes, opening up a new line of business and boosting the bottom line. Credit card fraud is a huge problem costing billions of dollars per year. Fraudulent transactions cost 28 billion in 2018, and they continue to grow rapidly. In fact, annual losses are expected to exceed 40 billion by the end of the decade. With Akkio's no-code machine learning, the likelihood of fraudulent transactions can be predicted effortlessly. This reduces the number of fraudulent transactions, while at the same time increases customer satisfaction. For banks, this means less cost per transaction and more revenue and profit. Akkio's fraud detection for credit card transactions is one example of how Akkio can help banks. By using a historical transaction dataset, machine learning models identify suspicious patterns and account for factors that are often overlooked in credit card transactions, like IP address changes, high-risk browsing behavior, or a low level of engagement with the transaction. By using proprietary AI training methods, Akkio can be used to build fraudulent transaction models in minutes, which can be deployed in any setting via API. Credit default rate is the percentage of loans that default. The credit default rate problem is difficult to model due to its complexity, with many factors influencing an individual's or company's likelihood of default, such as industry, credit score, income, and time. Understanding the factors that lead to credit card defaults can help lenders better assess the risk of lending to borrowers, and ultimately boost the bottom-line. Credit risk is a measure of the likelihood that a person will be unable to repay a debt, and this is what lenders use to determine whether or not to offer credit. In finance, credit risk is the risk of default on an obligation that arises due to the uncertainty of future cash flow. Akkio's API can help any organization that needs accurate credit risk models in a fraction of the time it would take to build them on their own. Akkio makes it easy to build a model that predicts the likelihood of default based on data from the past. In addition, Akkio can be used for automatic model retraining, so that once a model is built, it's easy to maintain and update as needed. This makes it possible for organizations not just to save time on predictive modeling tasks but also to be confident in their models at all times. Digital Wealth Management is a competitive field. In this market, it's not just about having the best investment products, but also about how to distribute them effectively while managing client assets. Akkio's machine learning algorithms can be deployed to constantly analyze data from your existing clients' portfolios to find new opportunities and assign values for each of your prospects. It's important to diversify your portfolio to make sure you are investing in the right technologies and companies. AI can help diversity portfolios by finding new investment opportunities Akkio helps asset managers learn which customers are more likely to invest in particular categories based on their previous investments and demographic information, as well as information like their risk appetite. AI can even be used to automate investment analysis, by ingesting financial data from sources like a securities market to predict the probability of stock prices rising or falling. These predictions can then provide real-time strategy recommendations for individuals or institutional investors. The result? A successful asset management strategy that attracts new clients and captures a greater share of existing client assets at the same time. Further, algorithms have been used in stock trading for decades. For example, a 1986 New York Times article titled Wall Streets Tomorrow Machine discussed the use of computers for evaluating new trading opportunities. Todays AI trading is a form of automated trading that uses algorithms to find patterns in the market and make trades. AI traders can also be used to optimize portfolios with respect to risk and return objectives and are often used in trading organizations. AI-powered trading systems can also use sentiment analysis to identify trading opportunities in the securities market. Sophisticated AI algorithms can find buy and sell signals based on the tone of social media posts. A blockchain is a decentralized database that stores information in blocks of data. The blocks are linked together through cryptography to create a history of all transactions. The system relies on consensus among the users of the network about the validity of information and data, making blockchains more secure than other types of databases. However, as blockchain technology becomes more popular, security threats are also increasing. Larger blockchains like Bitcoin and Ethereum are practically impossible to attack due to the sheer amount of resources required. That said there are hundreds of smaller blockchains at risk. MIT Technology Review reports , marketing slogans and headlines that called the technology unhackable were dead wrong, as blockchains can be rewritten if an attacker is able to muster over 51 of the computational power defending a network allowing the attacker to reallocate ownership of funds. One such example is when Ethereum Classic (a fork off of Ethereum) suffered a 51 attack 3 times in a single month . In 2020, there were over 120 blockchain attacks, leading to losses to the tune of nearly 4 billion. While preventing 51 attacks depends on distributed participants allocating compute resources to chain defense, users and exchanges need to be able to detect anomalous behavior when it happens on a chain (so they can attempt to minimize loss of funds). Akkio's machine learning algorithms can detect anomalies in real-time, alerting you and enabling you to take action quickly before additional damage is done. With Akkio's AutoML, it only takes minutes to build a fraud detection system tailored to your needs. The pharmaceutical supply chain is notoriously fragile , leading to shortages, higher costs, and safety issues. Part of these issues lie in under-optimized drug delivery systems. Pharmaceutical firms spend millions of dollars shipping drug samples to doctors and hospitals. Simple analyses uncover situations for order consolidation, such as when the same location requests two or more drug samples. However, manually looking at the data for order consolidation quickly becomes infeasible at scale. AI helps optimize supply chain delivery processes by predicting which orders can be consolidated, no matter how complex or how many orders there are to process. Thats the killer advantage of AI: Its incredibly fast and accurate compared to traditional techniques. AI can be used to find the best locations for consolidated shipping, estimate cost savings, and improve customer satisfaction. Instead of putting out fires related to unoptimized supply chains, health systems can now focus on what truly matters: Helping patients. In a world of virtually unlimited data and powerful analytics, it's easy to see why health systems are looking for ways to better understand the health of their patients. With AI platforms, teams can connect to various data sources, like lab results and HIE, and use machine learning models to predict the severity of a patient's condition and what type of care they will need. Medical professionals should consider screening patients that may have a higher likelihood for a particular disease. If they see a patient that could be predisposed to developing an illness, treating them right away will lead to better health outcomes, in addition to being more fiscally responsible than not seeing them until they're carrying it. Ultimately, using AI to automate disease propensity modeling has the potential to save hospitals and other healthcare providers millions of dollars per year by reducing unnecessary emergency room visits and readmissions. Staffing and budgeting for a hospital ICU is always a difficult decision, and it's even harder when you don't know how quickly the patient load will change. With machine learning, hospitals can easily make projections about their occupancy by modeling historic data to account for trends. Exceeding capacity limits, as has happened in ICU rooms around the world as of late, often results directly in patient death. Higher occupancy rates are clearly correlated to higher death rates . With AI, hospitals can quickly create a model that forecasts occupancy rates, which consequently leads to more accurate budgeting and staffing decisions. Machine learning models help hospitals save lives, reduce staffing inefficiencies, and better prepare for incoming patients. Forecasting models also help hospitals make better decisions about what services they need to offer their patients. Healthcare has been rapidly changing over the last few years, with an increased focus on providing holistic care and individualized treatment plans. Further, forecasting can help hospitals anticipate patient needs and provide the right services to meet expectations. Ultimately, machine learning algorithms make it easy for hospitals to predict the next step in their operations and make more informed decisions about future staffing needs. The result is healthier, happier patients and a stronger bottom line for hospitals. Sepsis is a life-threatening condition that can develop suddenly and with devastating consequences. It is a leading cause of death in intensive care units and in hospital settings, and the incidence of sepsis is on the rise . Doctors and nurses are constantly challenged by the need to quickly assess patient risk for developing sepsis, which can be difficult when symptoms are non-specific. Decades ago, sepsis wasnt much of a concern. Today, sepsis accounts for almost a fifth of human deaths. AI complements medical professionals' expertise by providing data-driven insights to identify patients at high risk for developing sepsis. Medical professionals can leverage the power of machine learning to aggregate patient data and generate automated alerts tailored to each patient's unique needs. Machine learning models are designed to learn from historical data, which can include past sepsis cases, to provide accurate predictions, enabling healthcare professionals to confidently identify patients at high risk for developing sepsis. The average cost of a hospital readmission ranges from 15,000 to 25,000 , which leads to wasted resources, unnecessary tests, potentially harmful treatments, delayed patient care, and other damaging consequences. Machine learning can help in reducing readmission risk via predictive analytics models that identify at-risk patients. By feeding in historical hospital discharge data, demographics, diagnosis codes, and other factors, medical professionals can calculate the probability that the patient will have a readmission. AI makes it easy for hospitals to identify which patients are most at-risk for readmissions. No-code AI tools dont require any IT work or coding, so hospitals can save money and improve the quality of care they provide. Ultimately, AI's hospital readmission risk use-case can help hospitals reduce their costs and increase the quality of care they are able to provide to their patients. Terrorism is a top concern for intelligence and law enforcement agencies around the world. After 911, preventing terrorist attacks became a heavily-funded, prime directive for a number of government agencies. As described in a United Nations Office of Counter-Terrorism report on AI , government agencies can use predictive modeling to identify red flags of radicalization, detect the spread of terrorist misinformation, and counter terrorist narratives. Machine learning isn't just for marketing; it can also be used to help prevent terror attacks by identifying patterns in past events and predicting future ones, saving lives, and making the world a safer place. Fraud is an issue that is costly, not only to the government and its citizens, but to companies as well. Every government agency from the IRS to the Social Security Administration suffers significant losses from fraud. In fact, as explored in an Association of Certified Fraud Examiners report , a study of nearly 3,000 cases of occupational fraud found that government entities ""were the most represented sectors among the fraud cases analyzed."" While much public discourse centers around governments as perpetrators of fraud, the reality is often that government employees and agencies are often the targets of a wide-range of fraudulent activities. Fraudulent activities can be difficult to detect, costing agencies valuable time and resources. Ultimately, AI makes it easy for government agencies to detect fraudulent activities as they happen, saving them time and resources while also safeguarding taxpayer dollars. In the age of digital transformation, attack vectors are getting ever larger. As a result, even government agencies are at risk of being breached by insiders (or ex-employees) who want to use their data for malicious purposes. At the same time, there are a number of insider threats that can seem innocuous in nature, but costly nonetheless, such as sending company information over a personal account, or even accidentally misconfiguring access credentials. For example, while cybersecurity firms like to keep their exact techniques private, research shows that AI can accurately identify malicious emails, which cost governments billions of dollars if undetected. To make sure that firms dont have to pay for these kinds of internal breaches, agencies need to proactively block any potential misuse, using machine learning to identify risks. Cyberattacks are on the rise, with real-world consequences for everyday people. Recently, for instance, hackers stopped gasoline and jet fuel pipelines and closed off beef and pork production at a leading US supplier. These are just a couple of examples of the tens of thousands of annual cybersecurity attacks. One of the main challenges in cybersecurity today is an ever-growing attack vector. As more and more of our world goes digital, theres more data to keep track of, and its easier for hackers to go unnoticed. Manually combing through this data can only get you so far, but AI can scan massive amounts of data in real-time. No-code AI enables security teams to build, deploy and refresh models to predict incoming threats in real-time, whether its scanning incoming emails for malicious threats or flagging concerning IP activity, so they can prevent a breach before it happens. Ultimately, this enables security teams to reduce their risk exposure and prepare for an increasingly hostile cyber landscape. Teams that fail to deploy AI for cybersecurity will be more vulnerable to attacks compared to other market players who do. Good customer service is of universal importance, with surveys indicating that 96 of customers feel customer service is important in their choice of loyalty to a brand. Customer service is also a major factor in customer retention. In other words, people are more likely to stay with a company if they're satisfied with the service they receive. AI-based classification of customer support tickets can help companies respond to queries in an efficient manner. By combining natural language processing and machine learning, AI can be used to automatically group queries into predefined categories, making it easy for customer support teams to select the appropriate department to handle a query based on their area of expertise. Essentially, by digesting past queries to find patterns in terms of content, AI can learn how to classify new tickets more accurately and efficiently. This means that with time, AI-based ticket classification will become an integral part of any organizations customer service strategy. Customer support teams need to handle a huge number of customer queries in a limited time, and they're often not sure which tickets need to be addressed first. Machine learning models can rank tickets according to their urgency, with the most urgent tickets addressed first. This relieves teams of the burden of deciding which tickets require the most attention, freeing up more time for actually addressing tickets and satisfying customers. Predictive analytics is also useful for identifying patterns in the data so that customer queries can be more accurately met with answers, and it allows teams to improve their customer experience by responding faster. Social media is an invaluable tool for marketing and customer support teams, but it's a complicated and fast-moving landscape. Every day, millions of people post their thoughts, opinions, and suggestions to social media about brands they're interacting with. From a raving comment to a scathing review, social media posts can have a big impact on your company's success. Machine learning can help teams make sense of the vast amount of social media data, by automatically classifying the sentiment of posts in real-time thanks to models trained on historical data. This enables teams to respond faster and more effectively to customer feedback. Ultimately, this allows marketers and customer service teams to identify early warning signs of dissatisfaction before they spiral out of control and needlessly drive away customers. In the process of data entry, we know that errors will be made. Humans are not perfect and this includes those who code the data: editing mistakes can occur such as inverting an S or a Z in the input document. It is reasonable to assume that there may be multiple copies of your records in which different people may have typed one letter wrong or did not notice inconsistent formatting, such as smith versus Smith, before saving it as a new version. Additionally, data can be brought in by multiple systems, with different column values, such that duplicates wont be found by traditional means (e.g. one system has the first and last name, while another system has their email). Detecting duplicates is notoriously difficult, requiring manual intervention to identify duplicate records. This can be time-consuming and prone to human error. AI is different: it's fully automated and can detect duplicates for all types of fields with high accuracy. AI is essential for complex deduplication tasks, because the same record could show up multiple times throughout your database. With AI, you can detect these duplicates even if they have different data fields - making it easy to clean up your database so that it adheres to best practices without any manual intervention. Lead scoring is a powerful way to determine which leads are most in need of your attention. AI enables teams to automatically predict the likelihood that each lead will become a paying customer. Armed with these insights, marketing teams can decide which leads to pursue and spend time on, and which to put on the back-burner. Todays lead scoring is powered by machine learning that leverages any historical data, whether from Salesforce, Snowflake, Google Sheets, or any other source, to predict the likelihood a given lead will convert. This insight helps marketing teams to identify leads that are in need of more attention, as well as those that are likely to be a waste of time for the team. As a business, forecasting is one of your most important tasks. It's what allows you to plan ahead and make better use of your budget. Machine learning can help you do that with unparalleled accuracy, even in unpredictable economic environments. No-code AI can be used to quickly build a model from past sales data and predict the sales you're likely to receive in the future. With no-code AI, you can get accurate forecasts in a matter of seconds by uploading your product catalog and past sales data. Instead of relying on rules of thumb or gut feelings, AI offers a more scientific approach that lets you make better decisions about your budget, staff hiring, and promotional campaigns. This is essential for businesses that need to know how to budget for the future or optimize their limited resources. Forecasting models can be deployed through a web-based interface, API, Salesforce, or even through Zapier, making it easy to get started in any setting without requiring any data science know-how. The way we consume goods has changed. In the past, we would go to the store, pick out what we needed, and purchase it. Nowadays, we can order what we need from the comfort of our own home and have it delivered to our door. As a result, the way we are marketed to has changed. Direct marketing is an excellent way for businesses to reach their potential customers, and its a largely under-utilized opportunity. That said, it's often difficult to determine which prospects are the most likely to purchase. Marketing to uninterested leads isnt just a waste of time and money - it can be a huge turn-off to those leads from ever deciding to make a purchase decision. That's where data-driven AI comes in. AI can find the best prospects among a particular group and determine the best way to reach them. This means you can quickly and easily identify the most valuable leads, and then contact them with a personalized message that speaks to their particular needs. With no-code AI, you can effortlessly prioritize and classify leads based on their likelihood of converting, all at a fraction of the time and cost that traditional methods require. A loyalty program is a reward program that gives points or other awards to customers who shop at a particular establishment. A typical example might be a program that provides each customer with ten points for every dollar spent at the store, and if a customer collects 1,000 points, they are given 10 off their purchase. Loyalty programs are designed to incentivize customers to shop with the company on a regular basis, and they usually consist of various tiers of rewards, depending on how much the customer spends each time. The most effective type of loyalty program is one that provides increased benefits based on the amount of money spent, as customers are more likely to be motivated by the prospect of an increased reward. Unfortunately, even if you have a good understanding of your customers' behaviors and preferences, it is not easy to predict which rewards will incentivize them most effectively. While your neighborhood coffee shop might offer a free coffee for every fifth visit, the scale and complexity of loyalty programs are orders of magnitude greater for large, data-driven firms. Machine learning algorithms can analyze past data and detect which customer segments are most likely to respond positively to certain rewards. This helps managers make informed decisions about which rewards to offer and when, increasing the likelihood that they will convert. One of the best ways that marketers can create a personalized experience for customers is by considering the ""next best offer."" This requires marketers to take into account all of the possible actions they could take with that customer and then select the most appropriate one. As an example, suppose that a customer visits a website for information on renting. The customer can't decide between a studio or one-bedroom apartment, so she searches for more information on both and cannot find any definitive information. In this case, the ""next best offer"" could be to create a personalized email with links to articles and videos from both types of apartments, so the customer can decide which one is better for her. Doing this manually is clearly impossible at scale. Businesses can use AI to offer the right product to the right person at the right time. Businesses can automatically make recommendations in real-time, using predictive models that account for customer preferences, price sensitivity, and product availability, or any data provided for training. Predicting the right offer for the right person at the right time is a huge undertaking, but AI makes it easy for retailers to optimize their operations. Best of all, retailers don't need any data scientists or AI specialists to deploy predictive models - no-code AI automatically powers recommendations with no coding required. If your marketing budget includes advertising on social media, the web, TV, and more, it can be difficult to tell which channels are most responsible for driving sales. With machine learning-driven attribution modeling, teams can quickly and easily identify which marketing activities are driving the most revenue. Marketing attribution models are traditionally built through large-scale statistical analysis, which is time-consuming and expensive. No-code AI platforms can build accurate attribution models in just seconds, and non-technical teams can deploy the models in any setting. This lets marketing teams keep costs down while still pinpointing exactly where to allocate their marketing budget to optimize for the best ROI. Ultimately, this makes it easier to ensure that every dollar spent on marketing is worth it, so you're consistently getting the most out of your marketing budget. By automating attribution, marketers can overcome the boring stuff and get more creative with what really matters. Armed with knowledge on how specific channels are performing, marketers can finally double-down on high-performing channels, eliminate the laggards, and strategize how to move forward. Consumers today expect personalized products and content. Machine learning enables businesses to finally target consumers with the right message, at the right time, and on the right channel. For example, rather than using one message to reach everyone on your website, machine learning could be used for sentiment analysis of customer reviews on your site, or your CRM or social media tools, to present different customer segments with different messages. In addition, AI platforms can be trained on historical product purchase data to build a product recommendations model. For example, if a customer has purchased a certain product in the past, an AI API can be deployed to recommend related products that the customer is likely to be interested in. This can be a powerful propellant for the bottom line, as research shows that 80 of consumers are more likely to make a purchase when brands offer personalized experiences. Beyond personalized experiences, AI can even be used for personalizing products and services themselves. While today, many of these individualized products are created by an individual designer or a custom order, personalized AI will make this process much more efficient, tailoring the product to an individual customer's needs and delivering it in a matter of days. The churn rate, also known as the rate of attrition, is the number of customers who discontinue their subscriptions within a given time period. For a company to grow, it must acquire more new customers than its churn rate. It's quite a challenge to prevent customer churn, which is why it's so important for companies to be proactive. Fortunately, AI has the power to do just that. Machine learning algorithms can identify the data patterns common among customers who are likely to churn, such as those with a high cost of acquisition or those that are misaligned with your ideal customer persona. Armed with this knowledge, you can optimize your retention strategy by targeting high-risk customers with personalized offers or incentives before they leave. Moreover, marketing teams can tailor their strategies to avoid high-churn-profile leads. The more data you have, the better. AI platforms like Akkio allow you to work with your data sources wherever they are - your CRM system, data warehouses, and other databases - to create the best model for predicting churn for your business. When it comes to marketing, there are always more tactics to explore than time or resources allow. Trying to decide which channel or activity to focus on that will have the biggest impact on revenue means you're forced to make guesses. AI can put those guesses to the test. Machine learning algorithms can be fed with data from all of your marketing channels, as well as customer lifecycle information, to identify which activities are most likely to move each individual customer closer to purchase. AB testing is a great way to figure out how best to allocate marketing resources, but only if you can measure success accurately. That's where machine learning excels: it's able not only to measure and predict sales, but also predict what might happen if you try any given marketing tactic. Google AdWords is a huge part of most advertising budgets, but it can be difficult to get bidding right. If you bid too low, you lose out on opportunities. If you bid too high, your marketing ROI will dwindle. However, machine learning can make this process easier by building a model off of past marketing and sales activities to predict the sales volume attributable to each AdWord, making it easy to determine the optimal price to bid to achieve your target ROI while avoiding losing the word to a competitor. It is incredibly difficult and time-consuming for teams to build auction models that can capture complex human behavior. But no-code AI can be used to build accurate models with just a few clicks. Companies can deploy these models easily with an API in any setting or even with no-code tools like Zapier. Ultimately, this enables marketing teams to boost the effectiveness of their ad spend, which is critical for success in an ever-more competitive landscape for consumer attention. Teams that fail to deploy AI for AdWords bidding will lose directly to their competitors that are using data-driven strategies. Lead scoring is a crucial part of any marketing campaign because it helps you focus your time and resources on the potential customers that are most likely to become paying customers. In other words, an accurate lead scoring model helps you go where the money is. In fact, over two-thirds of marketers point to lead scoring as a top revenue contributor. Accurate lead scoring can be tough, though. It's not easy to measure how well a customer will interact with your product without knowing much about them, so traditional lead scoring models rely on interest from the prospect to determine the score. Traditional approaches are highly limited, since they dont necessarily indicate the prospects ability or true probability of making a purchase. That's where AI comes in. Machine learning models use a wide range of factors to score marketing leads. With data-driven lead scoring models, you can have more confidence in your marketing decisions because you're looking at more data points than just interest from the prospect. Studies have shown that attracting and retaining top talent is one of the most important factors in a company's success. After all, the average employee exit costs an entire third of their annual salary. However, as employee-employer relationships are shifting, the challenge of getting and keeping top talent is getting tougher. Year after year, employee attrition is increasing, and some are calling this crisis  The Great Resignation . But there's hope: data. No-code AI platforms let HR professionals scan massive amounts of data - from hiring pipelines to employee history or performance reviews - to uncover insights to keep your best people working for your team. With no-code AI, you can use machine learning algorithms to create predictive models that let you predict when an employee might be considering a job change, when they might be considering leaving their current position, or if they're simply unsatisfied. This data-driven approach illuminates potential issues before they become major problems, giving HR teams the high-quality insights they need for more informed decision-making. With tools like Zapier, HR teams can even deploy predictive models in any setting without writing code. For many, machine learning might as well be magic. But the truth is, as weve seen, that its really just advanced statistics, empowered by the growth of data and more powerful computers. Having said that, machine learning models are incredibly versatile tools that can add tremendous value across business units. We saw earlier, for example, how finance teams can use machine learning to predict fraud , marketing teams can score leads or predict churn , HR teams can predict attrition , and more. Building the machine learning models to make these use-cases possible was once an arduous, resource-intensive task, requiring technical experts for data engineering, building pipelines, coding, maintaining infrastructure, and more. As weve explored, no-code AI allows anyone to create and deploy machine learning models on their own, without needing programming skills. However, to become truly AI-driven, getting AI to work for you is not a one-time upgrade. It is a journey that will require an understanding of data management and the use of machine learning. Another reason that code-based AI is problematic is that there is a shortage of programmers, and the shortfall is expected to grow as the AI industry grows. As ACM reports , theres actually a recent decrease in computer science graduates, in spite of increasing demand for them, fueled by delays in student visa processing, limited access to educational loans, and travel embargos. As weve seen, data is the fuel that powers machine learning engines, which is why data preparation is so important when building a model. The expression the more the merrier'' holds true in machine learning, which typically performs better with larger, high-quality datasets. With Akkio, you can connect this data from a number of sources, such as a CSV file, an Excel sheet, or from Snowflake (a data warehouse) or Salesforce (a Customer Relationship Manager). For example, suppose youd like to use AI to score sales leads . If your business uses Salesforce, you can directly connect your sales dataset, and then select a column that relates to whether or not a deal was closed. Many smaller sales teams keep it simple, using Google Sheets or Excel to organize lead data. Both of these sources can be easily connected to Akkio as well, and youd build the model in the same wayby selecting the column youd like to predict. On the other end of the spectrum, some larger firms use Snowflake for handling massive amounts of sales data, which can be easily integrated with Akkio as well. Weve explored how machine learning models are mathematical algorithms that are used to find patterns in data. To train a machine learning model, you need a high-quality dataset that is representative of the problem youre trying to solve. Lets walk through a practical example. In Akkio, you can train a model by hitting Add Step once a dataset is connected, and then Predict. Then, simply select the column to predict. Generally speaking, there are two kinds of models you can train: Classification models and regression models. A few examples of classification include fraud prediction, lead conversion prediction, and churn prediction. The output values of these examples are all Yes or No, or similar such classes. On the other hand, regression models are used to predict a range of output variables, such as sales revenue or costs. After selecting Predict, training either kind of model is the same: Youll select the column name you want to predict, whether its called conversion, churn, attrition, fraud, or any other metric. You also have the option to select a Training Mode, which ranges from 10 seconds of training time to 5 minutes, where longer training times may lead to more accurate models. While the training process is done in just a couple clicks, a lot of work is done in the background. It starts with software engineering to lay the groundwork for the platform itself. Software engineering is a branch of engineering that deals with the design, development, operation, and maintenance of software. Most of today's software development activities are performed by a team of engineers. But thats not all. DevOps is used to help bring AI applications to production. DevOps is a software development method that focuses on the collaboration between software developers and other IT professionals. It aims to shorten the time between the software's conception and its adoption by end users. In order to build the AI pattern recognition models themselves, a number of different approaches are used. Pattern recognition is the ability to identify a pattern in data and match that pattern in new data. This is a key part of machine learning, and it can be either supervised or unsupervised. The Bayesian approach to AI is a probabilistic approach to making decisions. Bayesian methods are used to estimate the probability of a hypothesis, based on prior knowledge and new evidence. Another technique is dimensionality reduction, a process that reduces the number of dimensions of a dataset by identifying which are important and removing those that are not. K-means clustering and PCA, or Principle Component Analysis, are two methods commonly used together. In order to group associated data points, k-means finds the partition in data, while PCA finds the cluster membership vector. Random forest is another common method. A random forest is a machine learning method that generates multiple decision trees on the same input features. The hierarchy of decision trees is built by randomly selecting observations to root each tree. Gradient descent is a commonly used technique in various model training methods. Its used to find the local minimum in a function through an iterative process of descending the gradient of error. These AI methods are often built with tools like TensorFlow, ONNX, and PyTorch. TensorFlow is an open-source software library for Machine Intelligence that provides a set of tools for data scientists and machine learning engineers to build and train neural nets. It is one of the most popular deep learning frameworks. ONNX is an open-source modeling language for neural networks that was created to make it easier for AI developers to transfer their algorithms between systems and applications. This open-source AI framework was made to be widely available to anyone who wants to use it. PyTorch is an open source machine learning library for Python, based on Torch. PyTorch provides GPU acceleration and can be used either as a command line tool or through Jupyter Notebooks. PyTorch has been designed with a Python-first approach, allowing researchers to prototype models quickly. All of these model training processes are iterative, and many technical model training considerations are accounted for. One of these concerns is overfitting, which happens when a model tries to predict every individual input that it might get instead of just being able to predict certain patterns in the data. There are best practices that can be followed when training machine learning models in order to prevent these mistakes from happening. One of these best practices is regularization, which helps with overfitting by shrinking parameters (e.g., weights) until they make less impact on predictions. An additional best practice for successful training is using cross validation. Another concern is called the curse of dimensionality. This happens when the number of inputs to a model gets too large for it to work properly, especially if many inputs are not statistically relevant to the outcome being predicted. A way to get around this is by simplifying or reducing the number of features or dimensions being used in order to make more accurate predictions - this is known as dimensionality reduction. One technique for dimensionality reduction is called Principal Component Analysis, or PCA. PCA turns a large amount of data into a few categories that are most useful for describing the properties of what youre measuring. Not all machine learning models are made equal. Theres a popular saying in the AI world: Garbage in, garbage out. If low-quality data is used to build a machine learning model, then the model will generate low-quality predictions as well. There are a number of metrics you can use to evaluate the performance of a model. After making any model in Akkio, you get a model report, including a Prediction Quality section. If youve built a classification model, the quality metrics include percentage accuracy, precision, recall, and F1 score, as well as the number of values predicted correctly and incorrectly for each class. Here are what these fields mean: Because forecasting is used to predict a range of values, as opposed to a limited set of classes, there are different evaluation metrics to consider. After building a forecasting model, such as for cost modeling, youll see an RMSE value and a field called usually within. RMSE stands for Root Mean Square Error, which is the standard deviation of the residuals (prediction errors). The usually within field provides values that are simpler to understand in context, such as a cost model thats usually within 40 of the actual value. VentureBeat reports that 87 machine learning models never make it into production. This is affirmed by a separate study indicating that just 14.6 of firms have deployed AI capabilities in production. We cant blame them. AI is a difficult task, and many companies try to reinvent the wheel by building their own data pipelines, model infrastructure, and more. At the same time, a McKinsey survey found that just 8 of respondents engaged in effective scaling practices. What this means is that many firms are building models, but are unable to deploy them, particularly at scale. With Akkio, businesses can effortlessly deploy models at scale in a range of environments. More technical users can use our API to serve predictions in practically any setting, while business users can deploy predictions directly in Salesforce, Snowflake, Google Sheets, and thousands of other apps with the power of Zapier. The term API is short for ""application programming interface,"" and it's a way for software to talk to other software. APIs are often used in cloud computing and IoT applications to connect systems, services, and devices. By querying Akkios API endpoints, businesses can send data to any model and get a prediction back in the form of a JSON data structure. For context, data structures refer to the way data is organized in a computer program. Data structures are built on two concepts: data types and data manipulation. Data types define the type of data in the structure, such as number, word, or image. Data manipulation defines how data is organized in the structure, such as linear, hierarchical, or tree. Models can even be deployed via web app to instantly get a URL to share with others. When you hit Deploy for a web app, youll also get an iFrame embed (an inline frame), which is an HTML tag that can be embedded in any site. Users who deploy models can take advantage of cloud storage that scales to accommodate unlimited data uploads. AI is the next growth engine for cloud storage, with a massive annual growth rate. Further, these cloud servers are home to huge Graphical Processing Unit (GPU) clusters. AI algorithms that require a lot of mathematical calculations, such as neural networks, are well suited to GPU processing, such that cloud servers enable unlimited scalability of model predictions. The importance of continuous learning in machine learning cannot be overstated. Continuous learning is the process of improving a system's performance by updating the system as new data becomes available. Continuous learning is the key to creating machine learning models that will be used years down the road. The process of updating a system with new data, or learning, is something that is done by people all the time. Continuous learning seeks to replicate this process in a machine. The key to building robust models that continue to be valuable in the future is to learn from new information as it becomes available. This would allow the machine to adjust its behavior accordingly when responding to new information, just like humans do. The more data a machine has, the more effective it will be at responding to new information. The extent to which continuous learning is applied will help determine how intelligent the system is and how well it responds to new situations. Machine Learning Operations (MLOps) is the compendium of services and tools that an organization uses to help train and deploy machine learning models. MLOps services help businesses and developers to get started with AI, with service offerings that include data preparation, model training, hyper-parameter tuning, model deployment, and ongoing monitoring and maintenance. Organizations with a large training pipeline need MLOps to efficiently scale training and production operations. These services allow developers to tap into the power of AI without having to invest as much in the infrastructure and expertise that are required to build AI systems. With Akkio, machine learning operations are standardized, streamlined, and automated in the background, allowing non-technical users to have access to the same caliber of features as industry experts. To recap, data preparation is the process of transforming raw data into a format that is appropriate for modeling, which makes it a key component of machine learning operations. This process typically includes splitting the data into parts for training and validation, and normalizing the data. This means randomly splitting the data into a set of two subsets, known as training data and testing data (this is called stratified sampling). The first subset is then trained to try and find patterns in the data, but the model doesn't know what's coming next. The second subset is used as new input the AI has never seen before, which helps better predict outcomes. That way, when you create predictions on new inputs using this model, they're more accurate, because you're using examples that have not already been seen by the model. Data preparation can also include normalizing values within one column so that each value falls between 0 and 1 or belongs to a particular range of values (a process known as binning). For example, if someone were providing demographic information about people who visit their website and are able to purchase goods online, it would be helpful to split them into male or female; under 18 or over 18 years old; and so on, in order to classify their behavior while browsing based on these groupings. The training phase is where machine learning models are generated out of algorithms. The algorithm may determine which features of the data are most predictive for the desired outcome. This phase can be divided into several sub-steps, including feature selection, model training, and hyperparameter optimization. The goal of feature selection is to find a subset of features that still captures variability in the data, while excluding those features that are irrelevant or have a weak correlation with the desired outcome. Machine learning algorithms are supported by inferential statistics to ""train"" the model, such that it is able to make ""inferences"" about new data. Machine learning will often operate via a feedback loop whereby input data starts with an empty algorithm, which then finds patterns in that data over the course of multiple iterations. That information is fed back into the algorithm which modifies its parameters and goes through another iteration for refinement, until the optimal model is found. Finally, hyperparameter optimization determines what set of hyperparameter settings should be used based on some criteria, such as cost or computational efficiency. Factors to consider when evaluating model hyperparameter tunings can include: The process of deploying an AI model is often the most difficult step of MLOps, which explains why so many AI models are built, but not deployed. There are a number of different considerations to plan for, including: How will data be queried? What product or service will the AI model be embedded into? How do we ensure that all pieces of the model will continue to work together as expected over time? These are just some of many questions which must be addressed before deployment. With Akkio, teams can deploy models without having to worry about these considerations, and can select their deployment environment in clicks. Nowadays, there are many creative ways to deploy AI. For instance, you can deploy models on mobile phones with limited bandwidth, or even offline-capable AI servers. Offline AI is a model deployment option that can be used to serve predictions locally, or at the edge, for use-cases like smart CCTVs that might be in a wireless dead zone, or even AI-powered medical diagnostic apps that deal with sensitive health data. Building and deploying any type of AI model can seem daunting, but with no-code AI tools like Akkio, its truly effortless. As long as teams have the data, which can come from tools like Salesforce, Snowflake, or even just a Google Sheets file, they can effortlessly train and deploy intelligent models, for everything from churn prediction to sales funnel optimization.",21272
https://medium.com/@amitvsolutions/machine-learning-101-the-complete-beginners-guide-to-machine-learning-686a30cbcf6b,Machine Learning 101: The Complete Beginners Guide to Machine Learning | by Amit Verma | Medium,"-- Listen Share Machine Learning is transforming every industry  from saving lives to increasing profits  making businesses smarter and society better. NEED FOR MACHINE LEARNING Goal of AI is to give cognitive skills to machines  the ability to see, hear, speak, read, understand, decide , just like humans. AI  GOAL To build machines with human-like intelligence. ML  TOOL To teach machines by learning from data. Machine Learning is a subfield of AI that allows machines to learn patterns from data and make decisions or predictions without being explicitly programmed. Instead of hard-coding rules, we give the machine data  algorithms  and it finds the rules itself. The Era of Computation (1940s1960s) : Computers were born to calculate what humans couldnt compute fast enough. The Era of Data  Storage (1970s2000s) : As information exploded, we needed computers to remember and manage our data. The Era of Intelligence (2010spresent) : Today, we need machines that can see, speak, listen, think  and act intelligently. These problems are not just about numbers  they require perception, learning, decision-making  i.e., cognitive skills . DATA is the solution and Data is the key. We can generate insights and patterns from data to solve real-world problems. Data generation is currently skyrocketing. With availability of so much data, its finally possible to build predictive models that can study and analyze complex data to find useful insight and deliver more accurate results. We use patterns in data to understand whats happening , why its happening , and what might happen next , so we can take the right actions . Machine Learning is the process  the methodology we use to train a machine to learn from data and become capable of making decisions on its own. Machine Learning improves decision making, uncover pattern and trends in data and performs computation on data. The machine learning process involves building a Predictive Model that can be used to find a solution for a Problem Statement. Before jumping into code or data, you need to clearly define what problem youre trying to solve . Example: In an e-commerce company, we want to predict whether a customer will cancel an order based on their past behavior and current order details. Predictive Variable (a.k.a. Feature, Independent Variable): These are the inputs  the variables that you feed into the model to make a prediction. They are also called features or explanatory variables . Response Variable (a.k.a. Target, Dependent Variable): This is the output you want to predict. Its the goal of the prediction task. Output (target variable): Order Canceled: Yes or No. Clearly identifying the response variable helps you define the ML problem type :- What kind of data is needed to solve the problem? Collect the data that might help solve the problem. This could be from databases, logs, sensors, files, or APIs. If available, from where i can get this data? How can i get this data? Download data or Web Scrapping? Example: From your order cancellation problem, gather- a) Customer profiles, b) Order history, c) Product data, d) Time of order, e)Delivery location, f) Feedback or complaints. Note : Data can be structured (tables), semi-structured (JSON), or unstructured (text, images). Raw data is messy! This step ensures your data is clean, complete, and usable . Data cleaning involves getting rid of inconsistencies in data such as missing values or redundant values. Tasks include:- 1)Handling missing values, 2)Removing duplicates, 3)Encoding categorical variables (e.g., Male, Female  0, 1), 4)Normalizing or scaling numbers and 5)Creating features from raw columns (e.g., extracting day of week from a timestamp). Example : If some orders have no delivery location, you can- Data exploration involves understanding the patterns and trends in data. At this stage all the useful insight are drawn and correlations between the variables are understood. Correlation simply means: How strongly does one variable move (increase or decrease) when another variable changes? Understand your data using visuals and statistics . This helps you: It helps us answer questions like: Example: 1) Use plots like histograms, scatter plots, box plots. 2)Correlation heatmaps to see how features relate to the output and 3)You might find that: Most canceled orders happen in remote locations or during holidays Goal: Gain insights to improve model performance and decide which features matter. At this stage a predictive models is built by using ML algorithms such as linear regression, decision trees etc. Choose an ML algorithm, split your data into training and testing sets , and use the training data to create a model . Example: Algorithm- Logistic Regression (for YesNo prediction). In this stage, we split our dataset into two parts- In this customer order example, output is based on categorical variable i.e. either order cancelled or not cancelled. In this case we use- classification algorithm. Evaluate how well your model performs on unseen data. The efficiency of the model is evaluated and any further improvements in the model are implemented. Key metrics : Accuracy, Precision  Recall (for imbalance), F1 Score and AUC-ROC. The testing dataset is used to check the efficiency of the model and how accurately it can predict the outcome. Example : Your model has 92 accuracy  sounds good. But precision  60 and recall  40? Not good for fraud detection or healthcare. Tune it. Further improvement in the model are done by using techniques like: Cross-validation, Hyperparameter tuning (Grid Search, Random Search) and Feature selection. Now your trained model is ready to predict on new, real-world data  make it available as a service or embed it in an app. Example: When a new customer places an order, your deployed model predicts- There is a 72 chance the order will be canceled  flag it for manual review. You can retrain the model regularly with fresh data  this is model lifecycle management . Supervised Learning is a technique in which we train or teach the machine using data which is well labelled. Real-World Example: Loan Approval Prediction Semi-supervised learning is a branch of machine learning that combines supervised and unsupervised learning by using both labeled and unlabeled data to train artificial intelligence (AI) models. Real-World Example: Medical Image Classification Unsupervised learning is the training of machine using information that is unlabeled and allowing the algorithm to act on that information without any guidance. Real-World Example: Customer Segmentation in E-commerce Reinforcement Learning is a part of machine learning where an agent is put in an environment and he learns to behave in this environment by performing certain actions and observing the rewards which it gets from those actions. Real-World Example: Self-driving Car Navigation Self-supervised learning (SSL) is a machine learning paradigm where models learn from unlabeled data by automatically generating their own labels or supervisory signals. Instead of relying on manually labeled datasets, SSL algorithms define pretext tasks that allow the model to learn meaningful representations of the data by inferring relationships or patterns within the unlabeled input.  Start with data  define the objective  choose the learning type  select the algorithm  train the model  use it for predictionsdecisions. All machine learning problems are grouped into three major types based on what kind of question youre trying to answer  and that defines how the model will learn and predict . Question being asked: How much?, What is the number? Real-World Example: Predict House Prices. Question being asked: Which category does it belong to? Real-World Example: Spam Email Detection. Question being asked: What are the natural groups or segments? Real-World Example: Customer Segmentation in Marketing. Machine Learning problems are grouped as: All the problems which you gave to your machine learning model will fall into one of these categories. In Machine Learning, once your data and problem are defined, the next big decision is how to build the model . There are three main types of models that you can use  and each is trained using one or more of the five learning types: supervised , unsupervised , semi-supervised , reinforcement , and self-supervised learning . These are models that have already been trained on massive datasets by researchers or companies. They are trained on general tasks (like predicting the next word or filling in blanks) and can be used directly for many common problems. This means you take a pre-trained model and then train it further on your own labeled dataset . This process adapts the general intelligence of the model to your specific use case. In some cases, you may want to build a model entirely from the ground up using your own algorithms and data. The ultimate goal of Machine Learning is not just to create a model  but to solve real-world problems intelligently, efficiently, and at scale. Machine Learning can solve a wide range of complex, data-driven problems that are hard or impossible to solve using traditional programming: Machine Learning is transforming every industry  from saving lives to increasing profits  making businesses smarter and society better. Everything begins with the dream of building intelligent machines  systems that can see, read, listen, speak, and make decisions like humans. But how do we make machines intelligent ? Thats where Machine Learning (ML) steps in. It provides a way to train machines to learn from data and improve over time  without being explicitly programmed for every rule. Start with Data Real-world examples, records, or observations  this is the foundation. Define Your Objective and Choose a Learning Type Decide what kind of learning fits your problem: Choose the Right Algorithm Based on the learning type and data, select the best algorithm (e.g., Decision Trees, SVM, K-Means, Transformers). Train or Create Your Model Feed your data into the algorithm to train a model  this model captures patterns and knowledge from the data. Use the Trained Model Now the model can answer questions, make predictions, generate content, detect fraud, drive cars, and much more! Enjoy the Intelligence! Whether its ChatGPT answering questions, Spotify recommending songs, or self-driving cars navigating roads  its all powered by trained models. Data  Learning Type  Algorithm  Model  Predictions  Intelligence Unlocked The Resul t: Your model is now intelligent  it can predict, classify, recommend, or generate output. The Outcome : Your machine becomes a smart system  achieving Artificial Intelligence through Machine Learning. Further reads- www.geeksforgeeks.org python.plainenglish.io https:data-flair.trainingblogsmachine-learning-tutorial https:data-flair.trainingblogsmachine-learning-applications",1692
https://realpython.com/tutorials/data-science/,Python Data Science  Real Python," FREE Email Series   Python Tricks   No spam. Unsubscribe any time. Data science is just about as broad of a term as they come. It may be easiest to describe what it is by listing its more concrete components: Data exploration  analysis . Data visualization . A pretty self-explanatory name. Taking data and turning it into something colorful. Classical machine learning . Conceptually, we could define this as any supervised or unsupervised learning task that is not deep learning (see below). Scikit-learn is far-and-away the go-to tool for implementing classification, regression, clustering, and dimensionality reduction, while StatsModels is less actively developed but still has a number of useful features. Deep learning . This is a subset of machine learning that is seeing a renaissance, and is commonly implemented with Keras, among other libraries. It has seen monumental improvements over the last 5 years, such as AlexNet in 2012, which was the first design to incorporate consecutive convolutional layers. Data storage and big data frameworks . Big data is best defined as data that is either literally too large to reside on a single machine, or cant be processed in the absence of a distributed environment. The Python bindings to Apache technologies play heavily here. Odds and ends . Includes subtopics such as natural language processing, and image manipulation with libraries such as OpenCV. Oct 21, 2025 intermediate data-science data-viz web-dev Oct 15, 2025 intermediate data-science python Oct 15, 2025 intermediate data-science python Sep 26, 2025 intermediate best-practices data-science data-viz Sep 10, 2025 basics data-science python Sep 10, 2025 basics data-science python Aug 22, 2025 intermediate data-science data-structures Aug 08, 2025 intermediate data-science data-viz Aug 04, 2025 basics data-science Jul 15, 2025 intermediate data-science editors python tools Jul 11, 2025 intermediate best-practices data-science Jul 04, 2025 basics data-science data-viz Jun 24, 2025 intermediate databases data-science python May 26, 2025 intermediate data-science editors python tools May 26, 2025 intermediate data-science editors python tools May 20, 2025 intermediate databases data-science May 19, 2025 intermediate data-science python May 19, 2025 intermediate data-science python May 13, 2025 intermediate data-science python Apr 22, 2025 intermediate databases data-science Mar 26, 2025 intermediate databases data-science python Mar 19, 2025 intermediate ai data-science Mar 17, 2025 intermediate databases data-science python Mar 14, 2025 data-science projects tools Mar 06, 2025 intermediate databases data-science Mar 04, 2025 intermediate data-science Feb 26, 2025 intermediate best-practices data-science Feb 26, 2025 intermediate best-practices data-science python Feb 21, 2025 data-science data-viz python Feb 02, 2025 intermediate data-science data-viz Feb 01, 2025 intermediate data-science Jan 29, 2025 intermediate data-science machine-learning numpy Jan 26, 2025 intermediate data-science data-viz Jan 22, 2025 intermediate data-science python Jan 21, 2025 intermediate best-practices data-science python Jan 19, 2025 intermediate data-science Jan 18, 2025 basics data-science numpy Dec 22, 2024 intermediate data-science Dec 20, 2024 data-science machine-learning python Dec 07, 2024 intermediate data-science machine-learning Dec 01, 2024 intermediate data-science tools web-scraping Nov 06, 2024 intermediate best-practices data-science python Oct 25, 2024 intermediate data-science python Oct 18, 2024 best-practices data-science python intermediate data-science numpy Sep 06, 2024 community data-science python intermediate api data-science Sep 02, 2024 intermediate data-science numpy",515
https://www.geeksforgeeks.org/data-science/data-science-with-python-tutorial/,Data Science with Python Tutorial - GeeksforGeeks,"Data Science has become one of the fastest-growing fields in recent years, helping organizations to make informed decisions, solve problems and understand human behavior. As the volume of data grows so does the demand for skilled data scientists. Before starting the tutorial you can refer to these articles: To gain expertise in data science, you need to have a strong foundation in the following libraries: Data loading means importing raw data from various sources and storing it in one place for further analysis. Data preprocessing involves cleaning and transforming raw data into a usable format for accurate and reliable analysis. Data analysis is the process of inspecting data to discover meaningful insights and trends to make informed decision. Data visualization uses graphical representations such as charts and graphs to understand and interpret complex data. Machine learning focuses on developing algorithms that helps computers to learn from data and make predictions or decisions without explicit programming. A A What is Data Science? Top 25 Python Libraries for Data Science in 2025 Difference between Structured, Semi-structured and Unstructured data Types of Machine Learning What's Data Science Pipeline? Applications of Data Science Data Science with Python Tutorial Pandas Tutorial NumPy Tutorial - Python Library Data Preprocessing in Python EDA - Exploratory Data Analysis in Python Statistics For Data Science Descriptive Statistic What is Inferential Statistics? Bayes' Theorem Probability Data Distributions in Data Science Parametric Methods in Statistics Hypothesis Testing ANOVA for Data Science and Data Analytics Bayesian Statistics  Probability What is Feature Engineering? Introduction to Dimensionality Reduction Feature Selection Techniques in Machine Learning Feature Engineering: Scaling, Normalization and Standardization Principal Component Analysis(PCA) Evaluation Metrics in Machine Learning Regularization in Machine Learning Cross Validation in Machine Learning Hyperparameter Tuning ML  Underfitting and Overfitting Bias and Variance in Machine Learning Data Science Interview Questions and Answers Data Science Coding Interview Questions Top 65 Data Science Projects with Source Code",314
https://jakevdp.github.io/PythonDataScienceHandbook/,Python Data Science Handbook | Python Data Science Handbook,"Jake VanderPlas This website contains the full text of the Python Data Science Handbook by Jake VanderPlas; the content is available on GitHub in the form of Jupyter notebooks. The text is released under the CC-BY-NC-ND license , and code is released under the MIT license . If you find this content useful, please consider supporting the work by buying the book !",63
https://www.w3schools.com/datascience/,Data Science Tutorial,"W3Schools offers a wide range of services and products for beginners and professionals, helping millions of people everyday to learn and master new skills. Enjoy our free tutorials like millions of other internet users since 1999 Explore our selection of references covering all popular coding languages Create your own website with W3Schools Spaces - no setup required Test your skills with different exercises Test yourself with multiple choice questions Document your knowledge Create a free account to track your progress Earn XP and climb the ranks with different challenges Become a PLUS user and unlock powerful features (ad-free, hosting, support,..) Not sure where you want to start? Follow our guided path With our online code editor, you can edit code and view the result in your browser Learn the basics of HTML in a fun and engaging video tutorial We have created a bunch of responsive website templates you can use - for free! Host your own website, and share it to the world with W3Schools Spaces Create your own server using Python, PHP, React.js, Node.js, Java, C, etc. Large collection of code snippets for HTML, CSS and JavaScript Build fast and responsive sites using our free W3.CSS framework Read long term trends of browser usage Test your typing speed Use our color picker to find different RGB, HEX and HSL colors. W3Schools Coding Game! Help the lynx collect pine cones Join our newsletter and get access to exclusive content every month Check out our refererence page with all the emojis supported in HTML  Check out our full UTF-8 Character reference Chat, Learn and Connect with Us on Discord Contact us about W3Schools Academy for educational institutions Contact us about W3Schools Academy for your organization About sales: salesw3schools.com About errors: helpw3schools.com Today, Data rules the world. This has resulted in a huge demand for Data Scientists. A Data Scientist helps companies with data-driven decisions, to make their business better. Tip: Sign in to track your progress - it's free. With our ""Try it Yourself"" editor, you can edit Python code and view the result. Click on the ""Try it Yourself"" button to see how it works. Python is a programming language widely used by Data Scientists. Python has in-built mathematical libraries and functions, making it easier to calculate mathematical problems and to perform data analysis. In this tutorial, we will use Python to provide practical examples. To learn more about Python, please visit our Python Tutorial . REMOVE ADS If you want to use W3Schools services as an educational institution, team or enterprise, send us an e-mail: salesw3schools.com If you want to report an error, or if you want to make a suggestion, send us an e-mail: helpw3schools.com",448
https://aws.amazon.com/what-is/deep-learning/,What is Deep Learning? - Deep Learning AI Explained - AWS,"Deep learning is an artificial intelligence (AI) method that teaches computers to process data in a way inspired by the human brain. Deep learning models can recognize complex pictures, text, sounds, and other data patterns to produce accurate insights and predictions. You can use deep learning methods to automate tasks that typically require human intelligence, such as describing images or transcribing a sound file into text. Watch our introduction to deep learning Deep generative learning is deep learning that focuses on creating new output from learned input. Traditionally, deep learning focused on identifying relationships between data. Deep learning models were trained with large amounts of data to recognize patterns in the data set. Deep generative learning adds generation to pattern recognition. Such models look for data patterns and then create their own unique patterns. For example, they can analyze the text in several books and then use the information to generate new sentences and paragraphs not found in the original books. Deep generative learning is the basis of modern generative AI and foundation models . These models use deep learning technologies at scale, trained on vast data, to perform complex tasks like answering questions, creating images from text, and writing content. Watch an introductory video to foundation models Deep learning technology drives many artificial intelligence applications used in everyday products, such as the following: It is also a critical component of technologies like self-driving cars, virtual reality, and more. Businesses use deep learning models to analyze data and make predictions in various applications. Deep learning has several use cases in automotive, aerospace, manufacturing, electronics, medical research, and other fields. These various use cases of deep learning can be grouped into five broad categories: computer vision, speech recognition, natural language processing (NLP), recommendation engines, and generative AI. Computer vision automatically extracts information and insights from images and videos. Deep learning techniques to comprehend images in the same way that humans do. Computer vision has several applications, such as the following: Deep learning models can analyze human speech despite varying speech patterns, pitch, tone, language, and accent. Virtual assistants such as Amazon Alexa, text-to-speech , and speech-to-text software use speech recognition to do the following tasks: Computers use deep learning algorithms to gather insights and meaning from text data and documents. This ability to process natural, human-created text has several use cases, including: Applications can use deep learning methods to track user activity and develop personalized recommendations . They can analyze users' behavior and help them discover new products or services. For example, Generative AI applications can create new content and communicate with end users more sophisticatedly. They can assist in automating complex workflows, brainstorming ideas, and intelligent knowledge searches. For example, with generative AI tools like Amazon Q Business and Amazon Q Developer , users can Deep learning models are neural networks designed after the human brain. A human brain contains millions of interconnected biological neurons that work together to learn and process information. Similarly, artificial neurons are software modules called nodes that use mathematical calculations to process data. Deep learning neural networks, or artificial neural networks, comprise many layers of artificial neurons that work together to solve complex problems. The components of a deep neural network are the following. An artificial neural network has several nodes that input data into it. These nodes make up the system's input layer. The input layer processes and passes the data to layers further in the neural network. These hidden layers process information at different levels, adapting their behavior as they receive new information. Deep learning networks have hundreds of hidden layers that they can use to analyze a problem from several different angles. For example, if you were given an image of an unknown animal that you had to classify, you would compare it with animals you already know. For example, you would look at the shape of its eyes and ears, size, number of legs, and fur pattern. You would try to identify patterns, such as the following: The hidden layers in deep neural networks work in the same way. If a deep learning algorithm tries to classify an animal image, each of its hidden layers processes a different animal feature and tries to categorize it accurately. The output layer consists of the nodes that output the data. Deep learning models that output ""yes"" or ""no"" answers have only two nodes in the output layer. On the other hand, those that output a wider range of answers have more nodes. Generative AI has a sophisticated output layer to generate new data that matches patterns in its training data set. The terms machine learning, deep learning, and generative AI indicate a progression in neural network technology. Deep learning is a subset of machine learning . Deep learning algorithms emerged to make traditional machine learning techniques more efficient. Traditional machine learning methods require significant human effort to train the software. For example, in animal image recognition, you need to do the following: This process is called supervised learning. In supervised learning, result accuracy improves only with a broad and sufficiently varied dataset. For instance, the algorithm might accurately identify black cats but not white cats because the training dataset had more images of black cats. In that case, you would need more labeled data of white cat images to train the machine learning models again. A deep learning network has the following benefits over traditional machine learning. Machine learning methods find unstructured data, such as text documents, challenging to process because the training dataset can have infinite variations. On the other hand, deep learning models can comprehend unstructured data and make general observations without manual feature extraction. For instance, a neural network can recognize that these two different input sentences have the same meaning: A deep learning application can analyze large amounts of data more deeply and reveal new insights for which it might not have been trained. For example, consider a deep learning model trained to analyze consumer purchases. The model has data only for the items you have already purchased. However, the artificial neural network can suggest new items you haven't bought by comparing your buying patterns to those of similar customers. Deep learning models can learn and improve over time based on user behavior. They do not require large variations of labeled datasets. For example, consider a neural network that automatically corrects or suggests words by analyzing your typing behavior. Let's assume it was trained in English and can spell-check English words. However, if you frequently type non-English words, such as danke, the neural network automatically learns and autocorrects these words too. Volatile datasets have large variations. One example is loan repayment amounts in a bank. A deep learning neural network can categorize and sort that data by analyzing financial transactions and flagging some for fraud detection. Learn more about deep learning vs. machine learning Generative AI took the neural networks of machine learning and deep learning to the next level. While machine learning and deep learning focus on prediction and pattern recognition, generative AI produces unique outputs based on the patterns it detects. Generative AI technology is built on transformer architecture that combines several different neural networks to combine data patterns in unique ways. Deep learning networks first convert text, images, and other data into mathematical abstractions and then reconvert them into meaningful new patterns. Challenges in implementing deep learning and generative AI are given below. When you train them on large amounts of high-quality data, deep learning algorithms give better results. Outliers or mistakes in your input dataset can significantly affect the deep learning process. For instance, in our animal image example, the deep learning model might classify an airplane as a turtle if the dataset accidentally introduces non-animal images. To avoid such inaccuracies, you must clean and process large amounts of data before training deep learning models. The input data preprocessing requires large amounts of data storage capacity. Deep learning algorithms are compute-intensive and require infrastructure with sufficient compute capacity to function properly. Otherwise, they take a long time to process results. Running generative AI and deep learning on cloud infrastructure helps you design, develop, and train applications faster. You can train generative AI and deep learning models faster by using clusters of GPUs and CPUs to perform the complex mathematical operations that your neural networks require. You can then deploy these models to process large amounts of data and produce increasingly relevant results. With the wide range of on-demand resources available through the cloud, you can access virtually unlimited hardware resources to tackle AI deep learning models of any size. Your neural networks can take advantage of multiple processors to seamlessly and efficiently distribute workloads across different processor types and quantities. You can access AI and deep learning tools like notebooks, debuggers, profilers, pipelines, AIOps, and more. You can work with existing generative AI models from within the cloud as a service without requiring infrastructure to host the model. Teams can start with generative AI and deep learning applications even with limited knowledge and training. AWS AI and deep learning services harness the power of cloud computing so that you can build and scale the next wave of AI innovation. Reinvent customer experiences with the most comprehensive purpose-built services, AI infrastructure, deep learning technology, and generative AI solutions. For example, You can also use AWS AI infrastructure to access comprehensive, secure, and price-performant computing, storage, and networking to build any AI application. Get started with AI deep learning on AWS by creating a free AWS account today! Instantly get access to the AWS free tier. Get started building in the AWS Management Console.",1606
https://developers.google.com/search/docs/fundamentals/seo-starter-guide,SEO Starter Guide: The Basics | Google Search Central | Documentation | Google for Developers,"When you built your website, you likely created it with your users in mind, trying to make it easy for them to find and explore your content. One of those users is a search engine, which helps people discover your content. SEOshort for search engine optimizationis about helping search engines understand your content, and helping users find your site and make a decision about whether they should visit your site through a search engine. The Search Essentials outline the most important elements of what makes your website eligible to appear on Google Search. While there's no guarantee that any particular site will be added to Google's index, sites that follow the Search Essentials are more likely to show up in Google's search results . SEO is about taking the next step and working on improving your site's presence in Search . This guide will walk you through some of the most common and effective improvements you can do on your site. There are no secrets here that'll automatically rank your site first in Google (sorry!). In fact some of the suggestions might not even apply to your business, but following the best practices will hopefully make it easier for search engines (not just Google) to crawl, index, and understand your content. Google is a fully automated search engine that uses programs called crawlers to explore the web constantly, looking for pages to add to our index. You usually don't need to do anything except publish your site on the web. In fact, the vast majority of sites listed in our results are found and added automatically as we crawl the web. If you're hungry for more, we have documentation about how Google discovers, crawls, and serves web pages . Every change you make will take some time to be reflected on Google's end. Some changes might take effect in a few hours, others could take several months. In general, you likely want to wait a few weeks to assess whether your work had beneficial effects in Google Search results. Keep in mind that not all changes you make to your website will result in noticeable impact in search results; if you're not satisfied with your results and your business strategies allow it, try iterating with the changes and see if they make a difference. Before you actually do anything mentioned in this section, check if Google has already found your content (maybe you don't need to do anything!). Try searching on Google for your site with the site: search operator . If you see results pointing to your site, you're in the index. For example, a search for site:wikipedia.org returns these results . If you don't see your site, check out the technical requirements to make sure there's nothing technically preventing your site from showing in Google Search, and then come back here. Google primarily finds pages through links from other pages it already crawled. In many cases, these are other websites that are linking to your pages. Other sites linking to you is something that happens naturally over time, and you can also encourage people to discover your content by promoting your site . If you're open to a little technical challenge, you could also submit a sitemap which is a file that contains all the URLs on your site that you care about. Some content management systems (CMS) may even do this automatically for you. However this isn't required, and you should first focus on making sure people know about your site . When Google crawls a page, it should ideally see the page the same way an average user does . For this, Google needs to be able to access the same resources as the user's browser. If your site is hiding important components that make up your website (like CSS and JavaScript ), Google might not be able to understand your pages, which means they might not show up in search results or rank well for the terms you're targeting. If your pages have different information depending on the user's physical location, make sure you're satisfied with the information that Google sees from its crawler's location, which is generally the US. To check how Google sees your page, use the URL Inspection Tool in Search Console . It might be important for you to opt out your site as a whole or sections of it from appearing in search results. For example, you might not want your posts about your new embarrassing haircut to show up in search results. Google supports various ways that lets you opt out of crawling and indexing of your URLs. If you need to block some files, directories, or even your whole site from Google Search, check out our guide about ways to prevent content from appearing in search results . When you're setting up or redoing your site, it can be good to organize it in a logical way because it can help search engines and users understand how your pages relate to the rest of your site. Don't drop everything and start reorganizing your site right now though: while these suggestions can be helpful long term (especially if you're working on a larger website), search engines will likely understand your pages as they are right now, regardless of how your site is organized. Parts of the URL can be displayed in search results as breadcrumbs, so users can also use the URLs to understand whether a result will be useful for them. Domain Breadcrumb Google learns breadcrumbs automatically based on the words in the URL, but you can also influence them with structured data if you like a technical challenge. Try to include words in the URL that may be useful for users; for example: https:www.example.competscats.html A URL that only contains random identifiers is less helpful for users; for example: https:www.example.com26772756D707920636174 If you have more than a few thousand URLs on your site, how you organize your content may have effects on how Google crawls and indexes your site. Specifically, using directories (or folders) to group similar topics can help Google learn how often the URLs in individual directories change. For example, consider the following URLs: https:www.example.compoliciesreturn-policy.html https:www.example.compromotionsnew-promos.html The content in the policies directory seldomly changes, however the content in the promotions directory likely changes very often. Google can learn this information and crawl the different directories at different frequencies. To learn more about search-friendly site structures, check out our guide for ecommerce sites , for which a good URL structure is more important as they tend to be larger. Some websites show the same content under different URLs, which is called duplicate content . Search engines choose a single URL (the canonical URL) to show users, per piece of content. Having duplicate content on your site is not a violation of our spam policies, but it can be a bad user experience and search engines might waste crawling resources on URLs that you don't even care about. If you're feeling adventurous, it's worth figuring out if you can specify a canonical version for your pages. But if you don't canonicalize your URLs yourself, Google will try to automatically do it for you. When working on canonicalization, try to ensure that each piece of content on your site is only accessible through one individual URL; having two pages that contain the same information about your promotions can be a confusing user experience (for example, people might wonder which is the right page, and whether there's a difference between the two). If you have multiple pages that have the same information, try setting up a redirect from non-preferred URLs to a URL that best represents that information. If you can't redirect, use the rel""canonical"" link element instead. But again, don't worry too much about this; search engines can generally figure this out for you on their own most of the time. Creating content that people find compelling and useful will likely influence your website's presence in search results more than any of the other suggestions in this guide. While ""compelling and useful content"" can mean different things to different people, content like this generally shares some common attributes, such as: Think about the words that a user might search for to find a piece of your content. Users who know a lot about the topic might use different keywords in their search queries than someone who is new to the topic. For example, some users might search for ""charcuterie"", while others might search for ""cheese board"". Anticipating these differences in search behavior and writing with your readers in mind could produce positive effects on how your site performs in search results. However, don't worry if you don't anticipate every variation of how someone might seek your content. Google's language matching systems are sophisticated and can understand how your page relates to many queries, even if you don't explicitly use the exact terms in them. While ads are a part of the internet and are meant to be seen by users, don't let them become overly distracting or prevent your users from reading your content. For example, advertisements, or interstitial pages (pages displayed before or after the content you're expecting) that make it difficult to use the website. Links are a great way to connect your users and search engines to other parts of your site, or relevant pages on other sites. In fact, the vast majority of the new pages Google finds every day are through links, making links a crucial resource you need to consider to help your pages be discovered by Google and potentially shown in search results. Additionally, links can also add value by connecting users (and Google) to another resource that corroborates what you're writing about. Link text (also known as anchor text ) is the text part of a link that you can see. This text tells users and Google something about the page you're linking to. With appropriate anchor text , users and search engines can easily understand what your linked pages contain before they visit. Links can provide more context on a topic, both for users and search engines, which may help demonstrate your knowledge on a topic. However when you're linking to pages outside of your control, for example content on other sites, make sure you trust the resource you're linking to. If you can't trust the content and you still want to link to them, add a nofollow or similar annotation to the link to avoid search engines associating your site with the site you're linking to. This helps avoid potential negative consequences in your rankings in Google Search. If you're accepting user-generated content on your site, such as forum posts or comments, make sure every link that's posted by users has a nofollow or similar annotation automatically added by your CMS. Since you're not creating the content in this case, you likely don't want your site to be blindly associated with the sites users are linking to. This can also help discourage spammers from abusing your website. A typical Google Search results page consists of a few different visual elements that you can influence to help users decide whether they should visit your site through those search results. In this section, we're focusing on the title link and the snippet because these are the more visually significant elements. The title link is the headline part of the search result and it can help people decide which search result to click. There are a few sources that Google uses to generate this title link, including the words inside the title element (also called the title text) and other headings on the page. This title text can also be used for the title that's shown in browsers and bookmarks. How to make your own chili oil You can influence the title links in Search by writing good titles: a good title is unique to the page, clear and concise, and accurately describes the contents of the page. For example, your title could include the name of your website or business, other bits of important information like the physical location of the business, and maybe some information about what the particular page has to offer for users. Our documentation about title links has more tips about how to create good titles and how to influence your site's search results' title links. Below the title link, a search result typically has a description of the target page to help users decide whether they should click the search result. This is called a snippet . Learn how to cook eggs with this complete guide in less than 5 minutes. We cover all the methods, including sunny side up, boiled, and poached. The snippet is sourced from the actual content of the page the search result is linking to, thus you have complete control over the words that can be used to generate the snippet. Occasionally the snippet may be sourced from the contents of the meta description tag, which is typically a succinct, one- or two-sentence summary of the page. A good meta description is short, unique to one particular page, and includes the most relevant points of the page. Check out our tips for writing good meta descriptions for more inspiration. Many people search visually, and images can be how people find your website for the first time. For example, if you have a recipe blog, people might find your content by searching for ""fruit tart recipes"" and browsing photos of various types of fruit tarts. As you add images to your site, make sure that people and search engines can find and understand them. When you use high quality images, you give users enough context and detail to decide which image best matches what they were looking for. For example, if people are looking for ""daisies"" and come across a rogue edelweiss in search results, a higher quality image would help them distinguish the type of flower. Use images that are sharp and clear, and place them near text that's relevant to the image. The text that's near images can help Google better understand what the image is about and what it means in context to your page. For example, if the page is reviewing yarn shops in London, then it would make sense to embed one of your photos of the yarn shop in the section that details the location, description, and review information for that yarn shop. This helps Google and users associate the image with text that provides more context to what the page is about. Alt text is a short, but descriptive piece of text that explains the relationship between the image and your content. It helps search engines understand what your image is about and the context of how your image relates to your page, so writing good alt text is quite important. You can add this to your HTML with the alt attribute of the img element, or your CMS may have an easy way to specify a description for an image when you're uploading it to your site. Learn more about how to write good alt text , and how to add it to your images. If your website includes pages that are primarily about individual videos, people may also be able to discover your site through video results in Google Search. Many of the best practices for images and text also apply to videos: If your site is particularly video-focused, then continue reading about more things you can do to optimize your videos for search engines . Effectively promoting your new content will lead to faster discovery by those who are interested in the same subject, and also by search engines. You can do this in many ways: One of the most effective and lasting ways is word of mouth: that is, people familiar with your site tell their friends about it, who in turn visit your site. This can take time, and usually you need to invest some time and effort in other practices first, such as community engagement. Our friends over at Google for Creators have excellent resources about building and engaging your audience . Putting effort into the offline promotion of your company or site can also be rewarding. For example, if you have a business site, make sure its URL is listed on your business cards, letterhead, posters, and other materials. With their permission, you could also send out recurring newsletters to your audience letting them know about new content on your website. As with everything in life, you can overdo promoting your site and actually harm it: people may get fatigued of your promotions, and search engines may perceive some of the practices as manipulation of search results . As SEO has evolved, so have the ideas and practices (and at times, misconceptions) related to it. What was considered best practice or top priority in the past may no longer be relevant or effective due to the way search engines (and the internet) have developed over time. To help you focus on the things that are actually important when it comes to SEO, we collected some of the most common and prominent topics we've seen circulating the internet. In general, our message on these topics is that you should do what's best for your business area; we will elaborate on a few specific points here: When picking the name of your site, do what's best for your business. Users will use this name to find you, so we recommend following general marketing best practices. From a ranking perspective, the keywords in the name of the domain (or URL path) alone have hardly any effect beyond appearing in breadcrumbs . And while still on the topic of domain names: the TLD (the domain name ending like "".com"" or "".guru"") only matters if you're targeting a specific country's users, and even then it's usually a low impact signal. For example, if you're trying to sell Dutch cheese to people searching from Switzerland, it makes some sense (both from business and SEO point of view ) to use a .ch domain name. Otherwise Google Search doesn't care which TLD you're using (whether it's a .com or .org or .asia). Having your headings in semantic order is fantastic for screen readers, but from Google Search perspective, it doesn't matter if you're using them out of order. The web in general is not valid HTML, so Google Search can rarely depend on semantic meanings hidden in the HTML specification. There's also no magical, ideal amount of headings a given page should have. However, if you think it's too much, then it probably is. As you embark on your SEO journey, here are some resources that can help you stay on top of changes and new resources we publish:",3133
https://digitalmarketinginstitute.com/blog/what-is-seo,What Is SEO and How Does it Work? | Digital Marketing Institute," Back to Articles Apr 28, 2025 Articles by Cathal Melinn Posted on Apr 28, 2025 Share via: View Courses Share via: Cathal Melinn is a well-known Digital Marketing Director, commercial analyst, and eommerce specialist with over 15 years experience. Cathal is a respected international conference speaker, course lecturer, and digital trainer. He specializes in driving complete understanding from students across a number of digital marketing disciplines including: paid and organic search (PPC and SEO), analytics, strategy and planning, social media, reporting, and optimization. Cathal works with digital professionals in over 80 countries and teaches at all levels of experience from beginner to advanced. Alongside his training and course work, Cathal runs his own digital marketing agency and is considered an analytics and revenue-generating guru - at enterprise level. He has extensive local and international experience working with top B2B and B2C brands across multiple industries. Over his career, Cathal has worked client-side too, with digital marketing agencies and media owners, for brands including HSBC, Amazon, Apple, Red Bull, Dell, Vodafone, Compare the Market, Aer Lingus, and Expedia. He can be reached on LinkedIn here .",185
https://www.coursera.org/articles/content-strategy,How to Develop a Content Strategy: Step-by-Step Guide | Coursera,"Discover what goes into a content strategy, why its important, and how to start building one for your business. With a successful content strategy, you can build a relationship with your target audience while positioning yourself as an expert in your field. Ideally, you can leverage the trust you develop with your audience through high-quality content that moves you closer to your overarching goals. Explore how to define content strategy, why your content strategy matters, and get guidance as you develop an effective content strategy. Afterward, learn job-ready skills from industry leaders like Google, Microsoft, and IBM with a Coursera Plus subscription. Youll get a certificate for every program you finish, which you can add to further enhance your resume. Your content strategy details your plan to use content in a way that moves you closer to your business goals. It's essentially a roadmap for all of your content marketing efforts and can be included in a more comprehensive marketing strategy . Typically, you'll want to design a content strategy that attracts and engages customers throughout all stages of the buyer's journey. In implementing a content strategy, you can expect to organize your existing content library, create new content, and monitor your content's success. Content strategists specifically work with content strategies to create branded content for their organizations channels, both print and digital. Their goal is to reach new customers and audience members, and they play an important role in a business as the content they write, edit, or publish helps a company reach its overarching goals. Common responsibilities for a content strategist are gathering information about their target audience, creating content strategy frameworks, maintaining SEO guidelines, managing and training a team of content collaborators, and more. Every piece of content tells a story, and together, a body of content tells an even bigger story about who you are, your expertise, your values, and your place in the world. Developing a strategy for your content ensures that you're telling a cohesive narrative every time you hit publish. With an effective content strategy, you'll create opportunities to educate and serve your audience, establish yourself as an authority in your niche market , and show your audience why your business matters. Review the following seven steps of the content strategy planning process: Define your goals. Research your target audience. Conduct a content audit. Choose your content types. Create your content plan. Develop a process for content creation. Measure the success of your content. Take a closer look at each step. With clearly defined desired outcomes and success measures, you can design a strategy that moves you closer to your business goals. Think about what you'd like to achieve with your content. (At this stage, focus specifically on the ""what""we'll get to the ""how"" in later steps.) It may help to structure your goals with SMART methodology. SMART goals are specific, measurable, achievable, relevant, and time-bound. Below are some examples to draw from: Generate 50 percent more qualified leads in 90 days. Double the number of social media followers in 60 days. Get 100 new email subscribers in 30 days. Who are the potential customers you'd like to introduce to your business? This group of people makes up your target audience, and they likely have some shared characteristics worth keeping in mind as you develop your content. It may help to create a buyer persona, which is a fictional representation of your target customer that you use to guide your content creation process. Developing personas can make it easier to reflect on target customers needs and how your content can meet those needs. Some questions to ask as you develop your buyer persona include: What are their demographics and psychographics? What are their interests, values, and needs? How does your business fit into their lives? As you prepare your content strategy, it can also help to research how your target audience receives, consumes, and engages with content, as well as their preferred communication styles. Before you plan to create new content, it's worth revisiting the content you already have. Consider what types of content you've published, how well your content has performed, and whether your existing content has historically contributed to your company's goals. Additionally, consider the opposite: whether any of your content has underperformed or moved you away from your goals. Through assessing your current content library, you can gather hints about the types of content that your target audience might like or dislike in the future, and use this knowledge to guide future content plans. In addition to auditing your own content, you may be able to learn more about your target audience through a competitor analysis . Evaluating the competitive landscape can help reveal industry standards and opportunities to create fresh content that fills gaps and better serves customers. During a competitor analysis, you'll examine the content practices of businesses targeting audiences who are similar to your target audience. Take note of the types of content they publish, where they publish, how their audience engages with their content, and the topics they cover. Then, consider what aspects of their content strategy you may want to adopt and how you can elevate your content beyond their offerings. Next, think about the types of content that you can reasonably create, your target audience is likely to react positively to, and that can help you reach your content goals. You may also consider different types of content for different stages of the customer journey. Some common types of content to consider include: Blog posts Social media posts Videos Podcasts Email newsletters Case studies White papers Templates E-books Once you choose the types of content that make the most sense for your needs, consider the steps you'll need to take to optimize your content types for the platform you plan to focus on. For example, if you're publishing blog posts on your company website, you may want to use search engine optimization (SEO) techniques and tools, which can help surface your content on search engines like Google for relevant search terms. Or, if you plan to incorporate social media content creation into your content strategy, you may want to consider the hashtags your target audience may follow or the viral moments they're responding to. Knowing how you'll optimize your content types for your chosen platforms is one way to think strategically about your content. At this point, you have a strong foundation on which to start strategically planning your actual content. Reflect on the work you've done so far to determine the content topics you'd like to address across your various content types. Here, consider topics at the intersection of your unique expertise and your target audience's interests, values, or needs. You may also brainstorm ways you can further conversations around content areas that have historically performed well for you or that perform well for your direct business competitors. Leveraging your content across different platforms is another way to strategically approach your content. Audiences may have different communication expectations across different platforms. Think about how you can repurpose content pertaining to the same topic across your chosen platforms. Some people find it helpful to organize their content plan with a content calendar or an editorial calendar. With your pevelolan in place, youll have more clarity around what you'll need to do in order to begin generating your content. Consider the people you'll need on your content team in order to meet your goals and execute your plan, whether that's content strategists tasked with audience research and ideation, content creators willing to appear on camera, or writers who can serve as subject matter experts. Also, consider the tools you might need as you develop and publish your content. Tools may include a content management system (CMS), social listening tools, or editing software. Since you'll need to generate content on a regular basis, a streamlined creation process can make it easier over time to come up with new ideas and build continuous content that serves your audience and expands your goals. Once your content is published and your audience begins engaging with it, youll need to have a plan in place for measuring how well the content performs. Many websites, social media platforms, and email systems report metrics like the number of views or clicks a piece of content gets and how many people are subscribing or following over a span of time. Determine the metrics that are most relevant to your content goals, then decide on the best way to track those metrics over time. Once you begin to see how your content is performing, this will provide you with a basis for adjusting individual pieces of content or the strategy as a whole. Continue exploring how a strong content strategy can elevate your business practices. Learn more about digital marketing analytics with the Unilever Digital Marketing Analyst Professional Certificate , or expand your digital marketing skills with Google's Digital Marketing  E-commerce Professional Certificate , both available on Coursera. Sign up for Coursera for free to start learning today. Editorial Team Courseras editorial team is comprised of highly experienced professional editors, writers, and fact... This content has been made available for informational purposes only. Learners are advised to conduct additional research to ensure that courses and other credentials pursued meet their personal, professional, and financial goals. Coursera Footer Skills Certificates  Programs Industries  Careers Career Resources Coursera Community More",1563
https://www.youtube.com/creators/how-things-work/content-creation-strategy/,"Video Content Creation Strategy, Tips & Tools - YouTube Creators","For Creators who are looking to take their channels to the next level but arent sure where to start, this is for you. Well take you deeper into analytics, explain the science behind search, and more. Want to know why your recent video is blowing up? Understanding the way your viewers find your videos can help. Learn how YouTube makes recommendations and what factors influence your impressions. ""Be bold and trust in your creative spirit. Others will be inspired, too."" emmymade Insider tip: our algorithm doesnt pay attention to videos, it pays attention to viewers. So, rather than trying to make videos thatll make an algorithm happy, focus on making videos that make your viewers happy. Get Creator Tips on search and discovery Get Creator Tips to learn what your viewers are watching We track what viewers watch, how long they watch, what they skip over, and more. This helps us figure out what kind of videos they like best and what we can recommend to them next. Watch a video about recommendations Read more about how we recommend videos Things like how long your videos are and how often you post are what wed call programming. Learn some tips about what tends to work best for attracting and entertaining viewers, how to build a content calendar, and more. Watch videos on programming best practices Get Creator Tips for your upload schedule Taking a closer look at your channels analytics can help you make it better. Use data to get to know your audience and their watching habits, spot opportunities to make money, and more. With more filters to group and organize your videos, Advanced Mode helps you dig into trends like what type of content your viewers interact with most, what video length works best, and more. Watch a video about analytics Audience analytics can tell you things like what time of day your viewers are on YouTube and if they are new or returning fans, all so you can get strategic about when and how you post future content. Read more about audience analytics Get Creator Tips for channel performance Get Creator Tips about who your viewers are Using analytics can help you monetize your channel. Using metrics like Cost Per Mille (CPM) and Revenue Per Mille (RPM) can help you understand how advertisers value your content or how much youre earning per view. Watch a video about monetization metrics Read more about ad revenue Even if you have a loyal audience, theres always the chance you are missing viewers who would love your channel. Here are some tools and tips that can help you attract new viewers and more of them. Get Creator Tips about what content to create Collaborations are a great way to connect with other Creators, learn new skills, and find more fans for your channel. Get tips on how to choose collaborators and make the most of what you create together. Tips on collaborations YouTube Live is all about connecting with fans in more meaningful ways. If you qualify, you can enable live streaming from your phone, webcam, or with an encoder in order to let your fans into your life in real time. Learn more about Live Its not always an easy decision, but sometimes a pivot in your channels content is necessary. Making sure youre doing it strategically can set you up for success. Tips for pivots If you dont want to change your main channel, you can always start a secondary channel. This lets you experiment with new types of formats without risking alienating your fans. Watch a video about secondary channels Read more about creating a new channel Creative burnout is real. Prioritize your well-being by having an honest look at the things that matter most: balance, down time, having fun, and how far to push your creative genius. Tips on well-being Get Creator Tips for managing creator burnout YouTube Shorts make creating and watching videos on YouTube easier than ever. Shorts are made for mobile, allowing you to shoot, scroll, and share from your phone. ""When we look at our analytics to understand increased traffic, it always points to YouTube Shorts."" Reza  Puja Khan Curious about more info and insights? Keep exploring the tools and tips that will help you get the most out of your content and your channel, as well as the policies and guidelines that help protect and empower the Creator community. Explore all ways you can get paid on YouTube. Get the explanations behind the rules.",752
https://digitalmarketinginstitute.com/blog/what-are-the-most-effective-digital-marketing-strategies,What Are the Most Effective Digital Marketing Strategies? | Digital Marketing Institute," Back to Articles Jul 30, 2025 Articles by Clodagh O'Brien Posted on Jul 30, 2025 Share via: View Courses Share via: Clodagh O'Brien is a writer, digital marketer and content strategist. She has created and managed content for many SMEs and global brands and is passionate about digital marketing and the impact of technology on culture and society. You can find her on LinkedIn .",65
https://emotive.io/blog/11-essential-digital-marketing-tips,11 Essential Digital Marketing Tips | Emotive,Andres P. Digital Marketing Consultant,5
https://www.forbes.com/advisor/business/what-is-digital-marketing/,"What Is Digital Marketing? Types, Strategies & Best Practices  Forbes Advisor","You might be using an unsupported or outdated browser. To get the best possible experience please use the latest version of Chrome, Firefox, Safari, or Microsoft Edge to view this website. Have a question for Janette Novak or our other editors? Ask here for a chance to be featured in a story. Send a note to Janette Novak, Kiran Aditham and our other editors. We read every email. Keep reading Forbes Advisor for the chance to see the answer to your question in one of our upcoming stories. Our editors also may be in touch with follow-up questions. Digital marketing is one of the most popular and powerful ways to generate awareness, interest and sales for your products or services. As the name implies, digital marketing is conducted via digital avenues, including social media, websites, search engines, email and text messaging. For optimal results, you must understand which digital marketing tactics will work best for your target audience. This post offers an in-depth look at the most effective digital marketing strategies and best practices for achieving your business goals. Also known as online marketing or internet marketing , digital marketing communicates messages through digital channels accessed through electronic devices, including phones, computers and tablets. Digital marketing and traditional marketing, such as print ads and direct mail, share the same ultimate goal: generating product awareness and influencing purchasing decisions to drive sales. The main difference between traditional and digital marketing is that digital marketing uses internet-connected technologies to communicate and engage with targeted audiences. The launch of the World Wide Web in 1989 set the stage for the emergence of digital marketing. The proliferation of business websites, advancements in email technologies and the introduction of wildly popular social channels have sparked meteoric growth in digital marketing. Online marketing is now a key component in most businesses marketing plans primarily because of the widespread use of digital technologies but also because it can deliver outstanding results. To succeed, businesses must find effective ways to spread the word about their products and services and thats never been more challenging than today. Consumers face more choices from more providers, all clamoring for their attention. Deploying compelling content on digital marketing platforms is one way to stand out from the crowd. Another reason digital marketing is so important to businesses is simply this: its where your ideal customer is hanging out. According to the research experts at Statista, as of 2023, there are 5.19 billion internet users and 4.88 billion social media users worldwide. On average, internet users spend six hours and 40 minutes online every day. This enormous, highly engaged online audience presents tremendous opportunities for businesses that want to gain visibility for their goods and services. Digital marketing offers near-endless opportunities for connecting with potential customers and is a vital component of nearly every businesss marketing mix . Creating a solid digital marketing strategy for your business begins with a better understanding of the types of digital marketing methods that yield the best returns. Below, we introduce you to six types of digital marketing: social media marketing, search engine marketing (SEO), pay-per-click (PPC) advertising, email marketing, mobile marketing and content marketing. Social media marketing is one of the most popular forms of digital marketing. In the United States alone, over 308 million people access a social network at least once per month. People of all ages use social media for entertainment, interacting with others, gaining information about specific interests and shopping. For businesses hoping to gain visibility and sales, social media statistics reveal that incorporating social media into your marketing mix can be a sound strategy. Social media is the go-to source for brand information for 78 of internet users. Nearly half of U.S. consumers report theyve made a purchase through social media. Top social platforms include YouTube, Facebook, TikTok, Instagram, WhatsApp, Pinterest, LinkedIn, Snapchat and X (formerly Twitter). New platforms, such as BeReal and Poparazzi, are entering the market regularly. The social landscape is ever-evolving. For example, Twitter, now X, was once a top platform, but the social channel now appears to be struggling. Twitter has lost approximately 32 million users since Elon Musk purchased the platform in 2022. TikTok didnt even come on the international scene until 2017, but now has more than 1.7 billion monthly active users . Digital marketers need to remain attentive to social media channel changes. Search engine optimization (SEO) is a vital digital marketing strategy for businesses that benefit from driving traffic to their websites. SEO is the process of optimizing your website so search engines, such as Google rank your website high on search engine results pages (SERPs). SEO is all about driving organic traffic to your site. Unlike paid advertising, with SEO, visitors who find your site come from unpaid searches. Approximately 8.5 billion searches are done on Google daily, which presents a lot of opportunities for businesses that want to promote their product and services. Ranking high on Google is key to driving more traffic to your website. In a survey conducted by Search Engine Journal , 49 of respondents reported that SEO delivers the highest return on investment (ROI) of any digital marketing channel. You can get started with SEO on your own for free by learning more about Google Ranking Factors or with the help of top SEO tools and software . You can also work with an SEO service or agency to create an SEO plan and manage your SEO for you. PPC advertising is precisely what the name implies: you pay a fee every time someone clicks on your digital ads. The amount youll pay is determined by the platform youre advertising on, the potential traffic for your promoted post and the number of competitors willing to pay for similar ads. Google Ads is the largest PPC platform in the world. Many businesses who engage in SEO marketing also engage in PPC advertising on Google. Paid ads on Google appear above organic search results and that positioning advantage can drive even more traffic to your website. Google Ads is not your only avenue for PPC advertising. You can also purchase PPC ads via the Microsoft Search Network on Bing and partner sites as well as on top social channels, including YouTube, Facebook, Instagram, Snapchat, LinkedIn, Amazon and TikTok. Email marketing is another top digital marketing strategy youll likely want to add to your marketing mix. According to Statista, businesses earn an average of at least 32 for every dollar spent on email marketing. For some sectors, such as retail, e-commerce and consumer goods, that number is 45. To be effective at email marketing, you must develop a strategy for collecting email addresses from clients and prospects. Many businesses collect emails with every customer encounter, sometimes offering a special incentive for joining an email list. Your business website is also a terrific place to offer incentives to visitors so you can grow your email database. Growing and nurturing your email list is vital to successful email marketing . You also must respect the communication preferences of your list and only send relevant information that your base wants to receive. Also, failing to manage the legal aspects of email marketing, including staying compliant with CANSPAM Act mandates, is paramount for email marketing success. Rather than managing business email manually, most marketers acquire email marketing software. The best email marketing software makes it effortless to keep your email database updated, handling new subscribers and unsubscribes for you. Your email software should also make it easy to segment your email database based on customer interests, create attractive email designs, manage email scheduling and measure email metrics, including open rates, click-through rates (CTR), conversion rates and bounce rates. Check out our list of email marketing examples to get a better idea of the topic. There are more than 310 million smartphone users in the U.S. alone, so it should be no surprise that mobile marketing has become a popular digital marketing strategy for businesses. Mobile marketing typically is conducted via text, also called short message service (SMS). Text open rates are estimated to be as high as 98, which is one reason mobile marketing can be so effective. While text messaging is the most common way to market via mobile devices, notifications from mobile apps and social channels can also be received on smartphones. The business applications for mobile marketing are expanding every day. Every form of digital marketing relies on compelling content to attract interest and engage prospects and customers. Content marketing is the term used to describe the different types of content you can develop to deploy in your digital marketing campaigns. Content marketing can take many forms, including blogs, infographics, whitepapers, ebooks, videos, podcasts, quizzes, slide decks and webinars. Unlike advertising, content marketing is not blatantly promotional but instead employs more subtle tactics to inform, educate or influence a desired target market. You can use content marketing to establish authority on particular subjects or create buzz for your brand. One of the key advantages of content marketing is that you can do it on virtually any budget. A do-it-yourself (DIY) approach to content marketing will cost you mere pennies or, if your budget allows, you can work with copywriters, videographers, designers and other content development experts to create content for your business. Read our content marketing statistics guide to learn more about the value of content marketing and latest trends. Featured Partners 1 Constant Contact Yes Yes Advanced Automation (Abandon Cart Reminders, etc.) 1 Constant Contact On Constant Contact's Website 2 Klaviyo Email, SMS, mobile push, and more 350 integrations, no coding needed Predictive analytics, personalized feeds, benchmarks 2 Klaviyo On Klaviyo's Website 3 Hubspot Free Marketing Yes Customizable templates, AI subject lines  copy 3 Hubspot On HubSpot's Website There are several key advantages of using digital marketing. Here are the top benefits: While digital marketing can be very effective for building business results, you must understand the drivers of success. When you embrace direct marketing best practices, youre far more likely to achieve the stellar results you want. Before engaging in any type of digital marketing, you must establish SMART goals . Specifically, what do you want to accomplish? Examples of top digital marketing goals include: You must have a well-defined audience in mind before selecting digital marketing channels and content marketing strategies. Otherwise, you risk creating messaging or using digital marketing tactics that are off the mark. Defining your target audience begins with identifying shared attributes, including age, gender, income and education levels, geographic locations, interests and purchasing patterns. Next, you need to identify the specific problems your audience is facing or the pressing desires they have. Once your target audience is defined clearly, you can develop digital marketing messaging that highlights how your business solves their top problems or satisfies their needs. Establishing a digital marketing budget will keep you from under or overspending. Setting clear marketing goals and success targets will ensure your digital marketing spend is on target. You may choose to establish a budget for each digital channel or an overall budget for all efforts. Its important to have a good handle on digital marketing costs to set a strong budget. Be sure to consider the technologies youll need to deploy your digital marketing efforts, including SEO software, email marketing software, website hosting services and social media management tools. If you plan to do PPC advertising, you must research costs related to the platforms you intend to use. PPC costs are platform-specific and Google Ads and most social media channels offer extensive information about PPC costs on their advertising portals. Other costs you may need to incorporate into your digital marketing budget include marketing services for copywriting, videography and design. If your budget allows, you can work with a traditional marketing agency, which can cost anywhere from 75 to 300 per hour. If youre on a shoestring budget, you may want to hire freelancers from popular gig sites, such as Upwork, Fiverr and Freelancer.com, which can cost as little as 15 per hour. Launching a company website is the first step in digital marketing for many businesses. The additional digital marketing methods you choose depend on what youre selling, where your ideal audience is spending their time and how much money you want to spend on digital marketing. Social media, SEO and email are the most popular digital marketing techniques, but you may find a different mix works best for your target market. The beauty of digital marketing is that its relatively easy to track results. In setting your goals, you establish what youre hoping to achieve. In the analysis stage of digital marketing, you measure how well youre performing against established goals. Set a cadence for how often youll monitor digital marketing performance data: daily (which is only advised in initial stages or when digital marketing spending is high), weekly or monthly. Very few digital efforts achieve stellar results out of the gate, so dont be disheartened if you arent hitting stretch goals on the first iteration of your marketing efforts. Learn from your analyses to refine your digital marketing strategies accordingly going forward. Digital marketing is one of the most powerful tools businesses have to generate attention and sales for their products and services. Several digital marketing techniques, including social media marketing, email marketing, SEO, PPC advertising and content marketing, offer exceptional ROI potential. You dont need a large budget to get started, so digital marketing can be an effective tool for all types of businesses. Digital marketing is a business strategy that uses online platforms to generate awareness and sales for products or services. There are many ways to conduct digital marketing, including through social media, email, SEO, PPC and content marketing. A digital marketer uses digital devices and digital marketing techniques, such as social media marketing, SEO and content marketing to drive awareness, interest and sales of business products and services. To be an effective digital marketer, you need to be adept with a variety of digital media as well as possess strong marketing skills. To get started with digital marketing, youll need a computer and an internet connection, which will involve an initial outlay of around 500 to 1000, plus 50-120 per month. Youll also need appropriate software, such as email marketing software , SEO software and marketing automation and customer relationship management (CRM) software . Together, these software programs can cost between 0 and 500 per month. In addition to the software and hardware youll need to start digital marketing, you may also need digital marketing training. You can develop digital marketing skills via self-study for free or participate in a training program that could cost anywhere from 150 for a digital marketing certificate to 100,000 or more for a full four-year degree. There are several ways to get started in digital marketing, even if you have no experience. You could enroll in a digital marketing certificate program or take digital marketing courses online or at your local college. If you already have some general business or marketing skills, you can get an internship in a marketing department specializing in digital marketing. Social media marketing, SEO and email marketing are three of the top digital marketing platforms business marketers use. The top marketing automation tools used for digital marketing include HubSpot , Marketo and Salesforce . Janette Novak is a freelance journalist and consultant who specializes in teaching online business and small business marketing. Previously, Janette owned a boutique marketing agency and served as a Chief Marketing Officer for a leading professional training services provider.",2596
https://blog.hubspot.com/marketing/what-is-digital-marketing,Digital Marketing: Everything You Need to Know to Get It Right,"Jul 28, 2025",3
https://mailchimp.com/marketing-glossary/content-marketing/,What is Content Marketing and does it still work in 2025? | Mailchimp,"Summary created with the help of our AI How does it work at different sales stages? Terms apply. Have more questions? Call Sales at 1 (800) 315-5939 Content marketing is a marketing strategy used to attract, engage, and retain an audience by creating and sharing relevant articles, videos, podcasts, and other media. This approach establishes expertise, promotes brand awareness, and keeps your business top of mind when its time to buy what you sell. A content marketing strategy establishes your brand as a thought leader, boosting trust among your audience by creating and distributing content in various ways. Content marketing is a type of inbound marketing that attracts customers and builds loyalty, making it effective for customer retention . Key content formats: Content marketing is the development and distribution of relevant, useful contentblogs, newsletters, white papers, social media posts, emails, videos, and the liketo current and potential customers. When its done right, this content conveys expertise and makes it clear that a company values the people to whom it sells. The consistent use of content marketing establishes and nurtures relationships with your prospective and existing customers. When your audience thinks of your company as a partner interested in their success and a valuable source of advice and guidance, theyre more likely to choose you when its time to buy. Businesses with blogs see 67 more leads and branded videos drive 88 of purchases. Content marketing is a go-to tactic thats proven to work. Also, it provides a competitive advantage. Take a look at what the data says about content marketing: Content marketing benefits businesses in many ways. When done right, an effective content marketing strategy can: Your business can use content marketing to attract leads, make a case for your product or service when someone is researching what to buy, and close sales. To use it effectively, youll need to deliver the right content at each stage of the sales cyclefrom awareness through consideration to purchase. If this sounds complicated, dont worry: Approaching content this way actually simplifies the process. Heres how companies use content marketing in each stage of the sales cycle to engage and sell. At the first stage of the sales process, your content should focus on the top concerns of your audience. Writing about their pain points, challenges, and questions gives you the best chance of engaging with them. Content at the awareness stage should be educational, how-to advice. Save your selling for the consideration and closing phases. The best content for this stage includes articles, blog posts, e-books, videos, and newsletters. Examples: In the consideration stage, content should offer a hybrid of helpful information and marketing. It should educate the reader about what features or functions to look for and how various features address their needs. Of course, your content should lean toward what your business offers. The best content for this stage includes case studies , how-to articles, how-to videos , and checklists or worksheets. Examples: Content marketing plays an important role when a prospect is close to buying. At this stage, you can focus on sales, as long as you continue to drive home why youre the best choice rather than just how great your services or products are. Your central message here should be your expertise, knowledge, and the differentiating benefits of what you sell. Best content for this stage: case studies, user-generated content, buyers guide, product video, research report Examples: Success in content marketing comes from knowing your readers and creating valuable, well-placed content theyll want to engage with. Content marketing can feel overwhelming, but it doesnt have to be. A successful content marketing campaign should be manageable and sustainable. Take these steps to get started: To create content for a particular reader, you need to have a clear idea of their priorities, challenges, and preferences. If you have detailed descriptions of your various segments, choose 1 or 2 to write for. Otherwise, craft profiles of your audience members and prospects before starting. The right format corresponds with what stage of the sales cycle youre creating content for. Another important consideration includes what formats will best help you showcase value. For some, this will be a video; for others, a checklist. An audience will judge your content on its quality, and they should. Identify the right resource, internal or external, to create this work. Regardless of who creates it, hire a professional proofreader to review anything before it goes out the door. Will you post content on your site, email it to people, or print it for an event? Start with where you know your audience is likely to be , and choose formats that make sense. For example, an article makes sense to send via an email, a checklist or worksheet can be posted on social media, and a buyers guide is a good follow-up to a pitch. Once you know who your target readers are and the best formats for every stage in the sales cycle, create a short-term (3-6 months) plan. Its easy to develop a content marketing plan thats overly ambitious. However, the plan you design should have content elements you can realistically make based on your budget and resources. Keep track of how long it takes you to create each piece of content so that you can build that time into your schedule. Compelling content is clearly written and doesnt contain jargon that only you and your peers will know. It should also include detailed how-to advice. A short, relevant, actionable piece of content is best. Find out how to create irresistible social media content that solves problems, teaches skills, and keeps your audience engaged and coming back for more. Content marketing makes it easy for good prospects to find your business. However, you can boost your efforts with search engine optimization (SEO) . Here are a few important best practices: Keywords are the foundation of your SEO effort. These all-important words and phrases are the terms a prospect types into a search engine when theyre looking for a company, product, or service. When you include the right keywords in your content, youll attract more traffic . The best keywords are: SEO has evolved so that search success depends in part on how well your content does what it says itll do. Search engines review content copy, assess its relevance, and determine whether it delivers on what the headline promises. Because of the importance search engines place on copy, using keywords throughout your content is important. Use the following guidelines: Once you have content, its time to get the word out about it. Social media  Facebook , LinkedIn , YouTube , Twitter , Medium, Instagram , and others is a proven and easy way to promote your content. You write a post and link to your content, and then voila! People are engaged. You can do this through 3 steps: To learn more about how Mailchimp can help with your social media strategy and how to create an effective social media calendar , check out the comparison of our free social media management tools versus others. Content marketing still works in 2025, but it has evolved significantly. It's no longer just about publishing blog posts; it's about creating strategic, high-quality, and personalized experiences across various platforms. Content marketing still works, because: Let your expertise and unique value shine through by creating content that attracts, engages, and sells. With some planning and systematic content marketing, you can reach the right people and drive brand loyalty . Mailchimp can help you take your online content marketing strategy to the next level by allowing you to create optimized content for social media, your website, and your email marketing campaigns . Use our tools to make branded content, including landing pages and paid ads, that can inform your customers about your offerings and business. With your own brand style guide , you can begin to build a brand identity and let your business show customers its remarkable personality. Mailchimp has the tools and resources to attract, engage, and retain the right customers for your business.",1345
https://sproutsocial.com/insights/social-media-marketing-strategy/,How to Build Your Social Media Marketing Strategy | Sprout Social,"Social Media Marketing Jump into this comprehensive guide for crafting an effective social media marketing strategy from scratch. We offers insights into defining goals, selecting the right platforms and measuring success through key metrics. Want to increase your teams productivity and effectiveness with one comprehensive platform? Sprout Social all-in-one social media management tools will help you unlock the full potential of social. Try Sprout free for 30 days Reading time 33 minutes Published on February 19, 2025 Table of Contents Share Summary Looking to fine-tune your social media marketing strategy? Nows the perfect time to make it happen. In a landscape with more competition, content and networks than ever, a succinct strategy gives you the focus needed to say no to efforts that dont serve your goals. Thats why we put together a comprehensive guide to creating a social media marketing plan from scratch. Whether youre new to social or want to double-check your priorities in 2025, this guide has you covered. Social media marketing means using social media platforms like Instagram, X (formerly known as Twitter) and Facebook to promote your brand and sell your product or service. If your business comes out with a new item and you plan to promote the launch on social media, thats social media marketing. If you interact with your customers via comments, thats social media marketing. And if you create engaging content that showcases your brands values and story, thats social media marketing too. This form of marketing requires you to use social media management skills and tools. Just as you prepare other aspects of your marketing strategy, you need to have a plan for your social media marketing. Honing your strategy is easier with the right tools. See how Sprout Social can help with a 30-day free trial. Try Sprout for 30-days free Social media marketing is poised to get even bigger results than ever. Data from our 2024 Social Media Content Strategy Report shows consumers of all ages are engaging more than ever with brands on social media. Dynamic content, especially short-form video formats will become the primary focus, with 84 of social users having an Instagram profile and 61 using Instagram to find their next purchase. Influencer marketing will be a driving force for brands in 2025 as they integrate influencer content more intentionally for a more effective multi-channel approach. This will include edutainment , i.e. content that educates and entertains, which is also poised to be the most engaging of all brand content on social. Brands like UK-based financial giant Barclays are already engaging their audiences with educational content on their social media to meet consumers where they are and build brand trust. A social media marketing strategy is a comprehensive plan that integrates your social media efforts with your teams goals and broader business objectives. This alignment ensures that your activities are optimized for performance and deliver measurable results that contribute to your overall marketing success. A well-defined social media marketing strategy also sets clear boundaries around your teams time and expertise. Social media is a unique channel, and while nearly everyone uses it, this widespread usage often leads people to overestimate their expertise. Social media managers often face requests to share content that doesnt align with the overarching strategy or audience interests. Not to mention proving social media ROI to ensure leadership teams can see the value of social and its benefits in terms of reach and revenue. Having a defined social media strategy helps navigate such requests, and so does having clearly defined metrics to prove the impact of social to executives. A social media management tool with capabilities such as Social Listening , Post Scheduling and Analytics and Reporting can help with this by enabling social teams to stay targeted and impactful. This question can feel like a bit of a no-brainer to marketers that live and breathe social. Building a sustainable social media strategy requires understanding both current best practices and the context of social, a perspective Sprout has developed over 15 years helping brands succeed. That said, being able to clearly articulate the advantages of a cohesive social media strategy is crucial for securing buy-in from other stakeholders. Heres how a well-defined social media strategy benefits your brand and business: According to The 2025 Sprout Social Index , 90 of consumers use social media to keep up with trends and cultural moments. Amid a fractured cultural landscape, social media has emerged to fill a seemingly endless need for content. And when brands commit to a cohesive social media marketing strategy, they develop the consistency needed to form a brand identity that cuts through the noise to resonate with a target audience. The rise of influencer marketing has further enabled brands to deepen their reach and drive meaningful engagement. According to the Q1 2025 Sprout Pulse Survey , 90 of marketers reported that sponsored influencer content performed better in terms of engagement compared to organic content posted on their brand accounts. Socials impact on brand trust is palpable, particularly for younger consumers. According to a Q2 2024 Sprout Pulse Survey, 78 of consumers surveyed agree that a brands social media presence has a larger impact on whether or not they trust that brand. That number goes up to 88 for Gen Z . What influences that trust the most? The content you post on social. But having a social media presence isnt enough. Consumers also want authentic content from brands they follow. The 2025 Sprout Social Index showed consumers rank authenticity and relatability as two out of the three most important brand content traits. Your social media marketing strategy creates the infrastructure needed to prove the ROI of your efforts. Without one, you may be able to report on social media KPIs , but itll be much harder to showcase how they align with strategic objectives. For example, say you work with an automotive brand and one of your top business objectives is to increase market share with parents of young children. With that in mind, you can develop a strategic content pillar around this specific audience, and report on the performance of those posts over time. With a social listening tool , you can even measure how your brands share of voice stacks up against key competitors. This is a highly effective way to gauge your brands visibility and market share within your industry. Learn more about social listening tools Our Q2 2024 Pulse Survey also found that social media is the top channel for product discovery, with 81 of consumers surveyed using the channel to shop around for their next purchase. As social commerce adoption continues to skyrocket in the US and abroad, social media now supports a full-funnel experience. Even B2B brands are using social media to enhance lead generation and drive pipeline growth. For example, when Simpli.fi , an advertising success platform, integrated employee advocacy into their social media strategy, the company realized 90,000 in earned media value in three months. Social media marketing transcends industries and offers businesses a dynamic platform for brand amplification, customer engagement and strategic growth. From healthcare to retailsocial media marketing fosters competitive agility and cultivates brand awareness and trust to drive sustained market influence. It also provides key social data that gives businesses nuanced audience insights in almost real-time. These insights can influence the entire organization through customer-centric data. Plus, because social media marketing enables quick and hyper-targeted access to your demographic at a fraction of the time and cost traditional marketing takes, it drives a more enhanced ROI for the business. We spoke to Penn State Health , a multi-hospital academic health system serving the central Pennsylvania region to understand how social media has been instrumental in enabling them to achieve their business goals. To say that social media has transformed the way customers interact with a business is an understatement. Most customers are social-savvy today. Even baby boomers are on social media for news, entertainment and brand interaction. According to The 2024 Content Strategy Report, 74 of Baby Boomers have profiles on YouTube and Instagram, while Facebook has the highest91. The popularity of user-generated content, influencers and content creators has further bolstered experience-focused brand interactions that consumers crave. This has leveled the field between B2C and B2B brands. You need to meet consumers where they are in their fast-paced livesand social gives them that opportunity. As Amy Peiffer, social media lead at Penn State Health aptly puts it, Peoples needs extend well beyond nine to five when somebody is in a clinic office picking up a phone and when people need answers to their questions. Often they go to social media because its the communication platform that theyre most familiar with and meets them at the times that they are working nine to five themselves. They may not necessarily have time to pick up the phone during the day. As with all regulated industries, the Penn State Health social team adheres to strict protocols when communicating with patients or caregivers on social. HIPAA regulations mean it does not answer specific health condition questions on social. However, the team is able to direct audiences to the right resources to ensure they get all the support they need. While healthcare is a highly regulated field that limits all we can use social media for, it at least allows us to be an intermediary to connect people to the right resources at the right times, Peiffer explains. Social media is a goldmine of business intelligence made up of unfiltered, real-time conversations between consumers and brands, all of which you can tap into with Social Listening . With social listening, you can uncover trends and themes that reveal everything from customer favorites to areas where your company is falling short. This enables you to take action based on customer feedback. Sprouts Listening tool also uses AI social media sentiment analysis so you can identify positive, negative and neutral chatter around you. You can automatically tap into negative brand mentions in comments and DMs to get targeted insights into where exactly you need to improve. Perhaps one of the most valuable social media business benefits is the ability to study your competitors. You can use competitor analysis tools to help you understand your competition. What are they currently promoting? What sort of ads are they running? How is your content strategy different from theirs? By conducting social competitive analysis , you can uncover opportunities to experiment with your own content or advertising. For example, maybe you notice that your competitors are crushing it with Facebook Ads but their Instagram presence is lacking. In turn, you might explore influencer marketing or user-generated content campaigns for the sake of standing out from the crowd. You can look at your competitors social performance in a cinch with Sprouts tools. Our competitor and sentiment analysis reports allow you to monitor growth and engagement to ensure that you arent falling behind. Through this analysis, you can also discover which pieces of your own content are earning the most engagement. Understanding your top-performing content is key to understanding how to break through the noise in your industry. Customers expect quick communication and authentic engagement from brands when they reach out to them for grievances or solutions. And businesses understand this. They know they need to go beyond expectations to deliver social customer service that supports long-lasting relationships. According to the Sprout Social Index , 53 of brands say customer service contributes to the organizations social strategy. With more people using social media today, brands can have meaningful, forward-facing conversations with customers easily. Another crucial benefit of social media marketing is that it helps you enhance brand engagement through employee advocacy . Our data shows that posts employees share have an 8x higher engagement rate than brand content. Plus, employee content has 20x greater reach than all organic channels combined. Take a listen to the video below to learn more. Securing more top-of-funnel leads is another key social media business benefit. Billions of people are active on social media daily and theres a large chance your audience is already online. Whether through paid ads or content promotion, you can attract more top-of-funnel leads by raising awareness for your brand. Having a social presence introduces people to what youre selling and represents another way to score more sales. Even if these leads dont make purchases directly through social, raising awareness could lead them to become full-fledged buyers later on. After all, they cant buy until they know your brand exists. Consistently publishing on channels relevant to your business signals that youre active and open to new customers. Social also enables you to tap into the power of social media search engines when someone looks up your brand. Shares and click-throughs via social represent positive search signals to Google, making social a sizable traffic source. You can track your social traffic with tools like Google Analytics . Dont neglect social media as a content distribution channel. A popular piece of content that scores hundreds of likes and shares can drive serious referral traffic to your site. Plus a piece of content that ranks high on the Search Engine Results Page (SERP) can bring in traffic too. You can optimize your social scheduling with Sprouts patented ViralPost technology that ensures youre utilizing optimal send times. Social media has transformed so many industries, and communications professionals are familiar with the impact of these online spaces. Brands arent limited to traditional mediums like radio and print newspapersyou can use social media to supercharge your media relations and investor relations strategies. Journalists use networks like X to find sources and potential stories, so meet them where they are. Follow and engage with journalists who report for your publications of interest to build rapport. Then when the opportunity arises, you can pitch to them. Along with connecting with journalists and publications, you can bolster company announcements and accomplishments through social posts to catch the eye of investors. Similar to job candidates and reporters, investors use social media to learn about brands. Start Your Free Trial Now that weve seen the critical ways social media marketing can elevate your business, lets walk through how to create a plan. Heres our six-step process for developing a social media marketing strategy that drives results. Social media strategy planning starts with your goals. Whether you want to expand your team, build a larger following, or a more active community, taking the time to define your social goals is the first step to reaching them. The goals you set will inform the key performance indicators (KPIs) you track, and how much time and energy youll need to dedicate to your campaigns. What really matters is that you set realistic social media goals . We recommend tackling smaller objectives that allow you to scale your social efforts in a way thats both reasonable and affordable. Below are some examples of social media marketing goals that businesses of all shapes and sizes can pursue. Goal example 1: Increase brand awareness Brand awareness means getting your name out there. According to the Index, 93 of consumers agree its important for brands to keep up with online culture. Try to avoid solely publishing promotional messages and strike a good balance with authentic content that emphasizes your brands voice and story. The Index further found consumers favor brands that post original content and interact regularly with their audience. For example, in this TikTok video, Sani, a family-owned apparel company features a day in the life of the brands founders while visiting India for business. If you want to increase brand awareness, here are the social media metrics youll want to focus on: As you define your objectives and define these goals, its also important to consider the role of both organic and paid social media in your overall strategy. Goal example 2: Generate leads and sales Whether online, in-store or directly through your social profiles, followers dont make purchases by accident. For example, are you alerting customers about new products and promos? Are you integrating your product catalog into your social profiles? Are you running exclusive deals for followers? Social media gives you an avenue to generate revenue. Here are the metrics youll want to track if youre focused on lead generation and sales: Goal example 3: Grow your brands audience Bringing new followers into the fold means finding ways to introduce your brand to folks who havent heard of you before. Growing your audience also means discovering conversations around your business and industry that matter the most. Digging through your social channels is nearly impossible without monitoring or listening for specific keywords, phrases or hashtags. Having a pulse on these conversations helps you expand your core audience (and reach adjacent audiences) much faster. Important audience growth metrics include: Goal example 4: Provide holistic customer care The Index shows most consumers believe the most memorable thing a brand can do on social media is respond to customers. This means companies need to experiment with messaging and content when approaching customer care . For example, does your team have a protocol for handling -mentions and comments? Do you have templated responses to FAQs? Does your brand promote user-generated content and hashtags? Your customers can be your best cheerleaders, but only if you give them a reason to grab the megaphone. If you want to improve your business approach to social customer care, here are the customer service metrics you need to track: Goal example 5: Drive traffic to your site to illustrate the ROI of social efforts The Index shows that marketing leaders plan to measure social media success with overall engagement, audience growth, social interactions, web visitors and share of voice. If youre laser-focused on generating leads or traffic to your website, social media can make it happen. Whether through organic promotional posts or social ads, keeping an eye on the following metrics can help you better determine your ROI from social media : Any combination of these goals is fair game and can help you better understand which networks to tackle, too. When in doubt, keep your social media marketing strategy simple rather than complicating it with too many objectives that might distract you. Pick one or two and rally your team around them. Bonus resource : A great deck can bridge the gap between raw social data and direct business value. Use this presentation template to pitch a compelling vision for your next campaign, initiative or annual strategy Get the deck template Making assumptions is bad news for marketers. Both leaders and practitioners can disprove assumptions from the valuable insights social data provides. With the right tool, marketers can quickly research their audience . No formal market research or data science chops are necessary. What you need to know about your audience to influence your social media marketing strategy is already available. You just have to know where to look. Remember: Different platforms attract different audiences. Social media demographics and benchmark statistics are great for understanding where your target audience lives, but its also important to understand the nuances of each social network so you can decide where your business needs to be. For the sake of narrowing down where you should spend your time, below is a quick overview of each of the major social platforms: Requiring minimal setup and providing a place to go back and forth with followers directly, theres a reason why X remains one of the go-to platforms for customer service . If youre trying to master the social media marketing basics of hashtags, tagging, brand voice and social media etiquette, look no further. With more than 3 billion users , Facebook is the worlds leading social media platform. It should be a part of your customer service strategy and marketing campaigns regardless of whether youre a B2C or B2B business. The platforms algorithms are much more sophisticated today and focus on showing users the most relevant, meaningful content based on inventory, signals, relevancy scoring and other factors. Plus with Meta investing in expanding advertising features within its short-video format feature Reels, the platform is poised to become a major network gone far beyond its humble origins of being a medium for social networking. Instagram is a network centered around visual content. From eye-popping photos to clever captions, its all about finding unique ways to show off what youre selling. Whether youre a regional business or one with a global presence, the platform offers you the creativity to explore different types of content to reach your audience. Check out how Australian garden center chain Bunnings uses Instagram to promote its products. When Meta released Threads on July 5, 2023, the social network received over 100 million registrations less than a week after its launch, making it the most rapidly downloaded app ever. The launch of Threads sparked conversations about its role in the fediverse, or decentralized social media . But, for now, Threads is a text-based social network that users can sign up for through their current Instagram account. Users can post on mobile, but Threads is also available on desktop. Threads are great for brands who already have Instagram accounts because the sign-up process is pretty seamless. LinkedIn is a network laser-focused on business trends and networking, and so a goldmine for anyone networking in the B2B space. Looking to get in touch with an influencer, marketing manager or CEO? Chances are you can find them here. However, the benefits of LinkedIn marketing go beyond networking, such as content distribution and lead generation. We also have a guide for LinkedIn best practices so you can get full advantage of those benefits. Pinterest marketing is insanely popular, especially among Gen Z and Millennials. Over 465 million people use this visual pinning platform every month to find inspiration and their next purchase. Like Instagram, Pinterest thrives on imagery and inspirational content where products serve as the proverbial centerpiece. TikTok remains one of the most popular apps in the world. Along with its viral trends and niche communities, the short-form video app is known for its hyper-personalized algorithm that keeps users scrolling for hours. TikTok marketing has changed the game for brands, allowing them to connect with customers in an entirely new way. Looking for more in-depth data on other platforms? Explore key Snapchat statistics to understand its audience and usage trends. YouTube has gone beyond being a video-hosting platform, transforming into the worlds most popular search engine, second only to Google. And considering that video represents the top-performing type of content across nearly every social network, YouTube is a great place to house your videos and optimize them for search and lead generation. In fact, according to The 2024 Content Strategy Report, consumers want brands to post entertaining content but also content that educates them about their products and services, followed by influencer content and contests and giveaways. There are more than 15 social media platforms your brand can use , but dont spread yourself too thin. Consider those platforms that make the most sense based on your industry and target audience. Do your homework on your existing social media audience and focus on networks where your core audience is already active and determine how you can segment them. Thats why many brands use a social media marketing dashboard that provides an overview of whos following you and how they interact with you on each channel. For example, Sprouts analytics dashboard puts your audience demographics front and center. It highlights which social networks see the most activity, helping you ensure you spend your time on the right network. You can also use analytics to determine if you should create a new social media account . With Sprout, you can view X, Facebook, Instagram, LinkedIn, YouTube and Pinterest data side-by-side in a customizable format thats exportable by date range and profile. There are plenty of other sources of valuable audience data to supplement your social media insights. This includes your Google and email analytics, CRM, customer service platform, and even your best-selling products. All of the above will ultimately influence everything from your marketing messaging to how youll approach customer service or social commerce . No surprises here. Your social media marketing strategy hinges on your content. At this point, you should have a pretty good idea of what to publish based on your goals, audience and brand identity. You probably feel confident in which networks to cover, too. But what about your content strategy? Below are some tips, ideas and inspiration that can help. Coming up with a content strategy might seem like a lot of legwork, but in reality, it all boils down to your goals. For example, Nike builds its entire social media strategy around inspirational storytelling to foster a deep, emotional connection with its audience. To ensure your content remains focused and aligned with your brands objectives, you can build your content plan around a set of social media content pillars . Regardless of what you might post, coming up with a hashtag to couple with your content is a brilliant branding move. Hashtags can be used to get your attention and encourage people to share their photos interacting with your brand. One of the best ways to stand out on social media is to have a distinct brand voice. Chances are youve seen a post from a particular brand that just feels like, well, theirs. The quippy, casual tone that makes Discords X presence beloved by casual users and moderators alike is a great example. The key is to present yourself as a human rather than a robot. Adopt a consistent brand voice and style thats appropriate for your business. Timeliness is arguably more important than ever for marketers. Not only are you expected to put out fresh content regularly, but also to always be on for your followers. But you cant always expect customers to operate on your clock. Plus, timeliness is a tall order when youre strapped for resources or are part of a small team. As evidenced by our best times to post on social , brands have a lot of ground to cover in terms of frequency and how much content to push. Its important to pay attention to the optimal times for engagement so you can automate the most tedious aspects of your social presence without having to worry about posting in real time. Another important factor is ensuring you respond to customer comments in a timely manner. If youre strapped for time and have a small team, consider taking advantage of chatbots and AI  automation to ensure youre engaged with your customers so you can serve and engage with customers when your team is offline, which leads us to our next point. Thanks to the rise of TikTok and Instagram Reels , social video is booming. Short-form productions continue to dominate the social space across all platforms due to their high engagement rates. Thanks to advancements in DIY and remote video production , you dont need massive budgets to be successful. All you need is a laptop or smartphone and a few tricks of the trade, like video length best practices and editing tools . Both personal and personable content should be a cornerstone of your social media marketing strategy. Dont be afraid to remind followers of the humans behind your posts. According to the latest Index, consumers crave original, entertaining and humanizing content from brands. For example, Zoom has excellent original content on their Instagram and TikTok accounts, like this Reel that explores the different signs in the workplace: If you havent already, its time to tap into the power of influencer marketing . Social partnerships are very effective when executed correctly. They can help drive traffic to your website, produce compelling content and inspire purchase decisions. But consumers care about creators qualifications, so choose wisely. The two most important qualifications of content creators working with brands is their experience with the productservice and their authenticity. Identify creators who align with your brand and consider how they can help you craft stand-out content for your audience. According to the 2024 Influencer Marketing Report , consumers overall look to engage with influencers who align with their personal values (53) and seem authentic (47), even when posting sponsored content and taking part in brand campaigns . Across ages and genders, honest and unbiased content stops audiences mid-scroll, while aspirational content is least likely to catch their attention. However, the report also found that authenticity is losing its appeal among younger generations. While trust in influencers remains strongand is even growing among younger consumersonly 35 of Gen Z value authenticity, compared to nearly half of Millennials, Gen X and Baby Boomers. This indicates that younger generations are more aware of the influencer-brand relationship and how it influences their buying decisions, but theyre comfortable with it. Instead, they prioritize other indicators of trustworthiness, such as follower count, posting frequency and community loyalty. Social media teams have a unique advantage when it comes to understanding customer sentiment. Youre the eyes and ears for your brand online. Those insights can do more than just inform your marketing strategy. They can transform your business. Stand-out social media teams will approach cross-department collaboration with enthusiasm and intention. The short answer? All of them. Index data shows around three-quarters of marketing leaders already say organic and paid social marketing are top priorities for the organization. However, dont bite off more than you can chew. Instead, start where you think you can make the most impact. Here are a few ideas to jumpstart your strategy. Collaborating with human resources on social-first employer brand initiatives can do more than just fill open roles quickly. It can attract stronger, more qualified candidates as well. Many companies have embraced social recruiting strategies, such as publishing creative were hiring posts on LinkedIn to attract top talent. Data from The 2023 Sprout Social Index notes marketers planned to track conversations and sales directly resulting from social efforts in 2024 to better connect the value of social to business goals. Sharing social insights with your sales organization can empower reps to work smarter in the context of increasingly digital customer journeys. Consider learning more about social selling to leverage the power of online networks even further. Youve probably received quite a few feature or product requests while managing your brands social inbox. With a social media management tool , you can distill those messages into actionable insights for your product or merchandising teams. These insights can complement existing roadmap research, creating a customer-focused plan that delights. Monitoring customer service metrics like average reply time, average wait time and response volume can help your social customer care team identify whats working well and spot opportunities for improvement. Marketers are using social media customer service software to elevate their support strategies and get the most out of their tech stack. By now you should have a big-picture understanding of your social media strategy. However, its important to adapt your strategy throughout the year. Without continuously analyzing your efforts, youll never know how one campaign did over another. Having a birds eye view of your social media activity helps put things into perspective. This means looking at your top-performing content and adjusting your campaigns when your content stalls . Theres no denying that a lot of social media is a matter of trial-and-error. Monitoring the metrics behind your campaigns in real time allows you to make small tweaks to your social media marketing strategy rather than sweeping, time-consuming changes. Doing social media marketing right starts with being diligent about your data. You can be reactive in the short term to get the most out of your running campaigns, and then proactively use these takeaways to inform your next strategy overhaul. To guarantee that you get in front of as many customers as possible, monitoring your growth is a major must-do. With Sprout, social reports can clue you in on everything from your top-performing content to how engaged your audience is. These reports are crucial for accountability and guaranteeing your numbers continue to tick upward. Reporting on data is also important for the sake of sharing valuable insights from social with your coworkers and colleagues. Remember that 60 of organizations use social data dailybe one of the brands that embrace it . Sharing this information in regular reports not only holds you accountable for your efforts but also highlights the impact and bottom-line results your social strategy produces. Based on your data, you can better assess whether your KPIs truly ladder up to your overarching company goals or whether they need to change. Maintaining an effective social media marketing strategy requires a balance of planning, execution and continuous optimization. Here are focus areas youll need to pay attention to to ensure your strategy remains evergreen. Winning leadership buy-in is one of the most important factors that can ensure your social media marketing strategy is a success. Approaching it in a layered manner and showcasing how your social media strategy is impacting your business, with tangible data, can help. Now that you have broader organizational support, create guardrails so youre on track with your goals. To do this, it helps to define what success looks likeis it brand awareness, engagement, lead generation or conversions? Align your KPIs (followers, reach, CTR, engagement rate) with your objectives. The 2024 Influencer Marketing Report found 49 of consumers make purchases at least once a month because of influencer posts. This means influencer marketing can have the most impact on your business compared to your other social efforts. To ensure you get the most of your influencer ROI , integrate an influencer marketing platform into your existing tech stack. This will help you automate data collection and analysis and enable you to track and measure the impact of influencer-led campaigns on your revenue. Sprout Influencer Marketing integrates into your martech stack seamlessly so you can search for the right influencers and collaborate with them, streamline influencer workflows, and manage influencer compensation and campaigns, all through a unified dashboard. Use AI for smarter workflows and get time back to focus on strategy. Use AI and automation for content recommendations, content creation, automated posting and sentiment analysis for brand insights. Similarly, implement chatbots on your social channels for instant customer interaction and improve customer support. This video highlights how Sprouts Bot Builder helps businesses. You can also use AI to automate reporting to track performance efficiently and provide different teams with the exact data and insights they need. Social media marketing gives you access to real-time data on customer experience and shifting consumer preferences. Having this data at your fingertips ensures youre making decisions that go beyond personal feelings and anecdotes and are based on tangible evidence. With this comes a greater ability to show that specific initiatives, types of content, themes or campaigns have or have not supported KPIs that weve identified as important to what were trying to achieve. When you have that level of data available, and in an easy-to-set-up way, it unleashes a lot of power in your decision-making and decision backing. Peiffer explains. One of the benefits of social media marketing is that you get comprehensive audience and campaign performance metrics easily and quickly to ensure youre aligned with your primary goals. For example, with Sprouts My Reports tool, you know exactly what metrics align with your business priorities and how to turn that engagement into tangible results. This makes it easy to prove your social ROI because now you can easily showcase how your social marketing strategy is performing, driving leads, and helping with your brands integrated marketing strategy. Rachael Goulet, Director of Social Media at Sprout Social explains how her team uses My Reports. Since My Reports are also highly customizable, its easy for social media managers to pull the exact KPIs leadership teams and stakeholders are interested in and reveal the impact of social on the brand and business. When you have five minutes to present to other key stakeholders at the executive level, they are looking for fast, quick takeaways. Sprout allows us to pull just that much information thats customizable for those key stakeholders. We can even automate it, such that, if they have a monthly check-in, for example, and they just want to know how some of our strategic priority areas are performing at that time, we can pull KPIs specific to those areas. Peiffer notes. Through reporting on social data youre also able to achieve greater transparency and accessibility through meaningful metrics. Data-driven decision-making is being built into the culture beyond our social media and web team, because we can build greater transparency and accessibility using reporting and social listening dashboards, she says. Because these reports are highly visual, and can be as robust or simple as we need them to be to communicate with key stakeholders, it allows us to empower really anyone to communicate the results of our efforts on social media in a way that is meaningful to their goalswhether that be an executive to a governance council, a director to our dean or an account manager to a service line physician, Peiffer adds. Social media marketing enables businesses greater segmentation and tracking through platform-specific data and insights from AI-powered tools like Sprout. You can target audiences based on demographics, interests, behaviors and even sentiment analysis through social listening. Plus, advanced targeting features like custom and lookalike audiences can ensure your ads reach the most relevant users. As Sprout customers, Penn State Health has used Sprouts Tagging feature to help benefit from improved segmentation and tracking for their marketing and communications objectives on social media. The tagging architecture within Sprout has really allowed us to have greater segmentation and tracking for those separate and distinct audiences and also the variety of content that were putting out, Peiffer notes. AI-powered analytics further helps track engagement, conversions and customer journeys. This will enable you to tailor content to audience personas and optimize campaigns in real-time for better social ROI and audience alignment. Content that resonates with your customers, including user-generated content and success stories, often goes hand-in-hand with higher engagement and conversion rates. Social gives you the advantage of curating this impactful content quickly. For example, you can monitor mentions and tags to uncover positive customer interactions and then share them on your social media channels to nurture brand trust. Many brands also curate customer photos to use throughout their marketing campaigns. This is why having a branded hashtag is so important. By encouraging your customers to tag their content, you can find shareable posts that your followers will love while also making a connection with your customers. You can manage this process effectively through a dedicated UGC platform . A Publishing Calendar can also be useful to ensure your curated content is posted at a consistent rate to ensure you have a steady brand social media presence. However, when it comes to cyclical content, constantly creating awesome content can be taxinga challenge all brands face. AI in social media can help overcome this block and even enhance creativity. Theres only so many ways over time I can think to say its National Doctors Day, thank a doctor who has made a difference in your life, Peiffer explains. As social media managers, we can use tools like generative AI to get unstuck in these creative blocks and tailor it to our own brand voice and audience preferences, she adds. Sprouts AI tools have made a difference in how Penn State Healths social team creates brand content. I appreciate that Sprout gives several options when generating text. Im sometimes pulling from this piece and adding it to another, or it just inspires a wholly separate thought and Im writing something entirely different. That inspiration saves time and helps find a new way to say the same thing, Peiffer notes. Generative AI tools like Sprout Socials AI Assist in Compose can help you create content easily. All you have to do is add a few thoughts or drop a link and you get multiple caption options in different tones. Similarly, the Suggestions by AI Assist capability helps improve social media posts by instantly generating multiple variations of the post or adjusting its tone. Yet another important way to optimize your content strategy is to have a balanced mix of videos, infographics, carousels and user-generated content to create multi-format content and keep engagement high. Its also important to align content with your brand persona and not jump on every trend you see on social. The 2025 Sprout Social Index revealed this as one of the top things consumers want brands to stop doing. Brands need to be constantly accessible to customers because with social, customers are just a touch of a button away from brands they want to reach. This can also mean overwhelmed social teams balancing customer support, content management and slicing and dicing data for reporting. However, with an intuitive social media management solution, this daunting task can become easy as pie. According to Amy, Penn State Healths social team was able to build custom reports faster and more efficiently, such that the time to build customer reports dropped by nearly 70. They also reduced errors by 80 and troubleshooting turnaround time from 3-5 days to within an hour. This collective efficiency helped save team resources as well. We eliminated the need for an additional contractor-supported role due to efficiency gained for full-time team members, Peiffer explains. This video explains how the Sprout team uses our own tool to save time and increase workflow efficiency. Per the latest Sprout Social Index, among the top things customers want brands to start doing in 2025 is prioritizing quick, personalized customer care. Social Customer Care by Sprout Social helps brands achieve this. Whether its through Case management that enables global customer care teams to be on the same page or tools like Saved Replies that help deliver quick service while maintaining brand voice, you deliver the best customer experience ever, and more importantly, humanize your brand. Peiffer says, What we found in years of inquiries was that there were certain themes and frequent requests to our social media pages. Using Sprout, we built Saved Replies that centralized how to locate those resources for our audiences, but could still be individualized and customized to impart that humanity to our social media communications, which I think is so important in health care. In Sprout, were able to unlock this potential and allow our team to focus on more strategic objectives. This brings us to customer engagement and building your own brand community. One of the ways to nurture a thriving brand community is to respond to comments and messages promptly. Tools like Sprouts Smart Inbox or Message Alerts help you in doing that because they automatically categorize messages according to priority. Collaborate with brand advocates to extend your reach and infuse your social media with authentic, relatable content. Plus, encourage user participation through polls, QA and challenges. This will help you grow and sustain your brands community with loyal followers. Analyze and track your efforts consistently. This includes testing your ad creatives, captions and posting times to ensure they are optimized for your audience. Tools like Sprouts Suggestions by AI Assist and ViralPost  capabilities enable you to do just this. Analyze your content performance as well and use that data to refine your approach. With Sprouts Tagging feature, you can pull tag-based reports that make it easy to assess what makes something resonate with your audience and see how it aligns with your strategic priority area. You can see whats performing well and apply those data-backed learnings to other projects to build your annual campaigns. This approach has also helped Penn State Health win executive buy-in. The ability to customize how specifically we want to be able to sort, filter and measure data has allowed us to build really enhanced reporting that provides sometimes real-time feedback to stakeholders in ways we havent always been able to, Peiffer says. Its something that not only allows us to plan better as were laying out our campaigns and our social strategy for the year, but then also to go back and to report to others when they say, I dont understand why you did this, or I dont understand why we dont do something else. We have the data and the insights available to communicate effectively why our decisions are what they are and to support them as we go forward, she adds. Another important factor is to keep track of platform algorithm changes so you arent caught off-guard and adapt your strategy accordingly. This cohesive approach will also enable you to create benchmarks that you can lean on for future campaigns. If you set actionable goals and address each of the steps above, youll already be way ahead of the curve when it comes to your social media marketing strategy. Try out some of the Sprout Social features we shared in this article and explore how your business can advance with greater consistency and impact. Sign up for a 30-day trial today. Social media management tools are essential for streamlining and amplifying a social media marketing strategy. They automate repetitive tasks, provide critical data for informed decisions, and enable businesses to manage their presence across multiple platforms efficiently. Heres the role of social media tools in a marketing strategy: The success of social media marketing is measured by analyzing key performance indicators (KPIs) that align with your business objectives. By tracking the right metrics, you can understand your audience, optimize your content, and demonstrate a clear return on investment (ROI). Here are five key metrics to measure the success of your social media marketing efforts: 8 winning holiday marketing strategies for 2025 11 UK social media marketing conferences in 2025 Top 8 social media conferences for Australian marketers (2025) 20 engaging Instagram post ideas for UK businesses Australian TikTok video ideas that convert Everything you need to know about WhatsApp marketing How to maximize your social strategy with video SEO 25 social media post ideas for UK brands 2025 A Social Media Scorecard Template to Keep Your C-Suite Informed How to use social media memes in your marketing strategy to drive engagement Why social media shares matter in 2025 (10 engagement tips) Reddit marketing: How to reach and connect with your audiences Social media marketing: What it is and how to build your strategy The importance of social media marketing: 7 stats that prove socials role in business success Index Insights: How to Gain Executive Buy-In for Bolder Social Moves in 2025 7 steps to a successful social media video marketing strategy The complete guide to using social media for business The future of social media: 7 expert predictions for 2025 A guide to choosing the most effective social media networks for your brand Balancing Act: lululemons Secret to a Relatable  Aspirational Social Presence Navigating Social Media Management in an Election Year 16 digital marketing platforms to check out in 2025 Target audience: What it is and how to find yours How to build a customer-centric B2B social media strategy 8 social media myths to unlearn (and dispel across your organization) 8 social media tips from experienced marketers New Index Data: The Social Dream Team of the Future New Index Data: Refine Your Playbook for Social Sophistication The Rise and Fall Of New Platforms: What Threads Has Taught Us About Emerging Social Media The complete guide to Pinterest Marketing What to do when faced with these 10 social media marketing challenges A beginners guide to social media marketing tools How to Captivate your B2B Audience with Emotional Marketing The ultimate guide to Twitter for business Masterclass: How to Prepare Your Brand for a New Era in Social How to Build the Case for Social Media Investment in a Tight Economy Tumblr is back. What does that mean for marketers? How the Atlanta Hawks created a slam dunk social strategy using Sprout Social Sprout on Sprout: How to communicate social media marketing priorities to outside stakeholders Supercharge your Marketing Strategy with Social Webinar Timely, Trendy  Compelling: How to Level Up Your Marketing Strategy With Social Webinar 8 marketing campaign ideas that customers will engage with Prepare to Launch With a Social Media Campaign Brief: Template Social media campaign examples to inspire your social strategy To see marketing differently, we need to turn the spotlight on social How to nail your pitch for a social media marketing campaign Twitch marketing: What it is and how brands can do it right The social media marketers guide to infographic marketing How to build a social media marketing funnel that converts 9 Smart social media tactics you need today How Sprout Social helps the Chicago Bulls take its social media game to the next level How Stoneacre Motor Group achieved 1 million in sales using Sprout Social How Trek uses Sprout Social to support its social strategy around the globe How James Hardie learned more about its audience and optimized operations using Sprout Social How Keele University builds its brand and loyalty using Sprout Social Small Business Marketing 101: Using Email, Social, Video and More A painless guide to social media marketing for dentists Braxton Brewing Company Says Cheers to Branding Opportunities With Sprout Social Please Link Responsibly: Social Media Guidelines for Alcohol Marketing",8233
https://www.shopify.com/blog/ecommerce-seo-beginners-guide,The Industry Leading Ecommerce SEO Guide (2025) - Shopify,"Learn about keyword research, site structure, and on-page optimization in this guide to ecommerce SEO. Follow this simple advice for ranking your store. Start your online business today. For free. Getting more traffic is top of mind for any ecommerce business. But how do you attract visitors to your online store without spending big on ads and marketing? The answer: by knowing how to harness ecommerce SEO. Ecommerce search engine optimization (SEO) is the process of fine-tuning your website to meet search engine best practices, which includes updating your content to reflect what your customers are searching for. Benefits of SEO for store owners include increased visitors, brand awareness, and sales. But with constant search engine algorithm updates, knowing how to approach search optimization can be difficult. This guide covers the basics of ecommerce SEO, including how to research keywords, structure your site, and create content for product pages. Equipped with this guide, and this SEO checklist , youll be set up to rank your store and reap some SEO rewards. Ecommerce SEO is the process of increasing the visibility of an online store in search engine results pages ( SERPs ). Ecommerce websites use SEO as a strategy to generate more traffic, attracting visitors who input queries related to their products and brand. The tasks involved in ecommerce SEO marketing are varied. For example, creating optimized website content is one SEO task you might undertake. Your content could show up in relevant search results that catch the attention of new customers and guide them to purchase. For example, an ecommerce store like True Classic , which sells t-shirts, could improve its website SEO by optimizing collection and product pages. As you begin the process of optimizing your online store, the most essential ecommerce SEO tasks to prioritize include: Other important tasks include: speeding up page load time , crafting detailed product descriptions , and doing backlink outreach . After prioritizing these SEO activities, you can consider creating informational content to provide additional value and traffic sources. This informational content, like blog posts or help center articles, should target queries that a customer would likely ask before purchasing an item. True Classic, for example, devotes an entire page to their different fabric options in detail so that shoppers can explore and get to know the products more deeply. When you search for something on Google, youre taken to a search engine results page (SERP). There, youll find approximately 10 organic results : These organic results appear below paid ads (orange) and Google Shopping ads (purple): Ecommerce SEO is all about ensuring your product pages appear among the top organic search results on the first page of Google. Websites that dont rank within the top 10 are rarely visited, and even those in positions three to five receive far less traffic than the top results.  Worth noting: SEO company Backlinko found that only 0.63 of searchers click on websites listed on page two of Google search results. Backlinko also reported that the first result on a Google SERP gets 27.6 of all the clicks: In other words: SEO matters. The name of the game is to rank as high as possible on the first page of search engines like Google and Bingboth for search terms related to your products, as well as searches within your ecommerce niche market . If youre new to search engine optimization and want to increase your stores ranking on Google, take a look at these six steps. They provide actionable tips for setting up good, basic ecommerce SEO on your website. The first step in any ecommerce SEO strategy is to identify high-value search terms that your potential customers are using. You can do that through ecommerce keyword research , which can be conducted in a number of ways. Ecommerce keyword research is slightly different from traditional keyword research. While most sites care only about informational keywords, youll want to target a mix of informational and commercial keywords, like this: Informational keyword searchers are looking for answers, guides, and explanations. Blogs and content-heavy sites care most about these keywords. Many Shopify stores and other ecommerce sites have blogs too, but they also target keywords that show buying intent , like raincoats for dogs. When you start to type a search query into Google, its autocomplete feature suggests relevant queries: These autocomplete suggestions can be a gold mine for keyword ideas, especially when you already have a few basic keywords in mind. (Dont forget to check the related search queries at the bottom of the SERP, too.) You can complete a similar process on Amazon. The great thing about Amazon suggestions is that, unlike Google, theyre product-focused and can include filterable details such as price. Pay particular attention to long-tail keywords , which are longer and describe more specific items. The longer the keyword, the more specific it is. That means lower competition and, often, higher conversion rates. You can also check how Amazon (and other major ecommerce sites) structure content for visibility in search. Take a look at relevant product menus for keyword category ideas. Lets say you sell womens fashion items. If you find that category on Amazon, you can see all of the different ways Amazon sorts and organizes its products in that niche: Repeat this process for any other major competitors. For more advanced keyword research, youll need a free SEO tool . The most popular is Ahrefs . These tools provide the ability to research and analyze keywords en masse. Lets say you compete with BustedTees , a geeky t-shirt ecommerce store. Enter its domain into a keyword research tool like Ahrefs and click Organic keywords at the top: Scroll down to see all the keywords BustedTees currently ranks for. Youll also find metrics like search volume and rank position. With an overview of your competitors SERP coverage, you can make an informed decision about where to compete for keywords. No ecommerce website can target every keyword. Based on your customers and products, youll need to decide which keywords to try to rank for. Consider the following factors: Head term keywords are very broad and usually very competitive. On the other hand, long tail keywords are more specific and have less competition, with usually a higher likelihood for conversion because of their relevance. The higher a keywords search volume , the more potential traffic to your site. You can discover keyword search volume using Ahrefs or a free tool like Google Keyword Planner . The lower the competition, the more likely you are to rank for a keyword. SEO tools will show you keyword difficultycompetition (KD). How relevant is your product page or category page to the search term? This is a huge ranking factor thats often neglected. Stick to keywords that your products would genuinely satisfy. Youre not foolin Google (and you shouldnt try to trick your customers either). Target keywords that show an intent to buy or learn about a product. Usually, you can evaluate search intent just by looking at a keyword. For example, if you own a bridal shop, which search has the more relevant intent: ball gown wedding dresses or work dresses? Its also wise to look at what other sites are currently ranking for a search term; thatll help make sure your keyword usage has the same search intent. If you sell more than three of the same product type, target relevant keywords with a collection. If you sell fewer than three of the same product type, target keywords with each individual product page.  The ultimate keyword? A high volume, low competition term that aligns with the content on your website. Once youve done your keyword research and your site structure is ready to rock, its time to optimize the content on your two highest-value page types: If youre using Shopify, you likely know that Shopify stores include several SEO features. Some are automatic: But other features require you to manually optimize your site: When optimizing your title tags and descriptions, note that these are Google-facing. The primary goal is ranking on the first page. The secondary goal is convincing searchers to click through to your site. Modifiers like Deals, 20 Off, Free Shipping, Wide Selection, etc., can give you a boost when placed in the meta description (or title, if it fits) and help you tackle long-tail keywords. In ecommerce SEO, Google and other search engines use the content on your page to decide which keywords to rank your page for and how high your page should rank for each keyword. If a product page has a short description and not much else, Google doesnt have much to go on. Copying and pasting a description from a manufacturer or supplier is called duplicate content and is also advised against. Instead, write unique, comprehensive product descriptions that capture readers interest and contain lots of details about your items. Quality on-page content can help improve the ranking of your product pages and reduce overall thin content on your store. Thats why, in higher-ranking search results, youll typically see product pages with longer descriptions, reviews, and more. Try to include relevant keywords and subheadings in every section of your page to help Google understand what your content refers to. If you cant create content for every product, focus on those currently ranking on the bottom of the first page. Boosting these results can have the biggest impact on conversions, as they dont have as far to climb up in rankings. The more you write, the more accurate Google can be in ranking your page. Your customers wont hate the extra product info eitherit might even help persuade them to buy. Related keywords are exactly what they seem: Theyre similar to your main keyword. Enter your keyword into Google Keyword Planner to find related terms and phrases that you can pursue with your content. You can also find related keywords through an Amazon search. Look up your main keyword and check for secondary keywords that repeatedly appear. For example, lets say youre trying to sell a blender. The terms 14 Speed, 450W, and 48oz Glass Jar all appear multiple times, indicating theyre strong selling factors and likely common elements of search terms. If youre getting traffic from a main keyword, try to slide onto the first page for related secondary keywords as well. Use related keywords in your content whenever they make sense. The longer you can keep your visitors browsing your content, the more chance you have of making a sale. Relevant internal links to other pages on your site help potential customers browse and discover information or products. In your anchor text (the words that you place the internal link in), make sure you include the target keyword verbatim. Internal linking can be used to drive customers to relevant product pages, category pages, and educational content. Dont get too wild with internal linking. One or two links every few hundred words is enough.  Pro tip: If you understand your audiences decision-making process, you can develop content that helps them through the various stages in their buying journey . When it comes to SEO ecommerce, how the pages on your site are organized and structured affects your search engine rankings. Site structure also impacts your user experience (UX). You need to make it easy for visitors and search engines bots to navigate content in your store. As you add and remove products and categories, site structure can get complicated. Before you progress too far with developing your website, ensure: Simplicity is underrated. You dont want to have visitors relying on the back button to get around your site, running in circles trying to find what theyre looking for. You also dont want to have to reorganize and rearrange your site structure every time you add a new product category. Most of your SEO link authority is on your homepage, because thats the most common page other businesses link to when referring to your website. So, the more clicks away from your homepage a product page is, the less authority it has. As you implement SEO on your website, youll want to make strategic choices about which webpages you choose to index and rank. Index is another name for the database used by a search engine. So to index a page is to have it added to that database. In other words, Google has discovered your page and added it to its search results: For advice on page indexing, take a look at these tips from Aleyda Solis, founder of SEO consultancy Orainti : Aleyda recommends identifying which page types are worth indexing and optimizing. Those pages should fulfill a real audience demand. One of the most common issues for ecommerce sites is thin content, as well as content duplication, Aleyda says. Thin content is the idea that theres not much actual text on an ecommerce site compared to, say, a blog or software site. Content duplication occurs when the same content appears on multiple product and category pages. Adding blog content to your online stores website is a good way to help counter thin content. The easiest way to handle content duplication is to hide a page from search engines , known as noindex-ing. However, you can also create useful content for those pages to make them different, relevant, and competitive. You can also canonicalize pages. Canonicalizing a page is a way of telling Google that a URL is the master version youd like to display in search results. This is helpful in duplicate content situations, because without canonical tags, Google might:  Good to know: If youre using Shopify, auto-generated canonical tags are added to pages to prevent duplicate content from appearing in search results. Aleyda suggests going beyond noindex or canonicalization when youre ready. Assess if there are enough search queries around a products characteristics to identify whether to index its page, she says. If you do index a page, ask yourself if theres enough content on the page and if its aligned with the way the users are searching. You may need to expand and optimize the page to keep it relevant and competitive. Aleyda shared this handy chart to help visualize the indexing decision process: The big takeaway? Not every level of your site structure is worth indexing and optimizing, so be strategic and refer to the chart above.  Pro tip: Add breadcrumbs to your product pages to improve website navigation for customers and Google. Breadcrumbs tell Google how your site is structured and let people know where they are within your store. Notice how Allbirds uses breadcrumbs on its product pages to orient users. If someone decides they dont want to purchase the Everyday sneakers, they can easily click back to Mens Shoes or the homepage and look for a different product. Use a third-party app like Category Breadcrumbs to show your customers the path theyve navigated down through your category tree. Technical SEO is an under-the-hood type of search engine optimization. Its unseen by shoppers, but ensures your website is optimized for crawlers, has ideal site speed, and works on mobile. Strategic Technical SEO leads to: Some ways to improve your technical SEO for ecommerce include the following:  Hire a technical SEO expert to run a site audit and optimize your store from the Shopify Experts marketplace . Ensure that your product feed is correctly verified in the Google Merchant Center so that your products appear in Google Shopping free listings and ads. This verification process confirms that your product data like titles, descriptions, prices, and availability is submitted accurately and meets Google's requirements. Heres how to get your products listed in Google Shopping feeds : A verified and accurate feed ensures that your products are discoverable by potential customers, enhances your visibility in search results, and contributes to a seamless shopping experience. Next, consider publishing relevant informational content that supports purchasing decisions or otherwise speaks to shoppers in the market for what you sell. This could be help center articles that cover common customer pre-purchase questions, About Us content that shares what makes your brand unique, or blog posts that target specific keywords that align with your audiences interests and needs. Youre using SEO to power an ongoing content strategy . When it comes to blogging, every post published has the potential to: Imagine you were starting a company that sells running gear . You want to help potential customers understand your products, use them more effectively, and solve their running and fitness problems. If you want to get found in search engines like Google, blogging can help you get there. A well-written blog gives your store a steady stream of original content. The more people who discover your content, the more reliable youll become as a source of information. This, in turn, helps you rank higher. Ecommerce businesses often struggle with blogging because it takes time, effort, and resources to get it right. Randomly publishing blog posts each month wont bring traffic to your website. However, there are many ecommerce businesses that do blogging well. For example, retailer Au Lit Fine Linens sells everything to help you get a good nights sleep, including luxury sheets, pillows, bath linens, and more. The brand also has a blog, Between the Sheets , that regularly provides helpful articles about how readers can improve sleep quality. The blog is SEO driven, meaning that its purpose is to rank in search engines. Posts often highlight a problem the reader is having, and offer Au Lit Fine Linens products as the solutiona fine balance between promotional and informational. When starting a blog for ecommerce SEO, focus on the following three elements: One of the oldest components of the Google algorithm is PageRank. Its a system that seeks to understand webpage quality by looking at how many links it receives from other websites. Google uses the number, quality, and relevancy of a pages links to judge its trustworthiness. As a result, new websites with few links have less authority in the eyes of search engines. While time can fix this, building quality backlinks can help Google recognize your authority more quickly. Respected TLDs , like .com, .gov, and .edu, tend to provide the most authority when they give you a backlink. Links from large, well-ranking websites operating within your niche are particularly lucrative. One of the best ways to approach building links is to focus on partnerships. Determine what content you can create that will provide value to other websites. If you can make something that others want to use, theyll usually cite your content with a link. Guest posting can be a functional way to build backlinks, provided the content you create for other websites is relevant to their users. Run some ecommerce keyword research and analyze backlinks with Ahrefs to find sites in your niche that are receptive to guest posts. Another way to build backlinks to your ecommerce store is through press mentions. Building a press list or hiring a PR firm can be expensive, so here is a simple growth hack anyone can do. Sign up for Help a B2B Writer and you will get a daily digest of reporter requests right to your email. When a lead matches your brand, reach out to the email address provided and pitch a story. If you get an interview, make sure to ask for a backlink to your website. If you own a website, youre going to use Google Analytics . This free SEO tool tracks and reports website traffic, giving you the insight to better understand customers, optimize your store for SEO, and improve marketing ROI . As a Shopify store owner, you can connect Google Analytics to Shopify Analytics and choose specific ecommerce data to track. Youve seen Ahrefs at work in this post, but its worth looking deeper at some of its key features. Ecommerce marketing professionals use Ahrefs to create SEO campaigns and rank higher in Google. Ahrefs is a competitor of Moz and Semrush, two other SEO software companies youll find when researching SEO tools. Use Ahrefs to analyze a websites link profile, keyword rank, and overall SEO performance. You can also use it to conduct keyword research for Google, Amazon, and YouTube. Avada SEO is a plug-in to help ecommerce stores outrank competitors. It offers image compression, site speed optimization, schema markup, and other technical features that keep your website optimized for search. It also has 247 customer support. SEOAnt is a free tool you can use to run SEO checkup reports, fix broken links, and optimize image sizes. It also has AI features for writing meta and alt text. Rankings are never static, so ecommerce SEO never stops. But the seven steps in this article should help you build a solid SEO foundation for your online store. Remember to keep your content original and in-depth, regularly audit your site for technical issues, explore backlinking opportunities, and always look out for new keywords that match your brand and products. Ecommerce SEO is the process of making changes to an online store to increase the visibility of its web pages and product listings in search engine results pages (SERPs). SEO is a powerful tool for ecommerce businesses. It helps to increase organic traffic to your site, which can lead to higher visibility, more potential customers, and ultimately, increased sales. Additionally, SEO is a cost-effective marketing strategy as it targets users who are already looking for your products online. The same principles apply to SEO and ecommerce SEO. However, ecommerce SEO strategies are tailored for online stores. The main goal of ecommerce SEO is to increase the visibility of products in search engine results to drive sales, while traditional SEO focuses on improving website content visibility to capture readers and attention. Tasks specific to ecommerce SEO include optimizing product pages and listings. The cost of doing SEO varies depending on the size of your website and the scope of your SEO goals. However, many aspects of SEO can be done at no cost. Tasks like keyword research, on-page optimization, and content creation are all essentially free, besides the time you invest. If you choose to hire an SEO professional or agency, costs will differ based on their expertise, the size of your website, and the extent of services required. Most businesses budget 1,5005,000 per month for intensive outsourced SEO projects. Shopify stores have SEO features to help you optimize your content. For example, you can create optimized product titles, descriptions, alt text, and URLs. You can also harness the power of Shopify Magic to AI-generate optimized descriptions of your products. Other SEO features include the ability to submit your sitemap to Google Search Console and create a blog for your online store. Adding a blog to a Shopify store can help it rank for relevant keywords that dont compete with product pages. For example, a Shopify store selling birthday party supplies may rank for product-focused keywords such as balloons, streamers, and gifts. Adding some thoughtful blog posts to this website may enable it to appear in other queries from motivated users, such as how to plan a birthday party. Its important to consider SEO for your Shopify store because it helps increase visibility in search engine result pages (SERPs). When you optimize a Shopify store for users (by creating pages that address queries and acquiring backlinks from relevant websites) it will rank higher in results. The more pages you do this for, the more pages start ranking. Getting website traffic from organic search results helps you attract customers and spend less on paid marketing. The newsletter for entrepreneurs Join millions of self-starters in getting business resources, tips, and inspiring stories in your inbox. Unsubscribe anytime. By entering your email, you agree to receive marketing emails from Shopify. By proceeding, you agree to the Terms and Conditions and Privacy Policy . popular posts popular posts",3982
https://www.woot.com/,Woot,"Don't work to find deals. Let the deals find you. Log in and get deals straight to your inbox. Get deals straight to your inbox. Nah, maybe later x",29
https://www.shopmissa.com/?srsltid=AfmBOoqr-F6zzKR-vGPqksAZp1wW4niXlINdN2eAREiMVNtHez_0-gAB,"The Original $1 Dollar Makeup, Cosmetics and Beauty Online Shop  Shop Miss A",4.6  5.0 4.85  5.0 5.0  5.0 5.0  5.0 4.2  5.0 4.75  5.0 4.75  5.0 4.59  5.0 4.59  5.0 4.71  5.0 4.21  5.0 4.64  5.0 4.53  5.0 4.73  5.0 4.34  5.0 4.66  5.0 4.79  5.0 4.12  5.0 4.71  5.0 And optional subtext 4.61  5.0 4.42  5.0 4.08  5.0 4.38  5.0 4.67  5.0 4.48  5.0 4.47  5.0 4.76  5.0 3.71  5.0 3.84  5.0 4.23  5.0 3.79  5.0 4.44  5.0 3.93  5.0 3.92  5.0 4.57  5.0 5.0  5.0 And optional subtext 5.0  5.0 5.0  5.0 4.5  5.0 5.0  5.0 5.0  5.0 5.0  5.0 And optional subtext 4.19  5.0 4.44  5.0 4.86  5.0 4.9  5.0 4.69  5.0 4.52  5.0 4.66  5.0 4.74  5.0 4.59  5.0 4.76  5.0 4.46  5.0 4.29  5.0 4.63  5.0 4.91  5.0 4.45  5.0 4.83  5.0 4.35  5.0 4.5  5.0 4.67  5.0 4.59  5.0 4.51  5.0 3.65  5.0 4.69  5.0 3.64  5.0 4.63  5.0 4.69  5.0 4.52  5.0 4.34  5.0 4.29  5.0 4.6  5.0,153
https://martie.com/?srsltid=AfmBOoqTEC0QXQ3xYEvV1VWP6OX6EZboYFZDuiiilhyLfDJNbuXIZ97r,Martie.com | Save up to 80% on your favorite brands!,FREE SHIPPING on all orders 50 Try our lightning-fast shopping experience  no download required.,14
https://www.dealsofamerica.com/,"Deals, Coupon Codes, Bargains & US Deals - Deals of America","Latest Deals -November 2, 2025 252 Posted so far today. DealsOfAmerica.com is one of the most frequently updated sites on the web. The site is updated multiple times every hour -from early morning to late evening. Do visit often throughout the day to take advantage of hundreds of online deals posted daily! - View Desktop Version Contains one (1) 20.1-ounce jumbo bag of KIT KAT Milk Chocolate Wafer Snack Size Candy Bars Fill snack ..... View More info SO SOFT - Midweight pique fabric feels super-soft up against your skin. KEEPS YOU COMFORTABLE - X-Temp technology ..... View More info The easy-to-use chug style spout delivers a smooth and continuous flow of hydration, while handle incorporates a easy ..... View More info AMYET S8 Adults Electric Bike For Men 2000W Dual Motor Bicycle 48V 25AH Battery 20"" Ebike Electric E ..... View More info The Breville Barista Express delivers third wave specialty coffee at home using the 4 keys formula and is ..... View More info Emergency-ready, multifunction EDC featuring a carabiner clip, cord cutter, screwdriver tip, hex wrench and carbide glass-breaker tip. Partially ..... View More info Newly added snappy and responsive Air Zoom unit A heart on the inside of the tongue was drawn ..... View More info S PETG or PLA filament 3D Printer Filament 10 Rolls 1KG 1.75MM Eco-Friendly Good Toughness Mix Color..... View More info AMYET has been focusing on the development and innovation of low carbon and green electric bike, with a ..... View More info Contains one 18.47-ounce bag of MILKY WAY Spooky Fun Size Chocolate Halloween Candy. Made with caramel, creamy nougat ..... View More info 27-inch QHD (2560 x 1440) HDR gaming monitor with ultrafast 180Hz refresh rate designed for professional gamers and ..... View More info ARIMA KANA from the anime ""Oshi no Ko"" joins the adorable figure line Adokenette that focuses on the ..... View More info Experience supreme coziness with our pad, made with soft blend of polyester and cotton. The underside, crafted from ..... View More info This unlined linen curtain panel is considered as Room Darkening, these drapes blocks upto 80-85 of the light. ..... View More info Transform your existing circular saw into a precision cutting powerhouse, delivering track saw-like accuracy for perfectly straight cuts ..... View More info Watch your kids have fun riding around indoors and outside in the 6 volt battery powered Sonic Bumper ..... View More info Presenter mode, built-in Class 1 red laser pointer for presentations, intuitive touch-keys for easy slideshow control. AAA batteries ..... View More info Epic Home Viewing: Up to 4K HDR with Dolby Vision delivers captivating, true-to-life detail. Connect speakers that support ..... View More info Electric spin scrubber adopts a tight protection design. It can be used in a humid environment or washed ..... View More info The LG 24BR400-B 24"" IPS FHD Monitor features a 24"" Full HD IPS display that delivers true color ..... View More info Durable knit fabric with a smooth face  a soft inner to trap warmthMaterial wicks sweat  dries ..... View More info Made of brand new extra-thick PCABS materials for hardshell, which make the luggage more durable, lighter and impact-resistant. ..... View More info Electrician's Pliers Hand Tool Set includes: long-nose, straight jaw, diagonal cutting pliers, High Leverage Lineman's Pliers with Crimper ..... View More info 9 Cooking Functions: Pressure cook, slow cook, saut, sous vide, steralize, keep warm, make rice, yogurt and eggsall ..... View More info Kirkland Signature Hair Regrowth Treatment Extra Strength for Men, 5 Minoxidil Topical Solution, 2 fl oz, 6-pack..... View More info Special designed for removing fuzz, pills, and lint from sweaters, blankets, curtains, carpets, furniture, couch, and more; compact ..... View More info This revolutionary 3-in-1 charging station for apple devices is designed specifically for the Apple user. Why juggle cables ..... View More info 12-Core Intel Core Ultra 7 255U Processor With Intel Ai Boost NPU  1 TB PCIe Gen4 NVMe ..... View More info Large Capacity: Holds up to 42 (12-oz) cans, perfect for outdoor activities and sports events. Optimal Storage: Stack ..... View More info The translation headset supports 32 languages. It can be translated as soon as it is worn. When the ..... View More info 49PCS Wooden Marble Run Music Tree Toys: Our upgraded musical tree set includes: 30pcs multicolored leaves(with 6 kinds ..... View More info Travel backpack with ample space to accommodate most 17-inch laptops alongside dedicated pockets for tablets, phones, sunglasses, and ..... View More info A COMPLETE SET INCLUDES: One 6-quart aluminum Dutch oven with gold-tone handle and glass lid NOURISH IS OUR ..... View More info PEST CONTROL ENGINEERED TO WORK- The Solar Jet Sprayer Device Provides Dependable 247 Defense Against Deer, Rabbits, Foxes, ..... View More info This unique kitchen workhorse, the Cuisinart Air Fryer Toaster Oven, is a premium full-size toaster oven with a ..... View More info The mobile robot comes with a Full HD 1080P dog camera that can check the status of your ..... View More info Barbie Extra Fly dolls travel in style, rocking bold fashions for different travel destinations! Each posable 5.5-inch Barbie ..... View More info This glass cutting board has four rubber feet on the bottom that prevent it from sliding on the ..... View More info Introducing the Suspension-NXT: the modern take on a classic multi-tool. This enhanced version of the original offers 15 ..... View More info Effortlessly move planters for indoor plants and planters for outdoor plants to catch the rain or sunlight; Our ..... View More info Lysol Toilet Bowl Cleaner is a bathroom essential tested and proven to kill 99.9 of household bacteria and ..... View More info Both ends of wrench include box end ratchet head and Open head with steel stamped size mark 932"" ..... View More info Show Your Colors On Game Day With The Economy Canopy Tailgate Tent. When Set Up It, Measures 9 ..... View More info Klein Tools' retractable utility knife is made of lightweight aluminum and designed to comfortably fit in your hand ..... View More info Included - One (1) 64 fl oz bottle of Ocean Spray Ruby Red Grapefruit Juice Drink From-the-Grove Goodness ..... View More info The audio Amplifier Splits sound from many different sources into one listening location for monitoring or routing. Each ..... View More info At under 9 lbs., the powerful, ultra-lightweight Shark Rocket (HV301) corded stick vacuum handles all floor types and ..... View More info This 100 Colombian Decaf is bold and flavorful with tasting notes of dark chocolate and walnut. A decaffeinated ..... View More info A beautiful lifelike plant perfect to accent any room or space for year-round greenery. A simple, yet elegant ..... View More info Start off every day with a perfectly brewed beverage and a smile. Whether you're feeling like a fresh ..... View More info The soft touch of chenille bathroom rugs helps soothe your feet and keep your toes warm from cold ..... View More info Animal toy for kids  Let imaginations soar with the LEGO DREAMZzz The Never Witch's Midnight Raven fantasy ..... View More info The Milwaukee 17-Piece Folding Hex Key Set - SAE  Metric features the easiest access keys on the ..... View More info Sacrificing communication in an emergency is not an option, and with frequent natural disasters, its essential to have ..... View More info Transparent view: Transparent design allows you to find the items you need at a glance, colored ones are ..... View More info JTSIOV artificial Christmas garlands with 200 green branches, 9ft Christmas lights with 30 LEDs, 8 pine cones, 12 ..... View More info Assorted color gel pens designed to deliver superior smoothness, drying speed, and line intensity to make your writing ..... View More info Safety firstthis walking pad with handle bar (a treadmill with handles) keeps you steady for walks, jogs, or ..... View More info Fabric: Made of slightly stretchy material. This is a bodycon dress, size up if necessary refers to the ..... View More info This led work light is made of hard rubber, anti-sweat and anti-slip, the head is aluminum which dissipates ..... View More info Why stick to just one language, With Rosetta Stone: Unlimited Languages, you'll receive access to all 25 plus ..... View More info eero 6 3-pack covers up to 4,500 sq ft. with wifi and supports wifi speeds up to 900 ..... View More info DELICIOUS MIXED FRUIT: The fruit cocktail is immersed in a tasty syrup, enhancing the natural taste of sweet ..... View More info Bosch GLL50-20 Self-Leveling Cross-Line Laser features a 50 ft. range and cross-line mode that projects both horizontal and ..... View More info The GEMBED Foldable Sofa Bed is a true space-saving marvel, effortlessly transforming from a cozy sofa to a ..... View More info This mini electric chainsawa powerful option among chainsawsis powered by a pure copper motor and equipped with a ..... View More info This portable air compressor quickly inflates a 19555 R15 car tire from 25 to 35 PSI within 2 ..... View More info The Childrens Place offers a huge selection of kid's clothing! Shop us for jeans, shorts, leggings, chinos, polo ..... View More info Mens golf shirt is made of high-end polyester spandex material, which is soft, skin-friendly, lightweight and breathable. Also ..... View More info Experience stunning colors across the entire display with the IPS panel. Colors remain bright and clear across the ..... View More info Live green plants need to be taken good care of everyday but still wither quickly? Try this! No ..... View More info E2PRO front and rear dashcam simultaneously capture 1440P 2k front facing videos and 1080P rear facing videos. Dual ..... View More info The TV stand adopts pop-up doors instead of handles, so that it looks very neat. And there are ..... View More info Give your living room some rustic style with our industrial inspired coffee table. Black painted metal accents are ..... View More info Ball storage garage combines with 2 big storage bins, 2 wire mesh basket and 2 tier ball rack ..... View More info EFFORTLESS SLIP-ON DESIGN: These mens slip on shoes feature an easy step-in design with bungee closure for a ..... View More info Vanity Desk measures 15.74''D x 43.3''W x 54.12''H, providing a space-efficient and compact solution for your beauty and ..... View More info The Juniper AP63 is a ruggedized and weather-resistant outdoor Wi-Fi 6 (802.11ax) access point that delivers fast and ..... View More info INCLUDES: 8 Inch Frying Pan  10 Inch Frying Pan  11 Inch Grill Pan  1.5 Quart ..... View More info Contains six (6) Boxes of 10 Peet's Luminosa Breakfast Blend Coffee Keurig K-Cup Pods (60 K-Cup Pods Total) ..... View More info This cordless leaf blower weighs only 3 lbs (1.36 kg), making it one of the lightest models on ..... View More info Steaming your clothes is a breeze with the Sunbeam 1200W Steam Burst Handheld Steamer with bristle brush attachment ..... View More info This adidas backpack lets you take your day in stride, whether you're headed to class or exploring the ..... View More info Waterlily, ginger, and hinoki mix together to create the can't-miss cool ambience of Ocean Rethink your air freshener ..... View More info Crafted with premium materials that surpass CA PROP 65 safety standards, our products offer peace of mind with ..... View More info For More Today's Live Hot Deals Please Visit Next Page Accessibility Statement - Do Not Sell My Personal Information  2003-2025 Ziff Davis, LLC, a Ziff Davis company. All Rights Reserved. Deals of America is a federally registered trademark of Ziff Davis and may not be used by third parties without explicit permission. The display of third-party trademarks and trade names on this site does not necessarily indicate any affiliate or endorsement of DealsOfAmerica.com.",1987
https://www.dealnews.com/,"DealNews: Best Daily Deals, Discounts & Sales","Bag nice savings on several handy household items. We've pictured this Gorilla Grip Ultra Water Absorbent Microfiber 18x24"" Dish Drying Mat for 8.99 (half off.) Shop Now at Amazon This is a great option for stocking up the freezer and saving at the same time. We've pictured this Marie Callender's Meat Loaf  Gravy 12.4 oz. Frozen Meal for 3.48. Buy Now at Amazon Save on all sorts of electronics in the outlet overstock section at Amazon. You will find deals on video game accessories, keyboards, cables, and much more. We've pictured the Recessed Power Strip w USB, Flat Plug for 9.99 (half off.) Shop Now at Amazon This is a really strong sale. There are monitors for all budgets, with several all-time low prices to be found; including the pictured Samsung Odyssey G93SC Series 49"" FreeSync OLED Curved Monitor for 869.99 - which is by far the best we've seen (it's 1,000 on Amazon right now.) Buy Now at Woot! An Amazon Company Get Winter-ready with this discounted selection of cozy slippers, waterproof boots and more. Sizes are limited on most styles, but the good deals are worth searching around for. Shop Now at Woot! An Amazon Company That's just 5 each and the best deal Amazon has ever offered on it. Buy Now at Amazon These are at a 90 discount. Buy Now at Woot! An Amazon Company This already-cheap pen multitool will drop by another 50 at checkout, putting it at its lowest-ever price. Buy Now at Amazon We've found this for as much as 45 at some other stores. Buy Now at Amazon You'd normally pay 14.95 for Audible Premium Plus each month, but you can sign up today and get your first three months for just 99 cents. You can cancel the membership at anytime, but it will renew at 14.95 per month after the promotion ends if you don't cancel in time. Shop Now at Amazon Save on foot massagers, supports, hearing aids, fitness trackers, and more. We've pictured this Zewa Fitness Activity Tracker for 8.99 (2 off.) Shop Now at Woot! An Amazon Company As part of today's daily deals, shop this discounted selection. We've pictured this Huluwat 6-Tier 82"" Steel Heavy Duty Adjustable Garage Storage Shelving Unit for 200 (85 off.) Shop Now at Home Depot It's the best price we could find by 6. Buy Now at Amazon That's better than half off and a really nice deal on a 400CFM blower with battery and charger. Buy Now at Amazon All of these radio multipacks at strong lows. The pictured Motorola T478 Talkabout Rechargeable 2-Way Radio 2-Pack for 51.99 is almost twice as much on Amazon right now. Shop Now at Woot! An Amazon Company That's at a 71 savings right now, and the best deal Amazon has ever offered on it. Most sizes in the pictured Olive Green Stripe are at this price, but some of the other styles bag this low price too. Buy Now at Amazon As part of today's daily deals, shop this discounted selection. We've pictured this DeWalt 14"", 38 "" and 12"" Drive Polished Chrome Mechanics Tool Set for 133 (typically 170 elsewhere.) Shop Now at Home Depot As part of today's daily deals, shop this discounted selection. We've picked out theGroundSmart 75-cu. ft. Black Rubber Nuggets Bulk Pack for 589 (200 Off.) Shop Now at Lowe's Use promo code ""OFF15"" to drop the price. That's a total savings of 12 off. Buy Now at adidas lululemon has updated their We Made Too Much Section with new specials on accessories, activewear, and casual wear. Plus, all orders get free shipping. Shop Now at lululemon Use promo code ""OFF15"" to drop the price to the lowest we've ever seen on this style. Buy Now at adidas That's a per-pair price of less than 1.50 - which is the best we've ever seen. Buy Now at Amazon As part of today's daily deals, shop this discounted selection. We've pictured this Anker 2,112Wh SOLIX C1000X Portable Power Station w 2 Solar Panels  extra battery for 1,299 (1,397 off.) Shop Now at Lowe's Apply coupon code ""E98FI3MS"" for a savings of 35, and tied as the best deal we've seen on it. Buy Now at Amazon Get deals on almost 3,000 clearance college sweatshirts and hoodies in this sale. Shipping is free on orders of 29 or more via coupon code ""29SSHIP"". Buy Now at Fanatics That's easily the best price we've ever seen, and 50 less than you'd pay on Amazon today. Buy Now at Woot! An Amazon Company This kit is more than double on Amazon today. Buy Now at Woot! An Amazon Company There's lots of other K-Pop gear here too, including in some kids sizes. Buy Now at Woot! An Amazon Company It's already 50 off, and code ""OFF15"" takes more off, for the best price we've seen, and in the most popular color too. adidas adiClub members get free shipping. (It's free to join.) Buy Now at adidas Get a one year Costco Gold Star membership at Groupon and you'll receive a 40 digital Costco Shop Card delivered to your email inbox. That's the second best Costco shop card offer we've seen with a membership sign up. This offer is valid only for new members and those whose previous memberships have been expired for at least 18 months or more. The Costco Gold Star Membership includes two cards and everyday discounts online and in warehouse. This offer ends December 21, 2025. Buy Now at Groupon As one of today's daily deals, bag this build at an all-time best price. Buy Now at Best Buy Apply coupon code ""92PFTMG5"" for a savings of at least 15. Buy Now at Amazon That's a really good deal on a 35-piece kit with a hardshell case. Buy Now at Amazon Both of these are nice lows. We've pictured the Rosetta Stone 25-Language Lifetime Digital Subscription for 134.99 (best you'll find anywhere today; most charge around 190.) Shop Now at Woot! An Amazon Company Use promo code ""OFF15"" to drop the price, it's typically around 16 elsewhere. Buy Now at adidas Apply coupon code ""3SZ7BKH6"" for a savings of 2. The 8.99 options drop to 6.29 with the same coupon code. Buy Now at Amazon Apply coupon code ""7KZ6IMJN"" for a savings of 13. Buy Now at Amazon Apply coupon code ""VCLZKK4A"" for a savings of at least 10. Buy Now at Amazon It's already 60 off, and code ""OFF15"" takes another 2 off, for the best price we've seen. adidas adiClub members get free shipping. (It's free to join.) Buy Now at adidas New Costco Executive Member sign ups will receive a 60 digital Costco Shop Card delivered to their email when they sign up on Groupon. Executive members get all the benefits of Gold Star, plus even more value. They earn an annual 2 reward (up to 1,250) on qualified Costco and Costco Travel purchases, along with extra savings on select Costco services. Offer ends December 21, 2025. Buy Now at Groupon Apply coupon code ""Z4MJX27C"" for a savings of 3. Buy Now at Amazon Apply coupon code ""LUVWOEHH"" for a savings of at least 3. It's available in several colors and quantities, depending on your travel needs. Buy Now at Amazon Apply coupon code ""9LWXCOMG"" for a savings of at least 5 on these packs of storage bags. Buy Now at Amazon Apply coupon code ""DMG9ESGA"" for a savings of 9. Buy Now at Amazon Apply coupon code ""SPU5DDPZ"" for a savings of at least 4. They're available in packs of 141 or 300, depending on how much furniture you need to protect your floors from. Buy Now at Amazon As part of today's daily deals, shop this discounted selection. We've pictured this NewAge Products Bold Series 132"" 24-Gauge Steel Garage Cabinet Set for 1,749.99 (740 off.) Shop Now at Home Depot Apply coupon code ""ALNMUXS9"" for a savings of at least 13. Buy Now at Amazon That's at a 75 discount right now. It's at least double at other stores today. Buy Now at Woot! An Amazon Company Apply coupon code ""YEBG3YP2"" for a savings of at least 6. Buy Now at Amazon New Uber Eats customers can apply the promo code ""affeats10us115"" to save 10 on your first order of 20 or more throughout November 2025. Note that some exclusions may apply and this code has a limited number of uses, so use it sooner rathern than later. The code is valid from November 1, 2025 through November 30, 2025. Buy Now at Uber Eats Get the latest deals delivered straight to your inbox",1439
https://viewyourdeal.com/,View Your Deal,Deals are valid only in the United States. Shipping policies and shipping rates are determined by each company and are listed at the time of purchase. Shipping beyond the U.S. is at the discretion of each company. Check each deal or inquire if interested in international shipment. This Shopify powered web store is operated under different terms and privacy policy than ABC.com. By taking advantage of these deals ABC receives promotional and financial consideration.,74
https://americasstealsanddeals.com/,Americas Steals & Deals | Online Steals & Deals Today,"Ships by Ships by Be the first to know when this product is back in stock! Ships by Ships by Be the first to know when this product is back in stock! Ships by Ships by Be the first to know when this product is back in stock! Ships by Ships by Be the first to know when this product is back in stock! We love partnering with brands in all locations, of all sizes and categories!",77
https://www.pricegrabber.com/,Check online store ratings and save money with deals at PriceGrabber.com,"Whoops! Please type a valid email address. Shop and Save on Millions of Products. See HUGE discounts and GREAT deals on the HOTTEST new items of the season! The best hand-selected deals on the web delivered right to your inbox. Be in touch with the PriceGrabber Newsletter Be in touch with the PriceGrabber Newsletter PriceGrabber Support Legal Sites Copyright 2017 PriceGrabber.com, Inc. All Rights Reserved",65
https://www.wikihow.com/Make-Money-Online,4 Ways to Make Money Online - wikiHow,"Last Updated: June 5, 2025 Approved This article was co-authored by Michael R. Lewis . Michael R. Lewis is a retired corporate executive, entrepreneur, and investment advisor in Texas. He has over 40 years of experience in business and finance, including as a Vice President for Blue Cross Blue Shield of Texas. He has a BBA in Industrial Management from the University of Texas at Austin. There are 11 references cited in this article, which can be found at the bottom of the page. wikiHow marks an article as reader-approved once it receives enough positive feedback. This article has 37 testimonials from our readers, earning it our reader-approved status. This article has been viewed 8,648,325 times. Nowadays there are lots of opportunities to earn money online. Whether youre looking to make money online full-time or you just want to supplement your income, you have a variety of options to choose from. This wikiHow will show you a few easy ways that can get you some money quickly. One of the easiest ways to make money online is to register for paid survey websites where you can earn money for taking surveys. You can also search online for website testing jobs and get paid to record yourself testing websites. If you want something that pays better, become an online tutor or start an online freelance writing business. For more tips from our Entrepreneur co-author, like what kind of items you can sell online to make money, keep reading! ALEXANDER KIBARA Sep 4, 2019 ALEXANDER KIBARA Sep 4, 2019 Anonymous Sep 12 IMIHIRI V. Jun 24 Anonymous Nov 21, 2017 Abid Solangi May 5, 2017",273
https://en.wikipedia.org/wiki/Search_engine_optimization,Search engine optimization - Wikipedia," Search engine optimization ( SEO ) is the process of improving the quality and quantity of website traffic to a website or a web page from search engines .  1   2  SEO targets unpaid search traffic (usually referred to as "" organic "" results) rather than direct traffic, referral traffic, social media traffic, or paid traffic . Organic search engine traffic originates from a variety of searches, including image search , video search , academic search ,  3  news search, industry-specific vertical search engines, and large language models. As an Internet marketing strategy, SEO considers how search engines work, the algorithms that dictate search engine results, what people search for, the actual search queries or keywords typed into search engines, and which search engines are preferred by a target audience. SEO helps websites attract more visitors from a search engine and rank higher within a search engine results page (SERP), aiming to either convert the visitors or build brand awareness.  4  Webmasters and content providers began optimizing websites for search engines in the mid-1990s as the first search engines were cataloging the early Web . Search engine users would query the URL of a page, and then receive information found on the page, if it existed in the search engine's index . ALIWEB and the earliest versions of search engines required website developers to manually upload website index files in order to be searchable and widely did not utilize any form of ranking algorithm for user queries.  5  The emergence of automated web crawlers would later be used to proactively discover and index websites. This led to website developers to optimize their websites search signals, including the use of meta tags , to achieve greater visibility in search results. According to a 2004 article by former industry analyst and current Google employee Danny Sullivan , the phrase ""search engine optimization"" came into use in 1997. Sullivan credits SEO practitioner Bruce Clay as one of the first people to popularize the term.  6  In some cases, early search algorithms weighted particular HTML attributes in ways that could be leveraged by web content providers to manipulate their search rankings.  7  As early as 1997, search engine providers began adjusting their algorithms to prevent these actions.  8  Eventually, search engines would incorporate more meaningful measures of page purpose, including the more recent development of semantic search.  9  Some search engines frequently sponsor SEO conferences, webchats, and seminars. Major search engines provide information and guidelines to help with website optimization.  10   11  Google has a Sitemaps program to help webmasters learn if Google is having any problems indexing their website and also provides data on Google traffic to the website.  12  Bing Webmaster Tools provides a way for webmasters to submit a sitemap and web feeds, allows users to determine the ""crawl rate"", and track the web pages index status. In 2015, it was reported that Google was developing and promoting mobile search as a key feature within future products, resulting in brands and marketers shifting toward mobile-first experiences.  13  In the 2020s, the rise of generative AI tools such as ChatGPT , Claude, Perplexity, and Gemini gave rise to discussion around a concept variously referred to as generative engine optimization , answer engine optimization or artificial intelligence optimization . This approach focuses on optimizing content for inclusion in AI-generated answers provided by large language models (LLMs). This shift has led digital marketers to discuss content formats, authority signals, and how structured data is presented to make content more ""promptable"".  14  It has also been argued that each of these tactics should be considered as subsets of ""search experience optimization,"" described by Ahrefs as ""optimizing a brands presence for non-linear search journeys over multiple platforms, not just Google.""  15  In 1998, two graduate students at Stanford University , Larry Page and Sergey Brin , developed ""Backrub"", a search engine that relied on a mathematical algorithm to rate the prominence of web pages. The number calculated by the algorithm, PageRank , is a function of the quantity and strength of inbound links .  16  PageRank estimates the likelihood that a given page will be reached by a web user who randomly surfs the web and follows links from one page to another. In effect, this means that some links are stronger than others, as a higher PageRank page is more likely to be reached by the random web surfer. Page and Brin founded Google in 1998.  17  Google attracted a loyal following among the growing number of Internet users, who liked its simple design.  18  Off-page factors (such as PageRank and hyperlink analysis) were considered as well as on-page factors (such as keyword frequency, meta tags , headings, links and site structure) to enable Google to avoid the kind of manipulation seen in search engines that only considered on-page factors for their rankings. Although PageRank was more difficult to game , webmasters had already developed link-building tools and schemes to influence the Inktomi search engine, and these methods proved similarly applicable to gaming PageRank. Many sites focus on exchanging, buying, and selling links, often on a massive scale. Some of these schemes involved the creation of thousands of sites for the sole purpose of link spamming .  19  By 2004, search engines had incorporated a wide range of undisclosed factors in their ranking algorithms to reduce the impact of link manipulation.  20  The leading search engines, Google, Bing , and Yahoo , do not disclose the algorithms they use to rank pages. Some SEO practitioners have studied different approaches to search engine optimization and have shared their personal opinions.  21  Patents related to search engines can provide information to better understand search engines.  22  In 2005, Google began personalizing search results for each user. Depending on their history of previous searches, Google crafted results for logged in users.  23  In 2007, Google announced a campaign against paid links that transfer PageRank.  24  On June 15, 2009, Google disclosed that they had taken measures to mitigate the effects of PageRank sculpting by use of the nofollow attribute on links. Matt Cutts , a well-known software engineer at Google, announced that Google Bot would no longer treat any no follow links, in the same way, to prevent SEO service providers from using nofollow for PageRank sculpting.  25  As a result of this change, the usage of nofollow led to evaporation of PageRank. In order to avoid the above, SEO engineers developed alternative techniques that replace nofollowed tags with obfuscated JavaScript and thus permit PageRank sculpting. Additionally, several solutions have been suggested that include the usage of iframes , Flash , and JavaScript.  26  In December 2009, Google announced it would be using the web search history of all its users in order to populate search results.  27  On June 8, 2010 a new web indexing system called Google Caffeine was announced. Designed to allow users to find news results, forum posts, and other content much sooner after publishing than before, Google Caffeine was a change to the way Google updated its index in order to make things show up quicker on Google than before. According to Carrie Grimes, the software engineer who announced Caffeine for Google, ""Caffeine provides 50 percent fresher results for web searches than our last index...""  28  Google Instant , real-time-search, was introduced in late 2010 in an attempt to make search results more timely and relevant. Historically site administrators have spent months or even years optimizing a website to increase search rankings. With the growth in popularity of social media sites and blogs, the leading engines made changes to their algorithms to allow fresh content to rank quickly within the search results.  29  Google has implemented numerous algorithm updates to improve search quality, including Panda (2011) for content quality, Penguin (2012) for link spam, Hummingbird (2013) for natural language processing, and BERT (2019) for query understanding. These updates reflect the ongoing evolution of search technology and Google's efforts to combat spam while improving user experience. On May 20, 2025, Google announced that AI Mode would be released to all US users. AI Mode uses what Google calls a ""query fan-out technique"" which breaks down the search query into multiple sub-topics which generates additional search queries for the user.  30  The leading search engines, such as Google, Bing, Brave Search and Yahoo!, use crawlers to find pages for their algorithmic search results. Pages that are linked from other search engine-indexed pages do not need to be submitted because they are found automatically. The Yahoo! Directory and DMOZ , two major directories which closed in 2014 and 2017 respectively, both required manual submission and human editorial review.  31  Google offers Google Search Console , for which an XML Sitemap feed can be created and submitted for free to ensure that all pages are found, especially pages that are not discoverable by automatically following links  32  in addition to their URL submission console.  33  Yahoo! formerly operated a paid submission service that guaranteed to crawl for a cost per click ;  34  however, this practice was discontinued in 2009. Search engine crawlers may look at a number of different factors when crawling a site. Not every page is indexed by search engines. The distance of pages from the root directory of a site may also be a factor in whether or not pages get crawled.  35  Mobile devices are used for the majority of Google searches.  36  In November 2016, Google announced a major change to the way they are crawling websites and started to make their index mobile-first, which means the mobile version of a given website becomes the starting point for what Google includes in their index.  37  In May 2019, Google updated the rendering engine of their crawler to be the latest version of Chromium (74 at the time of the announcement). Google indicated that they would regularly update the Chromium rendering engine to the latest version.  38  In December 2019, Google began updating the User-Agent string of their crawler to reflect the latest Chrome version used by their rendering service. The delay was to allow webmasters time to update their code that responded to particular bot User-Agent strings. Google ran evaluations and felt confident the impact would be minor.  39  To avoid undesirable content in the search indexes, webmasters can instruct spiders not to crawl certain files or directories through the standard robots.txt file in the root directory of the domain. Additionally, a page can be explicitly excluded from a search engine's database by using a meta tag specific to robots (usually meta name""robots"" content""noindex"" ). When a search engine visits a site, the robots.txt located in the root directory is the first file crawled. The robots.txt file is then parsed and will instruct the robot as to which pages are not to be crawled. As a search engine crawler may keep a cached copy of this file, it may on occasion crawl pages a webmaster does not wish to crawl. Pages typically prevented from being crawled include login-specific pages such as shopping carts and user-specific content such as search results from internal searches. In March 2007, Google warned webmasters that they should prevent indexing of internal search results because those pages are considered search spam.  40  In 2020, Google sunsetted the standard (and open-sourced their code) and now treats it as a hint rather than a directive. To adequately ensure that pages are not indexed, a page-level robot's meta tag should be included.  41  A variety of methods can increase the prominence of a webpage within the search results. Cross linking between pages of the same website to provide more links to important pages may improve its visibility. Page design makes users trust a site and want to stay once they find it. When people bounce off a site, it counts against the site and affects its credibility.  42  Writing content that includes frequently searched keyword phrases so as to be relevant to a wide variety of search queries will tend to increase traffic. Updating content so as to keep search engines crawling back frequently can give additional weight to a site. Adding relevant keywords to a web page's metadata, including the title tag and meta description , will tend to improve the relevancy of a site's search listings, thus increasing traffic. URL canonicalization of web pages accessible via multiple URLs, using the canonical link element  43  or via 301 redirects can help make sure links to different versions of the URL all count towards the page's link popularity score. These are known as incoming links, which point to the URL and can count towards the page link's popularity score, impacting the credibility of a website.  42  SEO techniques can be classified into two broad categories: techniques that search engine companies recommend (""white hat""), and those techniques of which search engines do not approve (""black hat""). Search engines attempt to minimize the effect of the latter, among them spamdexing . Industry commentators have classified these methods and the practitioners who employ them as either white hat SEO or black hat SEO.  44  White hats tend to produce results that last a long time, whereas black hats anticipate that their sites may eventually be banned either temporarily or permanently once the search engines discover what they are doing.  45  An SEO technique is considered a white hat if it conforms to the search engines' guidelines and involves no deception. As the search engine guidelines  10   11   46  are not written as a series of rules or commandments, this is an important distinction to note. White hat SEO is not just about following guidelines but is about ensuring that the content a search engine indexes and subsequently ranks is the same content a user will see. White hat advice is generally summed up as creating content for users, not for search engines, and then making that content easily accessible to the online algorithms, rather than attempting to trick the algorithm from its intended purpose. White hat SEO has been compared to web development that promotes accessibility,  47  although the two are not identical. Black hat SEO attempts to improve rankings in ways that are disapproved of by the search engines or involve deception. One black hat technique uses hidden text, either as text colored similar to the background, in an invisible div , or positioned off-screen. Another method gives a different page depending on whether the page is being requested by a human visitor or a search engine, a technique known as cloaking . Another category sometimes used is grey hat SEO . This is in between the black hat and white hat approaches, where the methods employed avoid the site being penalized but do not act in producing the best content for users. Grey hat SEO is entirely focused on improving search engine rankings.  citation needed  Search engines may penalize sites they discover using black or grey hat methods, either by reducing their rankings or eliminating their listings from their databases altogether. Such penalties can be applied either automatically by the search engines' algorithms or by a manual site review. One example was the February 2006 Google removal of both BMW Germany and Ricoh Germany for the use of deceptive practices.  48  Both companies subsequently apologized, fixed the offending pages, and were restored to Google's search engine results page.  49  Companies that employ black hat techniques or other spammy tactics can get their client websites banned from the search results. In 2005, the Wall Street Journal reported on a company, Traffic Power , which allegedly used high-risk techniques and failed to disclose those risks to its clients.  50  Wired magazine reported that the same company sued blogger and SEO Aaron Wall for writing about the ban.  51  Google's Matt Cutts later confirmed that Google had banned Traffic Power and some of its clients.  52  SEO is one approach within digital marketing, alongside other strategies such as pay-per-click advertising and social media marketing. Search engine marketing (SEM) is the practice of designing, running, and optimizing search engine ad campaigns. Its difference from SEO is most simply depicted as the difference between paid and unpaid priority ranking in search results. SEM focuses on prominence more so than relevance; website developers should regard SEM with the utmost importance with consideration to visibility as most navigate to the primary listings of their search.  53  A successful Internet marketing campaign may also depend upon building high-quality web pages to engage and persuade internet users, setting up analytics programs to enable site owners to measure results, and improving a site's conversion rate .  54   55  In November 2015, Google released a full 160-page version of its Search Quality Rating Guidelines to the public,  56  which revealed a shift in their focus towards ""usefulness"" and mobile local search . In recent years the mobile market has exploded, overtaking the use of desktops, as shown in by StatCounter in October 2016, where they analyzed 2.5 million websites and found that 51.3 of the pages were loaded by a mobile device.  57  Google has been one of the companies that are utilizing the popularity of mobile usage by encouraging websites to use their Google Search Console , the Mobile-Friendly Test, which allows companies to measure up their website to the search engine results and determine how user-friendly their websites are. The closer the keywords are together their ranking will improve based on key terms.  42  SEO may generate an adequate return on investment . However, search engines are not paid for organic search traffic, their algorithms change, and there are no guarantees of continued referrals. Due to this lack of guarantee and uncertainty, a business that relies heavily on search engine traffic can suffer major losses if the search engines stop sending visitors.  58  Search engines can change their algorithms, impacting a website's search engine ranking, possibly resulting in a serious loss of traffic. According to Google's CEO, Eric Schmidt , in 2010, Google made over 500 algorithm changes  almost 1.5 per day.  59  Industry analysts note that websites may face risks from algorithm changes that can significantly impact organic traffic. In addition to accessibility in terms of web crawlers (addressed above), user web accessibility has become increasingly important for SEO. Optimization techniques are highly tuned to the dominant search engines in the target market. The search engines' market shares vary from market to market, as does competition. Google has maintained dominant market share in most regions, with varying percentages by market.  60  In markets outside the United States, Google's share is often larger, and data showed Google was the dominant search engine worldwide as of 2007.  61  As of 2006, Google had an 8590 market share in Germany.  62  As of March 2024, Google still had a significant market share of 89.85 in Germany.  63  As of March 2024, Google's market share in the UK was 93.61.  64  Successful search engine optimization (SEO) for international markets requires more than just translating web pages. It may also involve registering a domain name with a country-code top-level domain (ccTLD) or a relevant top-level domain (TLD) for the target market, choosing web hosting with a local IP address or server, and using a Content Delivery Network (CDN) to improve website speed and performance globally. It is also important to understand the local culture so that the content feels relevant to the audience. This includes conducting keyword research for each market, using hreflang tags to target the right languages, and building local backlinks. However, the core SEO principlessuch as creating high-quality content, improving user experience, and building linksremain the same, regardless of language or region.  62  Regional search engines have a strong presence in specific markets: By the early 2000s, businesses recognized that the web and search engines could help them reach global audiences. As a result, the need for multilingual SEO emerged.  69  In the early years of international SEO development, simple translation was seen as sufficient. However, over time, it became clear that localization and transcreationadapting content to local language, culture, and emotional resonancewere more effective than basic translation.  70  On October 17, 2002, SearchKing filed suit in the United States District Court , Western District of Oklahoma, against the search engine Google. SearchKing's claim was that Google's tactics to prevent spamdexing constituted a tortious interference with contractual relations. On May 27, 2003, the court granted Google's motion to dismiss the complaint because SearchKing ""failed to state a claim upon which relief may be granted.""  71   72  In March 2006, KinderStart filed a lawsuit against Google over search engine rankings. KinderStart's website was removed from Google's index prior to the lawsuit, and the amount of traffic to the site dropped by 70. On March 16, 2007, the United States District Court for the Northern District of California ( San Jose Division) dismissed KinderStart's complaint without leave to amend and partially granted Google's motion for Rule 11 sanctions against KinderStart's attorney, requiring him to pay part of Google's legal expenses.  73   74 ",3499
https://simple.wikipedia.org/wiki/Search_engine_optimization,"Search engine optimization - Simple English Wikipedia, the free encyclopedia","Search engine optimization (SEO) is about making websites and other forms of online presence appear higher in search results when someone searches for a term.  1  The search term is called a keyword .  2  The results of the search are displayed in the search engine 's results pages (SERPS) such as those given by Google , Bing, Yahoo! and others. Other terms used to describe search engine optimization are internet marketing and search engine marketing.  3  SEO is performed because a website will receive more visitors from a search engine when it ranks higher on the SERP. These visitors can then be converted into customers. The process is often broken down into several core areas. On-page SEO refers to the practice of optimizing elements on the website itself. This includes:  4   5  Technical SEO refers to non-content elements of a site that affect its performance and crawlability. Key aspects include: Everything SEO-related that doesn't take place on a website is considered off-page SEO. Among other things, backlinks , social media, and local citations are all aspects of off-page SEO. SEO is a crucial part of marketing campaigns run by businesses to reach customers online. Companies hire SEO agencies to do the work for them because of the expertise required.  7  If an SEO method is approved by search engines to rank their website, it is called a "" white hat technique "". If the method is not approved, it is called a ""black hat technique"". Search engines penalize sites using black hat techniques by ranking them lower, or by not showing them on search results at all.  8  However, some techniques fall in between these two categories, known as "" gray hat techniques ."" These methods are not explicitly approved by search engines but are not strictly prohibited either. While they may offer short-term ranking benefits, they carry the risk of penalties if search engine guidelines change. Since the early 2020s, the integration of large language models (LLMs) into search engines has created a fundamental shift, leading to the emergence of a complementary discipline to traditional SEO. This new field is sometimes referred to as Generative Engine Optimization (GEO) or Answer Engine Optimization (AEO). Its primary goal is not to win a click from a list of links, but to have a brand's information or data used and cited within an AI-generated answer  9  . This scenario referral to a zero-click result - the successful resolution of a web query when the user gets their desired result immediately This evolution impacts all core areas of optimization: As a result, modern SEO is becoming a hybrid discipline, requiring strategies for both traditional search rankings and visibility within generative AI answers.",450
https://en.wikipedia.org/wiki/Content_marketing,Content marketing - Wikipedia," Content marketing is a form of marketing focused on creating, publishing, and distributing content for a targeted audience online.  1  It is often used in order to achieve the following business goals: attract attention and generate leads, expand their customer base, generate or increase online sales, increase brand awareness or credibility, and engage a community of online users. Content marketing attracts new customers by creating and sharing valuable free content as well as by helping companies create sustainable brand loyalty , providing valuable information to consumers, and creating a willingness to purchase products from the company in the future.  2  Content marketing starts with identifying the customer's needs. After that, the information can be presented in a variety of long form and short form formats, including news, video, white papers , e-books , infographics , email newsletters , case studies, podcasts , how-to guides, question and answer articles, photos, blogs , etc.  3  Examples of short form content include short blog posts and social media posts.  4  Content marketing requires continuous delivery of large amounts of content, preferably within a content marketing strategy.  5  Traditional marketers have long used content to disseminate information about a brand and build its reputation . Taking advantage of technological advances in transportation and communication, business owners began applying content marketing techniques in the late 19th century. Content marketing aims to attract and retain audiences by consistently creating and sharing valuable, relevant, and free content. During the golden age of TV, between the 1940s and 1950s, advertising took over the media. Companies focused on sales rather than connecting with the public. There were few ventures into content marketing and not many prominent campaigns. During the baby boom era, Kellogg's began selling sugary cereal to children. With this change in business model came sociable animal mascots, lively animated commercials and the back of the cereal box as a form of targeted content marketing. This represented a new approach to making a brand memorable with the audience.  11  In the 1990s, everything changed for marketers. The arrival of computers and the Internet made websites and blogs flourish, and corporations found content marketing opportunities through email. E-commerce adaptations and digital distribution became the foundation of marketing strategy. The Internet also helped content marketing become a mainstream form of marketing. Traditional media such as newspapers, magazines, radio and TV started to lose their power in the marketplace. Companies started to promote and sell their products digitally.  12  The phrase ""content marketing"" was used as early as 1996,  13  when John F. Oppedahl led a roundtable for journalists at the American Society for Newspaper Editors. By the late 2000s, when social networks such as Facebook , Twitter , and YouTube were born, online content marketing was accessible, shareable and on-demand anytime worldwide. By 2014, Forbes Magazine's website had written about the seven most popular ways companies use content marketing.  16  In it, the columnist points out that by 2013, the use of content marketing had jumped across corporations from 60 a year or so before, to 93  17  as part of their overall marketing strategy. Despite the fact that 70 of organizations are creating more content, only 21 of marketers think they are successful at tracking return on investment . Today, content marketing has become a powerful model for marketers. Storytelling is part of it, and they must convey the companies' messages or goal to their desired audience without pushing them to just buy the product or service. The rise of content marketing has turned many traditional businesses into media publishing companies.  18  For example: The rise of content marketing has also accelerated the growth of online platforms, such as YouTube , Yelp , LinkedIn , Tumblr , Pinterest , and more. For example: Businesses actively curate their content on these platforms with hopes to expand their reach to new audiences. Part of transitioning to a media publishing mindset requires a change in structure and process to create content at ""the speed of culture."" Marketing content production is transforming from an advertising agency model to a newsroom model, according to one consultant.  25  Metrics to determine the success of content marketing are often tied to the original goals of the campaign. For example, for each of these goals, a content marketer may measure the different engagement and conversion metrics: Businesses focused on expanding their reach to more customers will want to pay attention to the increase in the volume of visitors, as well as the quality of those interactions. Traditional measures of volume include the number of visitors to a page and number of emails collected, while time spent on page and click-through to other pages photos are good indicators for engagement.  citation needed  Businesses want to measure the impact that their messages have on consumers. Brand health refers to the positive or negative feedback that a company gets. It also measures how important a brand is for consumers. With this companies want to find out if brand reputation influences their customers to make a purchase.  26  Measures in this part comprise For businesses hoping to reach not only more - but also new - types of customers online, they should pay attention to the demographics of new visitors, as evidenced by cookies that can be installed, different sources of traffic, different online behaviors, andor different buying habits of online visitors. Businesses focused on increasing sales through content marketing should look at traditional e-commerce metrics including click-through-rate from a product-page to check-out and completion rates at the check-out. Altogether, these form a conversion funnel. Moreover, to better understand customers' buying habits, they should look at other engagement metrics like time spent per page, number of product-page visits per user, and re-engagement. Refers to companies that want to analyze whether their social media campaigns are generating commentary among consumers. This helps them to come up with ways to improve their product and service. This involves ""high level of brand engagement and builds brand loyalty"".  28  Examples: Digital content marketing, which is a management process, uses digital products through different electronic channels to identify, forecast and satisfy the necessity of the customers.  29  Examples: The supply chain of digital content marketing mainly consists of commercial stakeholders and end-user stakeholders which represent content providers and distributors and customers separately.  38  In this process, distributors manage the interface between the publisher and the consumer, then distributors could identify the content that consumers need through external channels and implement marketing strategies. For instance, Library and document supply agencies as intermediaries can deliver the digital content of e-books, and e-journal articles to the users according to their search results through the electronic channels. Another example is when consumers pay for the acquisition of some MP3 downloads, search engines can be used to identify different music providers and smart agents can be used by consumers to search for multiple music provider sites. In a word, the digital content marketing process needs to be conducted at the business level and service experience level because when consumers are accessing digital content, their own experience depends on the complex network of relationships in the content marketing channels such as websites and videos. The consumers interact directly with distributors in the big supply chain through various digital products which have an important role in meeting the requirements of the consumers. The design and user experience of these channels directly decides the success of digital content marketing.  29  Electronic services refer to interactive network services.  39  In the electronic service, the interaction between the customer and the organizations mainly through the network technology, such as using E-mail, telephone, online chat windows for communication. Electronic services are different from traditional services and they are not affected by distance restrictions and opening hours. Digital content marketing through electronic service is usually served together with other channels to achieve marketing purposes including face-to-face, postal, and other remote services. Information companies provide different messages and documents to customers who use multiple search engines on different sites and set up access rights for business groups. These are some channels of digital content marketing.  29 ",1347
https://simple.wikipedia.org/wiki/Content_marketing,"Content marketing - Simple English Wikipedia, the free encyclopedia","Content marketing is creating and sharing useful information to attract and keep customers. It is a type of marketing that helps businesses by giving people helpful content instead of just trying to sell things directly. Companies use this type of marketing to build trust and show they are experts in their field.  1  Content Marketing is different from traditional advertising. Traditional advertising tries to sell products directly through ads, commercials, and sales messages. Content marketing focuses on helping people by giving them useful information , entertainment , or education . Instead of saying ""buy our product,"" content marketing says ""here is some helpful tips to solve your pain point or achieve your goal.""  2  Content marketing works by attracting people who are interested in a topic related to a business. For example, a cooking company might write blog posts about healthy recipes. People who read these posts might later buy the company's cooking products. The company builds trust by being helpful first, then customers are more likely to buy from them.  3  Content marketing helps businesses in many ways:",179
https://en.wikipedia.org/wiki/Machine_learning,Machine learning - Wikipedia," Machine learning ( ML ) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions .  1  Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks , a class of statistical algorithms, to surpass many previous machine learning approaches in performance.  2  ML finds application in many fields, including natural language processing , computer vision , speech recognition , email filtering , agriculture , and medicine . The application of ML to business problems is known as predictive analytics . Statistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning .  4   5  From a theoretical viewpoint, probably approximately correct learning provides a mathematical and statistical framework for describing machine learning. Most traditional machine learning and deep learning algorithms can be described as empirical risk minimisation under this framework. The term machine learning was coined in 1959 by Arthur Samuel , an IBM employee and pioneer in the field of computer gaming and artificial intelligence .  6   7  The synonym self-teaching computers was also used in this time period.  8   9  The earliest machine learning program was introduced in the 1950s when Arthur Samuel invented a computer program that calculated the winning chance in checkers for each side, but the history of machine learning roots back to decades of human desire and effort to study human cognitive processes.  10  In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior , in which he introduced a theoretical neural structure formed by certain interactions among nerve cells .  11  Hebb's model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data.  10  Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch , who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.  10  By the early 1960s, an experimental ""learning machine"" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyse sonar signals, electrocardiograms , and speech patterns using rudimentary reinforcement learning . It was repetitively ""trained"" by a human operatorteacher to recognise patterns and equipped with a "" goof "" button to cause it to reevaluate incorrect decisions.  12  A representative book on research into machine learning during the 1960s was Nils Nilsson 's book on Learning Machines, dealing mostly with machine learning for pattern classification.  13  Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.  14  In 1981, a report was given on using teaching strategies so that an artificial neural network learns to recognise 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.  15  Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: ""A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T , as measured by P , improves with experience E .""  16  This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing 's proposal in his paper "" Computing Machinery and Intelligence "", in which the question, ""Can machines think?"", is replaced with the question, ""Can machines do what we (as thinking entities) can do?"".  17  Modern day Machine Learning algorithms are broken into 3 algorithms types: Supervised Learning Algorithms, Unsupervised Learning Algorithms, and Reinforcement Learning Algorithms.  18  In 2014 Ian Goodfellow and others introduced generative adversarial networks (GANs) with realistic data synthesis.  19  By 2016 AlphaGo obtained victory against top human players using reinforcement learning techniques.  20  Shortly after, transformer architectures obtained natural language processing, powering the now popular large language models advancing generative AI and multimodal applications.  21  As a scientific endeavour, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline , some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed "" neural networks ""; these were mostly perceptrons and other models that were later found to be reinventions of the generalised linear models of statistics.  23  Probabilistic reasoning was also employed, especially in automated medical diagnosis .  24  : 488 However, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.  24  : 488 By 1980, expert systems had come to dominate AI, and statistics was out of favour.  25  Work on symbolicknowledge-based learning did continue within AI, leading to inductive logic programming (ILP), but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval .  24  : 708710, 755 Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AICS field, as "" connectionism "", by researchers from other disciplines including John Hopfield , David Rumelhart , and Geoffrey Hinton . Their main success came in the mid-1980s with the reinvention of backpropagation .  24  : 25 Machine learning (ML), reorganised and recognised as its own field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence, to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics, fuzzy logic , and probability theory .  25  There is a close connection between machine learning and compression. A system that predicts the posterior probabilities of a sequence given its entire history can be used for optimal data compression (by using arithmetic coding on the output distribution). Conversely, an optimal compressor can be used for prediction (by finding the symbol that compresses best, given the previous history). This equivalence has been used as a justification for using data compression as a benchmark for ""general intelligence"".  26   27   28  An alternative view can show compression algorithms implicitly map strings into implicit feature space vectors , and compression-based similarity measures compute similarity within these feature spaces. For each compressor C(.) we define an associated vector space , such that C(.) maps an input string x, corresponding to the vector norm x. An exhaustive examination of the feature spaces underlying all compression algorithms is precluded by space; instead, feature vectors chooses to examine three representative lossless compression methods, LZW, LZ77, and PPM.  29  According to AIXI theory, a connection more directly explained in Hutter Prize , the best possible compression of x is the smallest possible software that generates x. For example, in that model, a zip file's compressed size includes both the zip file and the unzipping software, since you can not unzip it without both, but there may be an even smaller combined form. Examples of AI-powered audiovideo compression software include NVIDIA Maxine , AIVC.  30  Examples of software that can perform AI-powered image compression include OpenCV , TensorFlow , MATLAB 's Image Processing Toolbox (IPT) and High-Fidelity Generative Image Compression.  31  In unsupervised machine learning , k-means clustering can be utilized to compress data by grouping similar data points into clusters. This technique simplifies handling extensive datasets that lack predefined labels and finds widespread use in fields such as image compression .  32  Data compression aims to reduce the size of data files, enhancing storage efficiency and speeding up data transmission. K-means clustering, an unsupervised machine learning algorithm, is employed to partition a dataset into a specified number of clusters, k, each represented by the centroid of its points. This process condenses extensive datasets into a more compact set of representative points. Particularly beneficial in image and signal processing , k-means clustering aids in data reduction by replacing groups of data points with their centroids, thereby preserving the core information of the original data while significantly decreasing the required storage space.  33  Machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as "" unsupervised learning "" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.  citation needed  Machine learning also has intimate ties to optimisation : Many learning problems are formulated as minimisation of some loss function on a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the preassigned labels of a set of examples).  36  Characterizing the generalisation of various learning algorithms is an active topic of current research, especially for deep learning algorithms. Machine learning and statistics are closely related fields in terms of methods, but distinct in their principal goal: statistics draws population inferences from a sample , while machine learning finds generalisable predictive patterns.  37  Conventional statistical analyses require the a priori selection of a model most suitable for the study data set. In addition, only significant or theoretically relevant variables based on previous experience are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather, the data shape the model by detecting underlying patterns. The more variables (input) used to train the model, the more accurate the ultimate model will be.  38  Leo Breiman distinguished two statistical modelling paradigms: data model and algorithmic model,  39  wherein ""algorithmic model"" means more or less the machine learning algorithms like Random Forest . Some statisticians have adopted methods from machine learning, leading to a combined field that they call statistical learning .  40  Analytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems, including machine learning, e.g., to analyse the weight space of deep neural networks .  41  Statistical physics is thus finding applications in the area of medical diagnostics .  42  A core objective of a learner is to generalise from its experience.  3   43  Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examplestasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases. The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the probably approximately correct learning model. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The biasvariance decomposition is one way to quantify generalisation error . For the best performance in the context of generalisation, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalisation will be poorer.  44  In addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time . There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time. Machine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigms, depending on the nature of the ""signal"" or ""feedback"" available to the learning system: Although each algorithm has advantages and limitations, no single algorithm works for all problems.  45   46   47  Supervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs.  48  The data, known as training data , consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal. In the mathematical model, each training example is represented by an array or vector, sometimes called a feature vector , and the training data is represented by a matrix . Through iterative optimisation of an objective function , supervised learning algorithms learn a function that can be used to predict the output associated with new inputs.  49  An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.  16  Types of supervised-learning algorithms include active learning , classification and regression .  50  Classification algorithms are used when the outputs are restricted to a limited set of values, while regression algorithms are used when the outputs can take any numerical value within a range. For example, in a classification algorithm that filters emails, the input is an incoming email, and the output is the folder in which to file the email. In contrast, regression is used for tasks such as predicting a person's height based on factors like age and genetics or forecasting future temperatures based on historical data.  51  Similarity learning is an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in ranking , recommendation systems , visual identity tracking, face verification, and speaker verification. Unsupervised learning algorithms find structures in data that has not been labelled, classified or categorised. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. Central applications of unsupervised machine learning include clustering, dimensionality reduction ,  5  and density estimation .  52  Cluster analysis is the assignment of a set of observations into subsets (called clusters ) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated, for example, by internal compactness , or the similarity between members of the same cluster, and separation , the difference between clusters. Other methods are based on estimated density and graph connectivity . A special type of unsupervised learning called, self-supervised learning involves training a model by generating the supervisory signal from the data itself.  53   54  Semi-supervised learning falls between unsupervised learning (without any labelled training data) and supervised learning (with completely labelled training data). Some of the training examples are missing training labels, yet many machine-learning researchers have found that unlabelled data, when used in conjunction with a small amount of labelled data, can produce a considerable improvement in learning accuracy. In weakly supervised learning , the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.  55  Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximise some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as game theory , control theory , operations research , information theory , simulation-based optimisation , multi-agent systems , swarm intelligence , statistics and genetic algorithms . In reinforcement learning, the environment is typically represented as a Markov decision process (MDP). Many reinforcement learning algorithms use dynamic programming techniques.  56  Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent. Dimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables.  57  In other words, it is a process of reducing the dimension of the feature set, also called the ""number of features"". Most of the dimensionality reduction techniques can be considered as either feature elimination or extraction . One of the popular methods of dimensionality reduction is principal component analysis (PCA). PCA involves changing higher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D). The manifold hypothesis proposes that high-dimensional data sets lie along low-dimensional manifolds , and many dimensionality reduction techniques make this assumption, leading to the area of manifold learning and manifold regularisation . Other approaches have been developed which do not fit neatly into this three-fold categorisation, and sometimes more than one is used by the same machine learning system. For example, topic modelling , meta-learning .  58  Self-learning, as a machine learning paradigm was introduced in 1982 along with a neural network capable of self-learning, named crossbar adaptive array (CAA).  59   60  It gives a solution to the problem learning without any external reward, by introducing emotion as an internal reward. Emotion is used as state evaluation of a self-learning agent. The CAA self-learning algorithm computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence situations. The system is driven by the interaction between cognition and emotion.  61  The self-learning algorithm updates a memory matrix W w(a,s) such that in each iteration executes the following machine learning routine: It is a system with only one input, situation, and only one output, action (or behaviour) a. There is neither a separate reinforcement input nor an advice input from the environment. The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is the behavioural environment where it behaves, and the other is the genetic environment, wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioural environment. After receiving the genome (species) vector from the genetic environment, the CAA learns a goal-seeking behaviour, in an environment that contains both desirable and undesirable situations.  62  Several learning algorithms aim at discovering better representations of the inputs provided during training.  63  Classic examples include principal component analysis and cluster analysis. Feature learning algorithms, also called representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions. This technique allows reconstruction of the inputs coming from the unknown data-generating distribution, while not being necessarily faithful to configurations that are implausible under that distribution. This replaces manual feature engineering , and allows a machine to both learn the features and use them to perform a specific task. Feature learning can be either supervised or unsupervised. In supervised feature learning, features are learned using labelled input data. Examples include artificial neural networks , multilayer perceptrons , and supervised dictionary learning . In unsupervised feature learning, features are learned with unlabelled input data. Examples include dictionary learning, independent component analysis , autoencoders , matrix factorisation  64  and various forms of clustering .  65   66   67  Manifold learning algorithms attempt to do so under the constraint that the learned representation is low-dimensional. Sparse coding algorithms attempt to do so under the constraint that the learned representation is sparse, meaning that the mathematical model has many zeros. Multilinear subspace learning algorithms aim to learn low-dimensional representations directly from tensor representations for multidimensional data, without reshaping them into higher-dimensional vectors.  68  Deep learning algorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine is one that learns a representation that disentangles the underlying factors of variation that explain the observed data.  69  Feature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensory data has not yielded attempts to algorithmically define specific features. An alternative is to discover such features or representations through examination, without relying on explicit algorithms. Sparse dictionary learning is a feature learning method where a training example is represented as a linear combination of basis functions and assumed to be a sparse matrix . The method is strongly NP-hard and difficult to solve approximately.  70  A popular heuristic method for sparse dictionary learning is the k -SVD algorithm. Sparse dictionary learning has been applied in several contexts. In classification, the problem is to determine the class to which a previously unseen training example belongs. For a dictionary where each class has already been built, a new training example is associated with the class that is best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in image de-noising . The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.  71  In data mining , anomaly detection, also known as outlier detection, is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.  72  Typically, the anomalous items represent an issue such as bank fraud , a structural defect, medical problems or errors in a text. Anomalies are referred to as outliers , novelties, noise, deviations and exceptions.  73  In particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare objects, but unexpected bursts of inactivity. This pattern does not adhere to the common statistical definition of an outlier as a rare object. Many outlier detection methods (in particular, unsupervised algorithms) will fail on such data unless aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro-clusters formed by these patterns.  74  Three broad categories of anomaly detection techniques exist.  75  Unsupervised anomaly detection techniques detect anomalies in an unlabelled test data set under the assumption that the majority of the instances in the data set are normal, by looking for instances that seem to fit the least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labelled as ""normal"" and ""abnormal"" and involves training a classifier (the key difference from many other statistical classification problems is the inherently unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behaviour from a given normal training data set and then test the likelihood of a test instance to be generated by the model. Robot learning is inspired by a multitude of machine learning methods, starting from supervised learning, reinforcement learning,  76   77  and finally meta-learning (e.g. MAML). Association rule learning is a rule-based machine learning method for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of ""interestingness"".  78  Rule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves ""rules"" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilisation of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.  79  Rule-based machine learning approaches include learning classifier systems , association rule learning, and artificial immune systems . Based on the concept of strong rules, Rakesh Agrawal , Tomasz Imieliski and Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets.  80  For example, the rule  o n i o n s , p o t a t o e s    b u r g e r  displaystyle mathrm onions,potatoes Rightarrow mathrm burger  found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements . In addition to market basket analysis , association rules are employed today in application areas including Web usage mining , intrusion detection , continuous production , and bioinformatics . In contrast with sequence mining , association rule learning typically does not consider the order of items either within a transaction or across transactions. Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm , with a learning component, performing either supervised learning , reinforcement learning , or unsupervised learning . They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions.  81  Inductive logic programming (ILP) is an approach to rule learning using logic programming as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that entails all positive and no negative examples. Inductive programming is a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as functional programs . Inductive logic programming is particularly useful in bioinformatics and natural language processing . Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting.  82   83   84  Shapiro built their first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from positive and negative examples.  85  The term inductive here refers to philosophical induction, suggesting a theory to explain observed facts, rather than mathematical induction , proving a property for all members of a well-ordered set. A machine learning model is a type of mathematical model that, once ""trained"" on a given dataset, can be used to make predictions or classifications on new data. During training, a learning algorithm iteratively adjusts the model's internal parameters to minimise errors in its predictions.  86  By extension, the term ""model"" can refer to several levels of specificity, from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned.  87  Various types of models have been used and researched for machine learning systems, picking the best model for a task is called model selection . Artificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains . Such systems ""learn"" to perform tasks by considering examples, generally without being programmed with any task-specific rules. An ANN is a model based on a collection of connected units or nodes called "" artificial neurons "", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a ""signal"", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number , and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called ""edges"". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times. The original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology . Artificial neural networks have been used on a variety of tasks, including computer vision , speech recognition , machine translation , social network filtering, playing board and video games and medical diagnosis . Deep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.  88  Decision tree learning uses a decision tree as a predictive model to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modelling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels, and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers ) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making . In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision-making. Random forest regression (RFR) falls under umbrella of decision tree-based models . RFR is an ensemble learning method that builds multiple decision trees and averages their predictions to improve accuracy and to avoid overfitting. To build decision trees, RFR uses bootstrapped sampling, for instance each decision tree is trained on random data from the training set. This random selection of RFR for training enables model to reduce bias predictions and achieve a higher degree of accuracy. RFR generates independent decision trees, and it can work on single output data as well multiple regressor tasks. This makes RFR compatible to be used in various applications.  89   90  Support-vector machines (SVMs), also known as support-vector networks, are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category.  91  An SVM training algorithm is a non- probabilistic , binary , linear classifier , although methods such as Platt scaling exist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick , implicitly mapping their inputs into high-dimensional feature spaces. Regression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is linear regression , where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares . The latter is often extended by regularisation methods to mitigate overfitting and bias, as in ridge regression . When dealing with non-linear problems, go-to models include polynomial regression (for example, used for trendline fitting in Microsoft Excel  92  ), logistic regression (often used in statistical classification ) or even kernel regression , which introduces non-linearity by taking advantage of the kernel trick to implicitly map input variables to higher-dimensional space. Multivariate linear regression extends the concept of linear regression to handle multiple dependent variables simultaneously. This approach estimates the relationships between a set of input variables and several output variables by fitting a multidimensional linear model. It is particularly useful in scenarios where outputs are interdependent or share underlying patterns, such as predicting multiple economic indicators or reconstructing images,  93  which are inherently multi-dimensional. A Bayesian network, belief network, or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform inference and learning. Bayesian networks that model sequences of variables, like speech signals or protein sequences , are called dynamic Bayesian networks . Generalisations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams . A Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution , and it relies on a pre-defined covariance function , or kernel, that models how pairs of points relate to each other depending on their locations. Given a set of observed points, or inputoutput examples, the distribution of the (unobserved) output of a new point as function of its input data can be directly computed by looking like the observed points and the covariances between those points and the new, unobserved point. Gaussian processes are popular surrogate models in Bayesian optimisation used to do hyperparameter optimisation . A genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the process of natural selection , using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s.  95   96  Conversely, machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms .  97  The theory of belief functions, also referred to as evidence theory or DempsterShafer theory, is a general framework for reasoning with uncertainty, with understood connections to other frameworks such as probability , possibility and imprecise probability theories . These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined (e.g., Dempster's rule of combination), just like how in a pmf -based Bayesian approach would combine probabilities.  98  However, there are many caveats to these beliefs functions when compared to Bayesian approaches in order to incorporate ignorance and uncertainty quantification . These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learner's decision boundary , low samples, and ambiguous class issues that standard machine learning approach tend to have difficulty resolving.  99   7  However, the computational complexity of these algorithms are dependent on the number of propositions (classes), and can lead to a much higher computation time when compared to other machine learning approaches. Rule-based machine learning (RBML) is a branch of machine learning that automatically discovers and learns 'rules' from data. It provides interpretable models, making it useful for decision-making in fields like healthcare, fraud detection, and cybersecurity. Key RBML techniques includes learning classifier systems ,  100  association rule learning ,  101  artificial immune systems ,  102  and other similar models. These methods extract patterns from data and evolve rules over time. Typically, machine learning models require a high quantity of reliable data to perform accurate predictions. When training a machine learning model, machine learning engineers need to target and collect a large and representative sample of data. Data from the training set can be as varied as a corpus of text , a collection of images, sensor data, and data collected from individual users of a service. Overfitting is something to watch out for when training a machine learning model. Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions. Biased models may result in detrimental outcomes, thereby furthering the negative impacts on society or objectives. Algorithmic bias is a potential result of data not being fully prepared for training. Machine learning ethics is becoming a field of study and notably, becoming integrated within machine learning engineering teams. Federated learning is an adapted form of distributed artificial intelligence to training machine learning models that decentralises the training process, allowing for users' privacy to be maintained by not needing to send their data to a centralised server. This also increases efficiency by decentralising the training process to many devices. For example, Gboard uses federated machine learning to train search query prediction models on users' mobile phones without having to send individual searches back to Google .  103  There are many applications for machine learning, including: In 2006, the media-services provider Netflix held the first "" Netflix Prize "" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10. A joint team made up of researchers from ATT Labs -Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for 1 million.  107  Shortly after the prize was awarded, Netflix realised that viewers' ratings were not the best indicators of their viewing patterns (""everything is a recommendation"") and they changed their recommendation engine accordingly.  108  In 2010, an article in The Wall Street Journal noted the use of machine learning by Rebellion Research to predict the 2008 financial crisis .  109  In 2012, co-founder of Sun Microsystems , Vinod Khosla , predicted that 80 of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software.  110  In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognised influences among artists.  111  In 2019 Springer Nature published the first research book created using machine learning.  112  In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19.  113  Machine learning was recently applied to predict the pro-environmental behaviour of travellers.  114  Recently, machine learning technology was also applied to optimise smartphone's performance and thermal behaviour based on the user's interaction with the phone.  115   116   117  When applied correctly, machine learning algorithms (MLAs) can utilise a wide range of company characteristics to predict stock returns without overfitting . By employing effective feature engineering and combining forecasts, MLAs can generate results that far surpass those obtained from basic linear techniques like OLS .  118  Recent advancements in machine learning have extended into the field of quantum chemistry, where novel algorithms now enable the prediction of solvent effects on chemical reactions, thereby offering new tools for chemists to tailor experimental conditions for optimal outcomes.  119  Machine Learning is becoming a useful tool to investigate and predict evacuation decision making in large scale and small scale disasters. Different solutions have been tested to predict if and when householders decide to evacuate during wildfires and hurricanes.  120   121   122  Other applications have been focusing on pre evacuation decisions in building fires.  123   124  Although machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results.  125   126   127  Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.  128  The "" black box theory "" poses another yet significant challenge. Black box refers to a situation where the algorithm or the process of producing an output is entirely opaque, meaning that even the coders of the algorithm cannot audit the pattern that the machine extracted out of the data.  129  The House of Lords Select Committee, which claimed that such an ""intelligence system"" that could have a ""substantial impact on an individual's life"" would not be considered acceptable unless it provided ""a full and satisfactory explanation for the decisions"" it makes.  129  In 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a collision.  130  Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested.  131   132  Microsoft's Bing Chat chatbot has been reported to produce hostile and offensive response against its users.  133  Machine learning has been used as a strategy to update the evidence related to a systematic review and increased reviewer burden related to the growth of biomedical literature. While it has improved with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research themselves.  134  Explainable AI (XAI), or Interpretable AI, or Explainable Machine Learning (XML), is artificial intelligence (AI) in which humans can understand the decisions or predictions made by the AI.  135  It contrasts with the ""black box"" concept in machine learning where even its designers cannot explain why an AI arrived at a specific decision.  136  By refining the mental models of users of AI-powered systems and dismantling their misconceptions, XAI promises to help users perform more effectively. XAI may be an implementation of the social right to explanation. Settling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data but penalising the theory in accordance with how complex the theory is.  137  Learners can also disappoint by ""learning the wrong lesson"". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses.  138  A real-world example is that, unlike humans, current image classifiers often do not primarily make judgements from the spatial relationship between components of the picture, and they learn relationships between pixels that humans are oblivious to, but that still correlate with images of certain types of real objects. Modifying these patterns on a legitimate image can result in ""adversarial"" images that the system misclassifies.  139   140  Adversarial vulnerabilities can also result in nonlinear systems, or from non-pattern perturbations. For some systems, it is possible to change the output by only changing a single adversarially chosen pixel.  141  Machine learning models are often vulnerable to manipulation or evasion via adversarial machine learning .  142  Researchers have demonstrated how backdoors can be placed undetectably into classifying (e.g., for categories ""spam"" and well-visible ""not spam"" of posts) machine learning models that are often developed or trained by third parties. Parties can change the classification of any input, including in cases for which a type of datasoftware transparency is provided, possibly including white-box access .  143   144   145  Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data in a training and test set (conventionally 23 training set and 13 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold- cross-validation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods, bootstrap , which samples n instances with replacement from the dataset, can be used to assess model accuracy.  146  In addition to overall accuracy, investigators frequently report sensitivity and specificity meaning true positive rate (TPR) and true negative rate (TNR) respectively. Similarly, investigators sometimes report the false positive rate (FPR) as well as the false negative rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. Receiver operating characteristic (ROC) along with the accompanying Area Under the ROC Curve (AUC) offer additional tools for classification model assessment. Higher AUC is associated with a better performing model.  147  The ethics of artificial intelligence covers a broad range of topics within AI that are considered to have particular ethical stakes.  148  This includes algorithmic biases , fairness ,  149  automated decision-making ,  150  accountability , privacy , and regulation . It also covers various emerging or potential future challenges such as machine ethics (how to make machines that behave ethically), lethal autonomous weapon systems , arms race dynamics, AI safety and alignment , technological unemployment , AI-enabled misinformation ,  151  how to treat certain AI systems if they have a moral status (AI welfare and rights), artificial superintelligence and existential risks .  148  Different machine learning approaches can suffer from different data biases. A machine learning system trained specifically on current customers may not be able to predict the needs of new customer groups that are not represented in the training data. When trained on human-made data, machine learning is likely to pick up the constitutional and unconscious biases already present in society.  152  Systems that are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitising cultural prejudices.  153  For example, in 1988, the UK's Commission for Racial Equality found that St. George's Medical School had been using a computer program trained from data of previous admissions staff and that this program had denied nearly 60 candidates who were found to either be women or have non-European sounding names.  152  Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants.  154   155  Another example includes predictive policing company Geolitica 's predictive algorithm that resulted in ""disproportionately high levels of over-policing in low-income and minority communities"" after being trained with historical crime data.  156  While responsible collection of data and documentation of algorithmic rules used by a system is considered a critical part of machine learning, some researchers blame lack of participation and representation of minority population in the field of AI for machine learning's vulnerability to biases.  157  In fact, according to research carried out by the Computing Research Association (CRA) in 2021, ""female faculty merely make up 16.1"" of all faculty members who focus on AI among several universities around the world.  158  Furthermore, among the group of ""new U.S. resident AI PhD graduates,"" 45 identified as white, 22.4 as Asian, 3.2 as Hispanic, and 2.4 as African American, which further demonstrates a lack of diversity in the field of AI.  158  Language models learned from data have been shown to contain human-like biases.  159   160  Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases.  161   162  In 2016, Microsoft tested Tay , a chatbot that learned from Twitter, and it quickly picked up racist and sexist language.  163  In an experiment carried out by ProPublica , an investigative journalism organisation, a machine learning algorithm's insight into the recidivism rates among prisoners falsely flagged ""black defendants high risk twice as often as white defendants"".  156  In 2015, Google Photos once tagged a couple of black people as gorillas, which caused controversy. The gorilla label was subsequently removed, and in 2023, it still cannot recognise gorillas.  164  Similar issues with recognising non-white people have been found in many other systems.  165  Because of such challenges, the effective use of machine learning may take longer to be adopted in other domains.  166  Concern for fairness in machine learning, that is, reducing bias in machine learning and propelling its use for human good, is increasingly expressed by artificial intelligence scientists, including Fei-Fei Li , who said that ""there's nothing artificial about AI. It's inspired by people, it's created by people, andmost importantlyit impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.""  167  There are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines. This is especially true in the United States where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is potential for machine learning in health care to provide professionals an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.  168  Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of nonlinear hidden units.  169  By 2019, graphics processing units ( GPUs ), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI.  170  OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.  171   172  Tensor Processing Units (TPUs) are specialised hardware accelerators developed by Google specifically for machine learning workloads. Unlike general-purpose GPUs and FPGAs , TPUs are optimised for tensor computations, making them particularly efficient for deep learning tasks such as training and inference. They are widely used in Google Cloud AI services and large-scale machine learning models like Google's DeepMind AlphaFold and large language models. TPUs leverage matrix multiplication units and high-bandwidth memory to accelerate computations while maintaining energy efficiency.  173  Since their introduction in 2016, TPUs have become a key component of AI infrastructure, especially in cloud-based environments. Neuromorphic computing refers to a class of computing systems designed to emulate the structure and functionality of biological neural networks. These systems may be implemented through software-based simulations on conventional hardware or through specialised hardware architectures.  174  A physical neural network is a specific type of neuromorphic hardware that relies on electrically adjustable materials, such as memristors, to emulate the function of neural synapses . The term ""physical neural network"" highlights the use of physical hardware for computation, as opposed to software-based implementations. It broadly refers to artificial neural networks that use materials with adjustable resistance to replicate neural synapses.  175   176  Embedded machine learning is a sub-field of machine learning where models are deployed on embedded systems with limited computing resources, such as wearable computers , edge devices and microcontrollers .  177   178   179   180  Running models directly on these devices eliminates the need to transfer and store data on cloud servers for further processing, thereby reducing the risk of data breaches, privacy leaks and theft of intellectual property, personal data and business secrets. Embedded machine learning can be achieved through various techniques, such as hardware acceleration ,  181   182  approximate computing ,  183  and model optimisation.  184   185  Common optimisation techniques include pruning , quantisation , knowledge distillation , low-rank factorisation, network architecture search, and parameter sharing. Software suites containing a variety of machine learning algorithms include the following:",8814
https://simple.wikipedia.org/wiki/Machine_learning,"Machine learning - Simple English Wikipedia, the free encyclopedia","Machine learning gives computers the ability to learn without being explicitly programmed ( Arthur Samuel , 1959).  1   2  It is a subfield of computer science .  3  The idea came from work in artificial intelligence .  4  Machine learning explores the study and construction of algorithms which can learn and make predictions on data .  5  Such algorithms follow programmed instructions , but can also make predictions or decisions based on data.  6  : 2 They build a model from sample inputs. Machine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering , detection of artificial neural network intruders or malicious insiders working towards a data breach,  7  optical character recognition (OCR),  8  search engines and computer vision . Using machine learning has risks. Some algorithms create a final model which is a black box .  9  Models have been criticized for biases in hiring,  10  criminal justice,  11  and recognizing faces.  12  Learning algorithms try to predict what will happen in the future with patterns from the past. These predictions can be obvious: for example, if the sun rose for the past 10,000 days, it will probably rise again. These predictions can also be more complex. An example of a complex prediction is facial recognition (knowing who someone is by looking at face). Machine learning programs can do things that it hasn't been told to do by a programmer . Machine learning programs will be shown some patterns. These patterns will be an input (such as a question) and an output (the answer to the question). Then, the machine learning program will predict the output based on the input. Machine learning isn't always necessary. Computers can do simple tasks by being told instructions. However, sometimes there are a lot of things that control the output. Then, it is hard for a human to tell the computer all of the instructions. It is sometimes easier to tell the computer how to teach itself.  13  There are a lot of different ways to tell the computer to teach itself. When a problem has a lot of answers, different answers can be marked as valid. This is used to form data that the computer is trained with. One example of training data is the MNIST data. The MNIST data has images of handwritten numbers. The computer can learn to identify handwritten numbers using the MNIST data.",402
https://en.wikipedia.org/wiki/Artificial_intelligence,Artificial intelligence - Wikipedia," Artificial intelligence ( AI ) is the capability of computational systems to perform tasks typically associated with human intelligence , such as learning , reasoning , problem-solving , perception , and decision-making . It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.  1  High-profile applications of AI include advanced web search engines (e.g., Google Search ); recommendation systems (used by YouTube , Amazon , and Netflix ); virtual assistants (e.g., Google Assistant , Siri , and Alexa ); autonomous vehicles (e.g., Waymo ); generative and creative tools (e.g., language models and AI art ); and superhuman play and analysis in strategy games (e.g., chess and Go ). However, many AI applications are not perceived as AI: ""A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore .""  2   3  Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning , knowledge representation , planning , natural language processing , perception , and support for robotics .  a  To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization , formal logic , artificial neural networks , and methods based on statistics , operations research , and economics .  b  AI also draws upon psychology , linguistics , philosophy , neuroscience , and other fields.  4  Some companies, such as OpenAI , Google DeepMind and Meta ,  5  aim to create artificial general intelligence (AGI)AI that can complete virtually any cognitive task at least as well as a human. Artificial intelligence was founded as an academic discipline in 1956,  6  and the field went through multiple cycles of optimism throughout its history ,  7   8  followed by periods of disappointment and loss of funding, known as AI winters .  9   10  Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks and deep learning outperformed previous AI techniques.  11  This growth accelerated further after 2017 with the transformer architecture .  12  In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom . Generative AI's ability to create and modify content has led to several unintended consequences and harms, which has raised ethical concerns about AI's long-term effects and potential existential risks , prompting discussions about regulatory policies to ensure the safety and benefits of the technology. The general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.  a  Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions .  13  By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics .  14  Many of these algorithms are insufficient for solving large reasoning problems because they experience a ""combinatorial explosion"": They become exponentially slower as the problems grow.  15  Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.  16  Accurate and efficient reasoning is an unsolved problem. Knowledge representation and knowledge engineering  17  allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,  18  scene interpretation,  19  clinical decision support,  20  knowledge discovery (mining ""interesting"" and actionable inferences from large databases ),  21  and other areas.  22  A knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge.  23  Knowledge bases need to represent things such as objects, properties, categories, and relations between objects;  24  situations, events, states, and time;  25  causes and effects;  26  knowledge about knowledge (what we know about what other people know);  27  default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing);  28  and many other aspects and domains of knowledge. Among the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous);  29  and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as ""facts"" or ""statements"" that they could express verbally).  16  There is also the difficulty of knowledge acquisition , the problem of obtaining knowledge for AI applications.  c  An ""agent"" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen.  d   32  In automated planning , the agent has a specific goal.  33  In automated decision-making , the agent has preferencesthere are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the "" utility "") that measures how much the agent prefers it. For each possible action, it can calculate the "" expected utility "": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.  34  In classical planning , the agent knows exactly what the effect of any action will be.  35  In most real-world problems, however, the agent may not be certain about the situation they are in (it is ""unknown"" or ""unobservable"") and it may not know for certain what will happen after each possible action (it is not ""deterministic""). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.  36  In some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning ), or the agent can seek information to improve its preferences.  37  Information value theory can be used to weigh the value of exploratory or experimental actions.  38  The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be. A Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration ), be heuristic , or it can be learned.  39  Game theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.  40  Machine learning is the study of programs that can improve their performance on a given task automatically.  41  It has been a part of AI from the beginning.  e  There are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance.  44  Supervised learning requires labeling the training data with the expected answers, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).  45  In reinforcement learning , the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as ""good"".  46  Transfer learning is when the knowledge gained from one problem is applied to a new problem.  47  Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.  48  Computational learning theory can assess learners by computational complexity , by sample complexity (how much data is required), or by other notions of optimization .  49  Natural language processing (NLP) allows programs to read, write and communicate in human languages.  50  Specific problems include speech recognition , speech synthesis , machine translation , information extraction , information retrieval and question answering .  51  Early work, based on Noam Chomsky 's generative grammar and semantic networks , had difficulty with word-sense disambiguation  f  unless restricted to small domains called "" micro-worlds "" (due to the common sense knowledge problem  29  ). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure. Modern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning),  52  transformers (a deep learning architecture using an attention mechanism),  53  and others.  54  In 2019, generative pre-trained transformer (or ""GPT"") language models began to generate coherent text,  55   56  and by 2023, these models were able to get human-level scores on the bar exam , SAT test, GRE test, and many other real-world applications.  57  Machine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar , sonar, radar, and tactile sensors ) to deduce aspects of the world. Computer vision is the ability to analyze visual input.  58  The field includes speech recognition ,  59  image classification ,  60  facial recognition , object recognition ,  61  object tracking ,  62  and robotic perception .  63  Affective computing is a field that comprises systems that recognize, interpret, process, or simulate human feeling, emotion, and mood .  65  For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate humancomputer interaction . However, this tends to give nave users an unrealistic conception of the intelligence of existing computer agents.  66  Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis , wherein AI classifies the effects displayed by a videotaped subject.  67  A machine with artificial general intelligence would be able to solve a wide variety of problems with breadth and versatility similar to human intelligence .  68  AI research uses a wide variety of techniques to accomplish the goals above.  b  AI can solve many problems by intelligently searching through many possible solutions.  69  There are two very different kinds of search used in AI: state space search and local search . State space search searches through a tree of possible states to try to find a goal state.  70  For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis .  71  Simple exhaustive searches  72  are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers . The result is a search that is too slow or never completes.  15  "" Heuristics "" or ""rules of thumb"" can help prioritize choices that are more likely to reach a goal.  73  Adversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and countermoves, looking for a winning position.  74  Local search uses mathematical optimization to find a solution to a problem. It begins with some form of guess and refines it incrementally.  75  Gradient descent is a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize a loss function . Variants of gradient descent are commonly used to train neural networks ,  76  through the backpropagation algorithm. Another type of local search is evolutionary computation , which aims to iteratively improve a set of candidate solutions by ""mutating"" and ""recombining"" them, selecting only the fittest to survive each generation.  77  Distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking ) and ant colony optimization (inspired by ant trails ).  78  Formal logic is used for reasoning and knowledge representation .  79  Formal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as ""and"", ""or"", ""not"" and ""implies"")  80  and predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as "" Every X is a Y "" and ""There are some X s that are Y s"").  81  Deductive reasoning in logic is the process of proving a new statement ( conclusion ) from other statements that are given and assumed to be true (the premises ).  82  Proofs can be structured as proof trees , in which nodes are labelled by sentences, and children nodes are connected to parent nodes by inference rules . Given a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whose leaf nodes are labelled by premises or axioms . In the case of Horn clauses , problem-solving search can be performed by reasoning forwards from the premises or backwards from the problem.  83  In the more general case of the clausal form of first-order logic , resolution is a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved.  84  Inference in both Horn clause logic and first-order logic is undecidable , and therefore intractable . However, backward reasoning with Horn clauses, which underpins computation in the logic programming language Prolog , is Turing complete . Moreover, its efficiency is competitive with computation in other symbolic programming languages.  85  Fuzzy logic assigns a ""degree of truth"" between 0 and 1. It can therefore handle propositions that are vague and partially true.  86  Non-monotonic logics , including logic programming with negation as failure , are designed to handle default reasoning .  28  Other specialized versions of logic have been developed to describe many complex domains. Many problems in AI (including reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.  87  Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory , decision analysis ,  88  and information value theory .  89  These tools include models such as Markov decision processes ,  90  dynamic decision networks ,  91  game theory and mechanism design .  92  Bayesian networks  93  are a tool that can be used for reasoning (using the Bayesian inference algorithm),  g   95  learning (using the expectationmaximization algorithm ),  h   97  planning (using decision networks )  98  and perception (using dynamic Bayesian networks ).  91  Probabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g., hidden Markov models or Kalman filters ).  91  The simplest AI applications can be divided into two types: classifiers (e.g., ""if shiny then diamond""), on one hand, and controllers (e.g., ""if diamond then pick up""), on the other hand. Classifiers  99  are functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning . Each pattern (also called an "" observation "") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set . When a new observation is received, that observation is classified based on previous experience.  45  There are many kinds of classifiers in use.  100  The decision tree is the simplest and most widely used symbolic machine learning algorithm.  101  K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.  102  The naive Bayes classifier is reportedly the ""most widely used learner""  103  at Google, due in part to its scalability.  104  Neural networks are also used as classifiers.  105  An artificial neural network is based on a collection of nodes also known as artificial neurons , which loosely model the neurons in a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the weight crosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers.  105  Learning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.  106  Neural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.  107  In feedforward neural networks the signal passes in only one direction.  108  The term perceptron typically refers to a single-layer neural network.  109  In contrast, deep learning uses many layers.  110  Recurrent neural networks (RNNs) feed the output signal back into the input, which allows short-term memories of previous input events. Long short-term memory networks (LSTMs) are recurrent neural networks that better preserve longterm dependencies and are less sensitive to the vanishing gradient problem .  111  Convolutional neural networks (CNNs) use layers of kernels to more efficiently process local patterns. This local processing is especially important in image processing , where the early CNN layers typically identify simple local patterns such as edges and curves, with subsequent layers detecting more complex patterns like textures, and eventually whole objects.  112  Deep learning uses several layers of neurons between the network's inputs and outputs.  110  The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing , lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces.  114  Deep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, including computer vision , speech recognition , natural language processing , image classification ,  115  and others. The reason that deep learning performs so well in so many applications is not known as of 2021.  116  The sudden success of deep learning in 20122015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)  i  but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs ) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet .  j  Generative pre-trained transformers (GPT) are large language models (LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pre-trained on a large corpus of text that can be from the Internet. The pretraining consists of predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are prone to generating falsehoods called "" hallucinations "". These can be reduced with RLHF and quality data, but the problem has been getting worse for reasoning systems.  124  Such systems are used in chatbots , which allow people to ask a question or request a task in simple text.  125   126  Current models and services include ChatGPT , Claude , Gemini , Copilot , and Meta AI .  127  Multimodal GPT models can process different types of data ( modalities ) such as images, videos, sound, and text.  128  In the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training.  129  Specialized programming languages such as Prolog were used in early AI research,  130  but general-purpose programming languages like Python have become predominant.  131  The transistor density in integrated circuits has been observed to roughly double every 18 monthsa trend known as Moore's law , named after the Intel co-founder Gordon Moore , who first identified it. Improvements in GPUs have been even faster,  132  a trend sometimes called Huang's law ,  133  named after Nvidia co-founder and CEO Jensen Huang . AI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search ), targeting online advertisements , recommendation systems (offered by Netflix , YouTube or Amazon ), driving internet traffic , targeted advertising ( AdSense , Facebook ), virtual assistants (such as Siri or Alexa ), autonomous vehicles (including drones , ADAS and self-driving cars ), automatic language translation ( Microsoft Translator , Google Translate ), facial recognition ( Apple 's FaceID or Microsoft 's DeepFace and Google 's FaceNet ) and image labeling (used by Facebook , Apple's Photos and TikTok ). The deployment of AI may be overseen by a chief automation officer (CAO). The application of AI in medicine and medical research has the potential to increase patient care and quality of life.  134  Through the lens of the Hippocratic Oath , medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients.  135   136  For medical research, AI is an important tool for processing and integrating big data . This is particularly important for organoid and tissue engineering development which use microscopy imaging as a key technique in fabrication.  137  It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research.  137   138  New AI tools can deepen the understanding of biomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein .  139  In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria.  140  In 2024, researchers used machine learning to accelerate the search for Parkinson's disease drug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of alpha-synuclein (the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold.  141   142  Game playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques.  143  Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov , on 11 May 1997.  144  In 2011, in a Jeopardy! quiz show exhibition match, IBM 's question answering system , Watson , defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings , by a significant margin.  145  In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol , becoming the first computer Go -playing system to beat a professional Go player without handicaps . Then, in 2017, it defeated Ke Jie , who was the best Go player in the world.  146  Other programs handle imperfect-information games, such as the poker -playing program Pluribus .  147  DeepMind developed increasingly generalistic reinforcement learning models, such as with MuZero , which could be trained to play chess, Go, or Atari games.  148  In 2019, DeepMind's AlphaStar achieved grandmaster level in StarCraft II , a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map.  149  In 2021, an AI agent competed in a PlayStation Gran Turismo competition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning.  150  In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseen open-world video games by observing screen output, as well as executing short, specific tasks in response to natural language instructions.  151  Large language models, such as GPT-4 , Gemini , Claude , Llama or Mistral , are increasingly used in mathematics. These probabilistic models are versatile, but can also produce wrong answers in the form of hallucinations . They sometimes need a large database of mathematical problems to learn from, but also methods such as supervised fine-tuning  152  or trained classifiers with human-annotated data to improve answers for new problems and learn from corrections.  153  A February 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data.  154  One technique to improve their performance involves training the models to produce correct reasoning steps, rather than just the correct result.  155  The Alibaba Group developed a version of its Qwen models called Qwen2-Math , that achieved state-of-the-art performance on several mathematical benchmarks, including 84 accuracy on the MATH dataset of competition mathematics problems.  156  In January 2025, Microsoft proposed the technique rStar-Math that leverages Monte Carlo tree search and step-by-step reasoning, enabling a relatively small language model like Qwen-7B to solve 53 of the AIME 2024 and 90 of the MATH benchmark problems.  157  Alternatively, dedicated models for mathematical problem solving with higher precision for the outcome including proof of theorems have been developed such as AlphaTensor , AlphaGeometry , AlphaProof and AlphaEvolve  158  all from Google DeepMind ,  159  Llemma from EleutherAI  160  or Julius .  161  When natural language is used to describe mathematical problems, converters can transform such prompts into a formal language such as Lean to define mathematical tasks. The experimental model Gemini Deep Think accepts natural language prompts directly and achieved gold medal results in the International Math Olympiad of 2025.  162  Some models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics.  163  Topological deep learning integrates various topological approaches. Finance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated ""robot advisers"" have been in use for some years.  164  According to Nicolas Firzli, director of the World Pensions  Investments Forum , it may be too early to see the emergence of highly innovative AI-informed financial products and services. He argues that ""the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I'm not sure it will unleash a new wave of e.g., sophisticated pension innovation.""  165  Various countries are deploying AI military applications.  166  The main applications enhance command and control , communications, sensors, integration and interoperability.  167  Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles .  166  AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition , coordination and deconfliction of distributed Joint Fires between networked combat vehicles, both human-operated and autonomous .  167  AI has been used in military operations in Iraq, Syria, Israel and Ukraine.  166   168   169   170  Generative artificial intelligence (Generative AI, GenAI,  171  or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images , videos , audio , software code or other forms of data.  172   173  These models learn the underlying patterns and structures of their training data and use them to produce new data  174   175  based on the input, which often comes in the form of natural language prompts .  176   177  Generative AI tools have become more common since the AI boom in the 2020s. This boom was made possible by improvements in transformer -based deep neural networks , particularly large language models (LLMs). Major tools include chatbots such as ChatGPT , Copilot , Gemini , Claude , Grok , and DeepSeek ; text-to-image models such as Stable Diffusion , Midjourney , and DALL-E ; and text-to-video models such as Veo and Sora .  178   179   180  Technology companies developing generative AI include OpenAI , xAI , Anthropic , Meta AI , Microsoft , Google , Mistral AI , DeepSeek , Baidu  181  and Yandex .  182  AI agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, including virtual assistants , chatbots , autonomous vehicles , game-playing systems , and industrial robotics . AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks.  193   194   195  Microsoft introduced Copilot Search in February 2023 under the name Bing Chat , as a built-in feature for Microsoft Edge and Bing mobile app. Copilot Search provides AI-generated summaries  196  and step-by-step reasoning based of information from web publishers, ranked in Bing Search.  197  For safety, Copilot uses AI-based classifiers and filters to reduce potentially harmful content.  198  Google officially pushed its AI Search at its Google IO event on 20 May 2025.  199  It keeps people looking at Google instead of clicking on a search result. AI Overviews uses Gemini 2.5 to provide contextual answers to user queries based on web content.  200  Applications of AI in this domain include AI-enabled menstruation and fertility trackers that analyze user data to offer predictions,  201  AI-integrated sex toys (e.g., teledildonics ),  202  AI-generated sexual education content,  203  and AI agents that simulate sexual and romantic partners (e.g., Replika ).  204  AI is also used for the production of non-consensual deepfake pornography , raising significant ethical and legal concerns.  205  AI technologies have also been used to attempt to identify online gender-based violence and online sexual grooming of minors.  206   207  There are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated ""AI"" in some offerings or processes.  208  A few examples are energy storage , medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy , or supply chain management. AI applications for evacuation and disaster management are growing. AI has been used to investigate patterns in large-scale and small-scale evacuations using historical data from GPS, videos or social media. Furthermore, AI can provide real-time information on the evacuation conditions.  209   210   211  In agriculture, AI has helped farmers to increase yield and identify areas that need irrigation, fertilization, pesticide treatments. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics , classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water. Artificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for ""classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights."" For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation. During the 2024 Indian elections , US50 million was spent on authorized AI-generated content, notably by creating deepfakes of allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages.  212  AI has potential benefits and potential risks.  215  AI may be able to advance science and find solutions for serious problems: Demis Hassabis of DeepMind hopes to ""solve intelligence, and then use that to solve everything else"".  216  However, as the use of AI has become widespread, several unintended consequences and risks have been identified.  217   218  In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning.  219  Machine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy , surveillance and copyright . AI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI's ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency. Sensitive user data collected may include online activity records, geolocation data, video, or audio.  220  For example, in order to build speech recognition algorithms, Amazon has recorded millions of private conversations and allowed temporary workers to listen to and transcribe some of them.  221  Opinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy .  222  AI developers argue that this is the only way to deliver valuable applications and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation , de-identification and differential privacy .  223  Since 2016, some privacy experts, such as Cynthia Dwork , have begun to view privacy in terms of fairness . Brian Christian wrote that experts have pivoted ""from the question of 'what they know' to the question of 'what they're doing with it'.""  224  Generative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of "" fair use "". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include ""the purpose and character of the use of the copyrighted work"" and ""the effect upon the potential market for the copyrighted work"".  225   226  Website owners who do not wish to have their content scraped can indicate it in a "" robots.txt "" file.  227  In 2023, leading authors (including John Grisham and Jonathan Franzen ) sued AI companies for using their work to train generative AI.  228   229  Another discussed approach is to envision a separate sui generis system of protection for creations generated by AI to ensure fair attribution and compensation for human authors.  230  The commercial AI scene is dominated by Big Tech companies such as Alphabet Inc. , Amazon , Apple Inc. , Meta Platforms , and Microsoft .  231   232   233  Some of these players already own the vast majority of existing cloud infrastructure and computing power from data centers , allowing them to entrench further in the marketplace.  234   235  In January 2024, the International Energy Agency (IEA) released Electricity 2024, Analysis and Forecast to 2026 , forecasting electric power use.  236  This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation.  237  Prodigious power consumption by AI is responsible for the growth of fossil fuel use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources  from nuclear energy to geothermal to fusion. The tech firms argue that  in the long view  AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and ""intelligent"", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms.  238  A 2024 Goldman Sachs Research Paper, AI Data Centers and the Coming US Power Demand Surge , found ""US power demand (is) likely to experience growth not seen in a generation...."" and forecasts that, by 2030, US data centers will consume 8 of US power, as opposed to 3 in 2022, presaging growth for the electrical power generation industry by a variety of means.  239  Data centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all.  240  In 2024, the Wall Street Journal reported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for US650 million.  241  Nvidia CEO Jensen Huang said nuclear power is a good option for the data centers.  242  In September 2024, Microsoft announced an agreement with Constellation Energy to re-open the Three Mile Island nuclear power plant to provide Microsoft with 100 of all electric power produced by the plant for 20 years. Reopening the plant, which suffered a partial nuclear meltdown of its Unit 2 reactor in 1979, will require Constellation to get through strict regulatory processes which will include extensive safety scrutiny from the US Nuclear Regulatory Commission . If approved (this will be the first ever US re-commissioning of a nuclear plant), over 835 megawatts of power  enough for 800,000 homes  of energy will be produced. The cost for re-opening and upgrading is estimated at US1.6 billion and is dependent on tax breaks for nuclear power contained in the 2022 US Inflation Reduction Act .  243  The US government and the state of Michigan are investing almost US2 billion to reopen the Palisades Nuclear reactor on Lake Michigan. Closed since 2022, the plant is planned to be reopened in October 2025. The Three Mile Island facility will be renamed the Crane Clean Energy Center after Chris Crane, a nuclear proponent and former CEO of Exelon who was responsible for Exelon's spinoff of Constellation.  244  After the last approval in September 2023, Taiwan suspended the approval of data centers north of Taoyuan with a capacity of more than 5 MW in 2024, due to power supply shortages.  245  Taiwan aims to phase out nuclear power by 2025.  245  On the other hand, Singapore imposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban.  245  Although most nuclear plants in Japan have been shut down after the 2011 Fukushima nuclear accident , according to an October 2024 Bloomberg article in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near a nuclear power plant for a new data center for generative AI.  246  Ubitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI.  246  On 1 November 2024, the Federal Energy Regulatory Commission (FERC) rejected an application submitted by Talen Energy for approval to supply some electricity from the nuclear power station Susquehanna to Amazon's data center.  247  According to the Commission Chairman Willie L. Phillips , it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors.  247  In 2025, a report prepared by the International Energy Agency estimated the greenhouse gas emissions from the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300500 million tonnes depending on what measures will be taken. This is below 1.5 of the energy sector emissions. The emissions reduction potential of AI was estimated at 5 of the energy sector emissions, but rebound effects (for example if people switch from public transport to autonomous cars) can reduce it.  248  YouTube , Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation , conspiracy theories , and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation.  249  This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.  250  The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took some steps to mitigate the problem.  251  In the early 2020s, generative AI began to create images, audio, and texts that are virtually indistinguishable from real photographs, recordings, or human writing,  252  while realistic AI-generated videos became feasible in the mid-2020s.  253   254   255  It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda;  256  one such potential malicious use is deepfakes for computational propaganda .  257  AI pioneer Geoffrey Hinton expressed concern about AI enabling ""authoritarian leaders to manipulate their electorates"" on a large scale, among other risks.  258  AI researchers at Microsoft , OpenAI , universities and other organisations have suggested using "" personhood credentials "" as a way to overcome online deception enabled by AI models.  259  Machine learning applications can be biased  k  if they learn from biased data.  261  The developers may not be aware that the bias exists.  262  Discriminatory behavior by some LLMs can be observed in their output.  263  Bias can be introduced by the way training data is selected and by the way a model is deployed.  264   261  If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine , finance , recruitment , housing or policing ) then the algorithm may cause discrimination .  265  The field of fairness studies how to prevent harms from algorithmic biases. On 28 June 2015, Google Photos 's new image labeling feature mistakenly identified Jacky Alcine and a friend as ""gorillas"" because they were black. The system was trained on a dataset that contained very few images of black people,  266  a problem called ""sample size disparity"".  267  Google ""fixed"" this problem by preventing the system from labelling anything as a ""gorilla"". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.  268  COMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist . In 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61, the errors for each race were differentthe system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.  269  In 2017, several researchers  l  showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.  271  A program can make biased decisions even if the data does not explicitly mention a problematic feature (such as ""race"" or ""gender""). The feature will correlate with other features (like ""address"", ""shopping history"" or ""first name""), and the program will make the same decisions based on these features as it would on ""race"" or ""gender"".  272  Moritz Hardt said ""the most robust fact in this research area is that fairness through blindness doesn't work.""  273  Criticism of COMPAS highlighted that machine learning models are designed to make ""predictions"" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions as recommendations , some of these ""recommendations"" will likely be racist.  274  Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is descriptive rather than prescriptive.  m  Bias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4 are black and 20 are women.  267  There are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category is distributive fairness , which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negative stereotypes or render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict with anti-discrimination laws .  260  At its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022), the Association for Computing Machinery , in Seoul, South Korea, presented and published findings that recommend that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe, and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.  dubious  discuss   276  Many AI systems are so complex that their designers cannot explain how they reach their decisions.  277  Particularly with deep neural networks , in which there are many non- linear relationships between inputs and outputs. But some popular explainability techniques exist.  278  It is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as ""cancerous"", because pictures of malignancies typically include a ruler to show the scale.  279  Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at ""low risk"" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.  280  People who have been harmed by an algorithm's decision have a right to an explanation.  281  Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists.  n  Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.  282  DARPA established the XAI (""Explainable Artificial Intelligence"") program in 2014 to try to solve these problems.  283  Several approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output.  284  LIME can locally approximate a model's outputs with a simpler, interpretable model.  285  Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned.  286  Deconvolution , DeepDream and other generative methods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning.  287  For generative pre-trained transformers , Anthropic developed a technique based on dictionary learning that associates patterns of neuron activations with human-understandable concepts.  288  Artificial intelligence provides a number of tools that are useful to bad actors , such as authoritarian governments , terrorists , criminals or rogue states . A lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.  o  Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentially weapons of mass destruction .  290  Even when used in conventional warfare, they currently cannot reliably choose targets and could potentially kill an innocent person .  290  In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations ' Convention on Certain Conventional Weapons , however the United States and others disagreed.  291  By 2015, over fifty countries were reported to be researching battlefield robots.  292  AI tools make it easier for authoritarian governments to efficiently control their citizens in several ways. Face and voice recognition allow widespread surveillance . Machine learning , operating this data, can classify potential enemies of the state and prevent them from hiding. Recommendation systems can precisely target propaganda and misinformation for maximum effect. Deepfakes and generative AI aid in producing misinformation. Advanced AI can make authoritarian centralized decision-making more competitive than liberal and decentralized systems such as markets . It lowers the cost and difficulty of digital warfare and advanced spyware .  293  All these technologies have been available since 2020 or earlierAI facial recognition systems are already being used for mass surveillance in China.  294   295  There are many other ways in which AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours.  296  Economists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.  297  In the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that ""we're in uncharted territory"" with AI.  298  A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment , but they generally agree that it could be a net benefit if productivity gains are redistributed .  299  Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47 of U.S. jobs are at ""high risk"" of potential automation, while an OECD report classified only 9 of U.S. jobs as ""high risk"".  p   301  The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.  297  In April 2023, it was reported that 70 of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence.  302   303  Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that ""the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution"" is ""worth taking seriously"".  304  Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.  305  In July 2025, Ford CEO Jim Farley predicted that ""artificial intelligence is going to replace literally half of all white-collar workers in the U.S.""  306  From the early days of the development of artificial intelligence, there have been arguments, for example, those put forward by Joseph Weizenbaum , about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.  307  It has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, "" spell the end of the human race "".  308  This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like ""self-awareness"" (or ""sentience"" or ""consciousness"") and becomes a malevolent character.  q  These sci-fi scenarios are misleading in several ways. First, AI does not require human-like sentience to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of an automated paperclip factory that destroys the world to get more iron for paperclips).  310  Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that ""you can't fetch the coffee if you're dead.""  311  In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is ""fundamentally on our side"".  312  Second, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies , law , government , money and the economy are built on language ; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.  313  Geoffrey Hinton said in 2025 that modern AI is particularly ""good at persuasion"" and getting better all the time. He asks ""Suppose you wanted to invade the capital of the US. Do you have to go there and do it yourself? No. You just have to be good at persuasion.""  314  The opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.  315  Personalities such as Stephen Hawking , Bill Gates , and Elon Musk ,  316  as well as AI pioneers such as Yoshua Bengio , Stuart Russell , Demis Hassabis , and Sam Altman , have expressed concerns about existential risk from AI. In May 2023, Geoffrey Hinton announced his resignation from Google in order to be able to ""freely speak out about the risks of AI"" without ""considering how this impacts Google"".  317  He notably mentioned risks of an AI takeover ,  318  and stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI.  319  In 2023, many leading AI experts endorsed the joint statement that ""Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war"".  320  Some other researchers were more optimistic. AI pioneer Jrgen Schmidhuber did not sign the joint statement, emphasising that in 95 of all cases, AI research is about making ""human lives longer and healthier and easier.""  321  While the tools that are now being used to improve lives can also be used by bad actors, ""they can also be used against the bad actors.""  322   323  Andrew Ng also argued that ""it's a mistake to fall for the doomsday hype on AIand that regulators who do will only benefit vested interests.""  324  Yann LeCun ""scoffs at his peers' dystopian scenarios of supercharged misinformation and even, eventually, human extinction.""  325  In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.  326  However, after 2016, the study of current and future risks and possible solutions became a serious area of research.  327  Friendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky , who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.  328  Machines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.  329  The field of machine ethics is also called computational morality,  329  and was founded at an AAAI symposium in 2005.  330  Other approaches include Wendell Wallach 's ""artificial moral agents""  331  and Stuart J. Russell 's three principles for developing provably beneficial machines.  332  Active organizations in the AI open-source community include Hugging Face ,  333  Google ,  334  EleutherAI and Meta .  335  Various AI models, such as Llama 2 , Mistral or Stable Diffusion , have been made open-weight,  336   337  meaning that their architecture and trained parameters (the ""weights"") are publicly available. Open-weight models can be freely fine-tuned , which allows companies to specialize them with their own data and for their own use-case.  338  Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitate bioterrorism ) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses.  339  Artificial intelligence projects can be guided by ethical considerations during the design, development, and implementation of an AI system. An AI framework such as the Care and Act Framework, developed by the Alan Turing Institute and based on the SUM values, outlines four main ethical dimensions, defined as follows:  340   341  Other developments in ethical frameworks include those decided upon during the Asilomar Conference , the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others;  342  however, these principles are not without criticism, especially regarding the people chosen to contribute to these frameworks.  343  Promotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.  344  The UK AI Safety Institute released in 2024 a testing toolset called 'Inspect' for AI safety evaluations available under an MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities.  345  The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms.  346  The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.  347  According to AI Index at Stanford , the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.  348   349  Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.  350  Most EU member states had released national AI strategies, as had Canada , China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.  350  The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.  350  Henry Kissinger , Eric Schmidt , and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.  351  In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years.  352  In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, government officials and academics.  353  On 1 August 2024, the EU Artificial Intelligence Act entered into force, establishing the first comprehensive EU-wide AI regulation.  354  In 2024, the Council of Europe created the first international legally binding treaty on AI, called the "" Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law "". It was adopted by the European Union, the United States, the United Kingdom, and other signatories.  355  In a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78 of Chinese citizens, but only 35 of Americans, agreed that ""products and services using AI have more benefits than drawbacks"".  348  A 2023 Reuters Ipsos poll found that 61 of Americans agree, and 22 disagree, that AI poses risks to humanity.  356  In a 2023 Fox News poll, 35 of Americans thought it ""very important"", and an additional 41 thought it ""somewhat important"", for the federal government to regulate AI, versus 13 responding ""not very important"" and 8 responding ""not at all important"".  357   358  In November 2023, the first global AI Safety Summit was held in Bletchley Park in the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.  359  28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence.  360   361  In May 2024 at the AI Seoul Summit , 16 global AI tech companies agreed to safety commitments on the development of AI.  362   363  The study of mechanical or ""formal"" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing 's theory of computation , which suggested that a machine, by shuffling symbols as simple as ""0"" and ""1"", could simulate any conceivable form of mathematical reasoning.  365   366  This, along with concurrent discoveries in cybernetics , information theory and neurobiology , led researchers to consider the possibility of building an ""electronic brain"".  r  They developed several areas of research that would become part of AI,  368  such as McCulloch and Pitts design for ""artificial neurons"" in 1943,  117  and Turing's influential 1950 paper ' Computing Machinery and Intelligence ', which introduced the Turing test and showed that ""machine intelligence"" was plausible.  369   366  The field of AI research was founded at a workshop at Dartmouth College in 1956.  s   6  The attendees became the leaders of AI research in the 1960s.  t  They and their students produced programs that the press described as ""astonishing"":  u  computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English.  v   7  Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s.  366  Researchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field.  373  In 1965 Herbert Simon predicted, ""machines will be capable, within twenty years, of doing any work a man can do"".  374  In 1967 Marvin Minsky agreed, writing that ""within a generation ... the problem of creating 'artificial intelligence' will substantially be solved"".  375  They had, however, underestimated the difficulty of the problem.  w  In 1974, both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill  377  and ongoing pressure from the U.S. Congress to fund more productive projects .  378  Minsky and Papert 's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether.  379  The "" AI winter "", a period when obtaining funding for AI projects was difficult, followed.  9  In the early 1980s, AI research was revived by the commercial success of expert systems ,  380  a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research .  8  However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.  10  Up to this point, most of AI's funding had gone to projects that used high-level symbols to represent mental objects like plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially perception , robotics , learning and pattern recognition ,  381  and began to look into ""sub-symbolic"" approaches.  382  Rodney Brooks rejected ""representation"" in general and focussed directly on engineering machines that move and survive.  x  Judea Pearl , Lotfi Zadeh , and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.  87   387  But the most important development was the revival of "" connectionism "", including neural network research, by Geoffrey Hinton and others.  388  In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.  389  AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This "" narrow "" and ""formal"" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics , economics and mathematics ).  390  By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as ""artificial intelligence"" (a tendency known as the AI effect ).  391  However, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or ""AGI""), which had several well-funded institutions by the 2010s.  68  Deep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.  11  For many specific tasks, other methods were abandoned.  y  Deep learning's success was based on both hardware improvements ( faster computers ,  393  graphics processing units , cloud computing  394  ) and access to large amounts of data  395  (including curated datasets,  394  such as ImageNet ). Deep learning's success led to an enormous increase in interest and funding in AI.  z  The amount of machine learning research (measured by total publications) increased by 50 in the years 20152019.  350  In 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.  327  In the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo , developed by DeepMind , beat the world champion Go player . The program taught only the game's rules and developed a strategy by itself. GPT-3 is a large language model that was released in 2020 by OpenAI and is capable of generating high-quality human-like text.  396  ChatGPT , launched on 30 November 2022, became the fastest-growing consumer software application in history, gaining over 100 million users in two months.  397  It marked what is widely regarded as AI's breakout year, bringing it into the public consciousness.  398  These programs, and others, inspired an aggressive AI boom , where large companies began investing billions of dollars in AI research. According to AI Impacts, about US50 billion annually was invested in ""AI"" around 2022 in the U.S. alone and about 20 of the new U.S. Computer Science PhD graduates have specialized in ""AI"".  399  About 800,000 ""AI""-related U.S. job openings existed in 2022.  400  According to PitchBook research, 22 of newly funded startups in 2024 claimed to be AI companies.  401  Philosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines.  402  Another major focus has been whether machines can be conscious, and the associated ethical implications.  403  Many other topics in philosophy are relevant to AI, such as epistemology and free will .  404  Rapid advancements have intensified public discussions on the philosophy and ethics of AI .  403  Alan Turing wrote in 1950 ""I propose to consider the question 'can machines think'?""  405  He advised changing the question from whether a machine ""thinks"", to ""whether or not it is possible for machinery to show intelligent behaviour"".  405  He devised the Turing test , which measures the ability of a machine to simulate human conversation.  369  Since we can only observe the behavior of the machine, it does not matter if it is ""actually"" thinking or literally has a ""mind"". Turing notes that we can not determine these things about other people but ""it is usual to have a polite convention that everyone thinks.""  406  Russell and Norvig agree with Turing that intelligence must be defined in terms of external behavior, not internal structure.  1  However, they are critical that the test requires the machine to imitate humans. "" Aeronautical engineering texts"", they wrote, ""do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons. ' ""  408  AI founder John McCarthy agreed, writing that ""Artificial intelligence is not, by definition, simulation of human intelligence"".  409  McCarthy defines intelligence as ""the computational part of the ability to achieve goals in the world"".  410  Another AI founder, Marvin Minsky , similarly describes it as ""the ability to solve hard problems"".  411  The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals.  1  These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the ""intelligence"" of the machineand no other philosophical discussion is required, or may not even be possible. Another definition has been adopted by Google,  412  a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence. As a result of the many circulating definitions scholars have started to critically analyze and order the AI discourse itself  413  including discussing the many AI narratives and myths to be found within societal, political and academic discourses.  414  Similarly, in practice, some authors have suggested that the term 'AI' is often used too broadly and vaguely. This raises the question of where the line should be drawn between AI and classical algorithms,  415  with many companies during the early 2020s AI boom using the term as a marketing buzzword , often even if they did ""not actually use AI in a material way"".  416  There has been debate over whether large language models exhibit genuine intelligence or merely simulate it by imitating human text .  417  No established unifying theory or paradigm has guided AI research for most of its history.  aa  The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term ""artificial intelligence"" to mean ""machine learning with neural networks""). This approach is mostly sub-symbolic , soft and narrow . Critics argue that these questions may have to be revisited by future generations of AI researchers. Symbolic AI (or "" GOFAI "")  419  simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at ""intelligent"" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis : ""A physical symbol system has the necessary and sufficient means of general intelligent action.""  420  However, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning . Moravec's paradox is the discovery that high-level ""intelligent"" tasks were easy for AI, but low level ""instinctive"" tasks were extremely difficult.  421  Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a ""feel"" for the situation, rather than explicit symbolic knowledge.  422  Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.  ab   16  The issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias . Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence,  424   425  in part because sub-symbolic AI is a move away from explainable AI : it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches. ""Neats"" hope that intelligent behavior is described using simple, elegant principles (such as logic , optimization , or neural networks ). ""Scruffies"" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s,  426  but eventually was seen as irrelevant. Modern AI has elements of both. Finding a provably correct or optimal solution is intractable for many important problems.  15  Soft computing is a set of techniques, including genetic algorithms , fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks. AI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals.  427   428  General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively. There is no settled consensus in philosophy of mind on whether a machine can have a mind , consciousness and mental states in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that ""the additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.""  429  However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction . David Chalmers identified two problems in understanding the mind, which he named the ""hard"" and ""easy"" problems of consciousness.  430  The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). While human information processing is easy to explain, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like .  431  Computationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mindbody problem . This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam .  432  Philosopher John Searle characterized this position as "" strong AI "": ""The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.""  ac  Searle challenges this claim with his Chinese room argument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind.  436  It is difficult or impossible to reliably evaluate whether an advanced AI is sentient (has the ability to feel), and if so, to what degree.  437  But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals.  438   439  Sapience (a set of capacities related to high intelligence, such as discernment or self-awareness ) may provide another moral basis for AI rights.  438  Robot rights are also sometimes proposed as a practical way to integrate autonomous agents into society.  440  In 2017, the European Union considered granting ""electronic personhood"" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities.  441  Critics argued in 2018 that granting rights to AI systems would downplay the importance of human rights , and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part in society on their own.  442   443  Progress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a moral blind spot analogous to slavery or factory farming , which could lead to large-scale suffering if sentient AI is created and carelessly exploited.  439   438  A superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.  428  If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself . The improved software would be even better at improving itself, leading to what I. J. Good called an "" intelligence explosion "" and Vernor Vinge called a "" singularity "".  444  However, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve , slowing when they reach the physical limits of what the technology can do.  445  Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines may merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in the writings of Aldous Huxley and Robert Ettinger .  446  Edward Fredkin argues that ""artificial intelligence is the next step in evolution"", an idea first proposed by Samuel Butler 's "" Darwin among the Machines "" as far back as 1863, and expanded upon by George Dyson in his 1998 book Darwin Among the Machines: The Evolution of Global Intelligence .  447  Thought-capable artificial beings have appeared as storytelling devices since antiquity,  448  and have been a persistent theme in science fiction .  449  A common trope in these works began with Mary Shelley 's Frankenstein , where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000 , the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.  450  Isaac Asimov introduced the Three Laws of Robotics in many stories, most notably with the "" Multivac "" super-intelligent computer. Asimov's laws are often brought up during lay discussions of machine ethics;  451  while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.  452  Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel , and thus to suffer. This appears in Karel apek 's R.U.R. , the films A.I. Artificial Intelligence and Ex Machina , as well as the novel Do Androids Dream of Electric Sheep? , by Philip K. Dick . Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.  453  The two most widely used textbooks in 2023 (see the Open Syllabus ): The four most widely used AI textbooks in 2008: Other textbooks:",14000
https://simple.wikipedia.org/wiki/Artificial_intelligence,"Artificial intelligence - Simple English Wikipedia, the free encyclopedia"," Artificial intelligence ( AI or A.I. ) is a computer program or a machine that is able to learn and mimic human cognition .  1   2  Sometimes, AI is used to talk about neural networks or deep learning .  3  Artificial intelligence is a system's ability to understand external data , to learn from that data, and to use what it has learned to achieve specific goals or tasks through adaptation .  4  Artificial intelligence is widely applied in speech recognition , image recognition , robotics , autonomous systems , natural language processing , machine translation , predictive analytics , medical diagnostics , fraud detection , and the control of physical processes . John McCarthy came up with the name, ""artificial intelligence"" in 1956. Intelligence allows an organism to act in a meaningful way in its environment. It includes the ability to get sensory inputs, and to react to these. The European Union made a law (2024's second quarter) about artificial intelligence . It is the world's first law that regulates AI.  5  Connecticut and Colorado tried to pass laws (in 2024) regarding use of AI.  6  AI research started with a conference at Dartmouth College in 1956. It was a month-long brainstorming session many people who like AI came to. At the conference, they wrote programs which were able to beat humans at checkers or solving word problems. The Department of Defense started giving a lot of money to AI research, and labs were created all over the world. In a paper on AI, mathematician James Lighthill wrote "" no aspect of the discipline has so far seen discoveries generated the huge influence that was previously anticipated In no part of the field have the discoveries made so far produced the major impact that was then promised."" 1 . The governments of the US and UK decided to spend money on other projects which caused little new research to be done. This was known as an ""AI winter.""  7  In the 90s and early 2000s, AI became important again in data mining and medical diagnosis. This was possible because of faster computers and focusing on solving more specific problems. In 1997, the chess computer Deep Blue became the first computer program to beat chess world champion Garry Kasparov . In 2011, IBM Watson beat the top two Jeopardy! players Brad Rutter and Ken Jennings . In 2016, Google's AlphaGo beat top Go player Lee Sedol 4 out of 5 times. The idea is perhaps much older. Julien Offray de La Mettrie (1709-1751) was a materialist thinker of the Enlightenment . In his work of 1748, L'Homme Machine, he had the idea that both matter and life organized themselves.  8  He is seen as one of the precursors of Darwin's theory of evolution .  9  Today, one field of artificial intelligence, called strong artificial intelligence wants to build a machine that can think like a person.  10  However, weak artificial intelligence is about building a system that can support a human. One of the key problems is to make systems that can model wikt:uncertainity . Most of the time, this is done with probability theory and statistics . Artificial intelligence is used in many different areas today. Those subjects are part of Game artificial intelligence . Some software has become well-known, such as ChatGPT (a chatbot and virtual assistant ). There are different domains of artificial intelligence. Researchers Kaplan and Haenlein say there are three types of AI system: analytical, human-inspired, and humanized artificial intelligence.  4  In 2025, a municipality in Norway made a report in regard to permanently closing down schools; The report used ghost source (or fictitious sources); Those sources were claimed to be the works of two (named) professors; The municipality admitted that the report was made partly by A.I.; The process of closing down schools, has stopped (as of March).  12  An official that was involved, resigned (or left her job) one month later.  13  (See Hallucination, artificial intelligence ) A.I. chips are a kind of computer chip , according to media.  14   15  Researchers didn't know how difficult several issues were. They still couldn't offer computers things like emotions or common sense . Faster computers, deep learning, and more data have made AI popular throughout the world.  16  An great intelligent machine is flexible and perceives what is around it. It would use what it learns to make its chance of success at some goal better.  17  AI has been successful with decoding human speech ,  1  playing games (like chess and Go ), self-driving cars , and understanding complex data.  18  Someday, AI researchers hope to create computer programs that can learn, solve problems, and think logically.  19   20  So far, most AI programs only do what computers can do well like searching databases or doing calculations. AI is not able to sense and understand what is happening around itself because of problems with what computers can do. AI involves many different fields like computer science , mathematics , linguistics , psychology , neuroscience , and philosophy . Researchers hope to make a ""general artificial intelligence"" which can solve many problems instead of focusing on just one. Researchers are also trying to make creative and emotional AI which could create art. Alan Turing wrote in 1950 ""I propose to consider the question 'can machines think'?""  21  He said the question should be changed from if a machine ""thinks"" to ""whether or not it is possible for machinery to show intelligent behavior"".  21  Alan Turing also created the Turing test . This is a very general test. If a human cannot tell if at the other end of the line, there is a machine or a human answering questions, the machine is intelligent. The authors of Artificial Intelligence: A Modern Approach agree with Turing that AI must be defined by ""acting"" and not ""thinking"".  22  But they don't think the test compares machines to people . "" Aeronautical engineering texts do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons. ' ""  23  AI founder John McCarthy agreed, writing that ""Artificial intelligence is not, by definition, simulation of human intelligence"".  24   25  Computers can do some things like learning and problem solving , but not in the same way as people do.  1  Interestingly, advancements in AI have expanded its applications, including the use of Large language models (LLMs) to ""humanize"" AI-generated text. This reflects a growing interest in bridging the gap between machine outputs and human-like expression.  26  AI and machine learning technology is used in applications including: search engines , recommendation systems , virtual assistants , autonomous vehicles , automatic language translation , facial recognition , image labeling , advertising, and driving internet traffic . One interesting use of AI is in helping people with their personal relationships. For example, ChatGPT is a powerful AI tool that can create human-like text and assist in many communication tasks.  25  Optical character recognition is no longer thought of as an example of ""artificial intelligence"" since it's now commonly used.",1187
https://en.wikipedia.org/wiki/Digital_marketing,Digital marketing - Wikipedia," Digital marketing is the component of marketing that uses the Internet and online -based digital technologies such as desktop computers , mobile phones , and other digital media and platforms to promote products and services.  2   3  It has significantly transformed the way brands and businesses utilize technology for marketing since the 1990s and 2000s. As digital platforms became increasingly incorporated into marketing plans and everyday life,  4  and as people increasingly used digital devices instead of visiting physical shops,  5   6  digital marketing campaigns have become prevalent, employing combinations of methods. Some of these methods include: search engine optimization (SEO), search engine marketing (SEM), content marketing , influencer marketing , content automation, campaign marketing, data -driven marketing, e-commerce marketing, social media marketing , social media optimization , e-mail direct marketing , display advertising , e-books , and optical disks and games. Digital marketing extends to non-Internet channels that provide digital media, such as television , mobile phones ( SMS and MMS ), callbacks, and on-hold mobile ringtones.  7  The extension to non-Internet channels differentiates digital marketing from online marketing .  8  Digital marketing effectively began in 1990 when the Archie search engine was created as an index for FTP sites. In the 1980s, the storage capacity of computers was already large enough to store huge volumes of customer information. Companies started choosing online techniques, such as database marketing , rather than limited list brokers .  9  Databases allowed companies to track customers' information more effectively, transforming the relationship between buyer and seller. In the 1990s, the term digital marketing was coined.  citation needed  The first clickable banner ad , the ""You Will"" campaign by ATT , went live in 1994, and over the first four months, 44 of all people who saw it clicked on the ad.  10   11  Early digital marketing efforts focused on simple HTML websites and the burgeoning practice of email marketing, which allowed for direct communication with consumers.  12  In the 2000s, with increasing numbers of Internet users and the birth of the iPhone , customers began searching for products and making decisions about their needs online first, instead of consulting a salesperson , which created a new problem for the marketing department of a company.  13  In addition, a survey in 2000 in the United Kingdom found that most retailers still needed to register their own domain address.  14  These problems encouraged marketers to find new ways to integrate digital technology into market development. At the same time, pay-per-click (PPC) advertising, introduced by Google AdWords in 2000, allowed businesses to target specific keywords, making digital marketing more measurable and cost-effective.  15  The mid-2000s saw the emergence of social media platforms like Facebook (2004), YouTube (2005), and Twitter (2006). These platforms revolutionized digital marketing by facilitating direct and interactive engagement with consumers. In 2007, marketing automation was developed as a response to the ever-evolving marketing climate. Marketing automation is the process by which software is used to automate conventional marketing processes.  16  Marketing automation helps companies segment customers, launch multichannel marketing campaigns, and provide personalized information for customers.,  16  based on their specific activities. In this way, users' activity (or lack thereof) triggers a personal message that is customized to the user in their preferred platform. However, despite the benefits of marketing automation many companies are struggling to adapt it to their everyday uses correctly.  17   page needed  Digital marketing became more sophisticated in the 2000s and the 2010s, when  18   19  the proliferation of devices capable of accessing digital media led to sudden growth.  20  Statistics produced in 2012 and 2013 showed that digital marketing was still growing.  21   22  With the development of social media in the 2000s, such as LinkedIn , Facebook , YouTube , and Twitter , consumers became highly dependent on digital electronics in their daily lives. Therefore, they expected a seamless user experience across different channels for searching product information. The change in customer behavior improved the diversification of marketing technology.  23  Digital media growth was estimated at 4.5 trillion online ads served annually with digital media spending at 48 growth in 2010.  24  An increasing portion of advertising stems from businesses employing Online Behavioural Advertising (OBA) to tailor advertising for internet users, but OBA raises concerns about consumer privacy and data protection .  20  Nonlinear marketing, a type of interactive marketing, is a long-term marketing approach that builds on businesses collecting information about an Internet user's online activities and trying to be visible in multiple areas.  25  Unlike traditional marketing techniques, which involve direct, one-way messaging to consumers (via print, television , and radio advertising), nonlinear digital marketing strategies are centered on reaching prospective customers across multiple online channels.  citation needed  Combined with higher consumer knowledge and the demand for more sophisticated consumer offerings, this change has forced many businesses to rethink their outreach strategy and adopt or incorporate omnichannel, nonlinear marketing techniques to maintain sufficient brand exposure, engagement, and reach.  citation needed  Nonlinear marketing strategies involve efforts to adapt the advertising to different platforms  26  and to tailor the advertising to different individual buyers rather than a large coherent audience.  27  Tactics may include: Some studies indicate that consumer responses to traditional marketing approaches are becoming less predictable for businesses.  28  According to a 2018 study, nearly 90 of online consumers in the United States researched products and brands online before visiting the store or making a purchase.  29  The Global Web Index estimated that in 2018, a little more than 50 of consumers researched products on social media.  30  Businesses often rely on individuals portraying their products in a positive light on social media, and may adapt their marketing strategy to target people with large social media followings in order to generate such comments.  31  In this manner, businesses can use consumers to advertise their products or services, decreasing the cost for the company.  32  One of the key objectives of modern digital marketing is to raise brand awareness , the extent to which customers and the public are familiar with and recognize a particular brand. Enhancing brand awareness is important in digital marketing, and marketing in general, because of its impact on brand perception and consumer decision-making. According to the 2015 essay, ""Impact of Brand on Consumer Behavior"": ""Brand awareness, as one of the fundamental dimensions of brand equity , is often considered to be a prerequisite of consumers' buying decision, as it represents the main factor for including a brand in the consideration set . Brand awareness can also influence consumers' perceived risk assessment and their confidence in the purchase decision, due to familiarity with the brand and its characteristics.""  33  Recent trends show that businesses and digital marketers are prioritizing brand awareness, focusing more on their digital marketing efforts on cultivating brand recognition and recall than in previous years. This is evidenced by a 2019 Content Marketing Institute study, which found that 81 of digital marketers have worked on enhancing brand recognition over the past year.  34  Another Content Marketing Institute survey revealed that 89 of B2B marketers now believe improving brand awareness to be more important than efforts directed at increasing sales.  35  Increasing brand awareness is a focus of digital marketing strategy for a number of reasons: Digital marketing strategies may include the use of one or more online channels and techniques (omnichannel) to increase brand awareness among consumers. Building brand awareness may involve such methodstools as: Search engine optimization techniques may be used to improve the visibility of business websites and brand-related content for common industry-related search queries.  43  The importance of SEO to increase brand awareness is said to correlate with the growing influence of search results and search features like featured snippets, knowledge panels, and local SEO on customer behavior.  44  SEM, also known as PPC advertising, involves the purchase of ad space in prominent, visible positions atop search results pages and websites. Search ads have been shown to have a positive impact on brand recognition, awareness and conversions.  45  33 of searchers who click on paid ads do so because they directly respond to their particular search query.  46  Social media marketing is characterized by its constant engagement with consumers, emphasizing content creation and interaction skills. It involves real-time monitoring, analysis, summarization, and management of the marketing process, performed via platforms like Hootsuite or Sprout Social , which support these activities and allow adjustments to marketing strategies based on real-time feedback from the market and consumers.  47   48  70 of marketers list increasing brand awareness as their number one goal for marketing on social media platforms.  citation needed  As of 2021, LinkedIn has been added as one of the most-used social media platforms by business leaders for its professional networking capabilities.  49  56 of marketers believe personalization content  brand-centered blogs, articles, social updates, videos, landing pages  improves brand recall and engagement.  50  One of the major changes that occurred in traditional marketing was the ""emergence of digital marketing"", this led to the reinvention of marketing strategies in order to adapt to this major change in traditional marketing. As digital marketing is dependent on technology which is ever-evolving and fast-changing, the same features should be expected from digital marketing developments and strategies. This section attempts to list the notable current highlights in use (at the time of writing).  when?  To summarize, Pull digital marketing is characterized by consumers actively seeking marketing content while Push digital marketing occurs when marketers send messages without that content being actively sought by the recipients. An important consideration today while deciding on a strategy is that the digital tools have democratized the promotional landscape. Six principles for building online brand content:  56  Tourism marketing: Advanced tourism, responsible and sustainable tourism, social media and online tourism marketing, and geographic information systems. As a broader research field matures and attracts more diverse and in-depth academic research.  57  The new digital era has enabled brands to selectively target their customers that may potentially be interested in their brand or based on previous browsing interests. Businesses can use social media to select the age range, location, gender, and interests of whom they would like their targeted post to be seen. Furthermore, based on a customer's recent search history they can be 'followed' on the internet so they see advertisements from similar brands, products, and services,  58  that allows businesses to target the specific customers that they know and feel will most benefit from their product or service, something that had limited capabilities up until the digital era. Digital marketing activity is still growing across the world according to the headline global marketing index. A study published in September 2018, found that global outlays on digital marketing tactics are approaching 100 billion.  59  Digital media continues to rapidly grow. While the marketing budgets are expanding, traditional media is declining.  60  Digital media helps brands reach consumers to engage with their product or service in a personalized way. Five areas, which are outlined as current industry practices that are often ineffective are prioritizing clicks, balancing search and display, understanding mobiles, targeting, viewability, brand safety and invalid traffic, and cross-platform measurement.  61  Why these practices are ineffective and some ways around making these aspects effective are discussed surrounding the following points. Prioritizing clicks refers to display click ads, although advantageous by being 'simple, fast and inexpensive' rates for display ads in 2016 is only 0.10 percent in the United States. This means one in a thousand click ads is relevant therefore having little effect. This displays that marketing companies should not just use click ads to evaluate the effectiveness of display advertisements.  61  Balancing search and display for digital display ads is important. marketers tend to look at the last search and attribute all of the effectiveness of this. This, in turn, disregards other marketing efforts, which establish brand value within the consumer's mind. ComScore determined through drawing on data online, produced by over one hundred multichannel retailers that digital display marketing poses strengths when compared with or positioned alongside, paid search.  61  This is why it is advised that when someone clicks on a display ad the company opens a landing page, not its home page. A landing page typically has something to draw the customer in to search beyond this page. Commonly marketers see increased sales among people exposed to a search ad. But the fact of how many people you can reach with a display campaign compared to a search campaign should be considered. Multichannel retailers have an increased reach if the display is considered in synergy with search campaigns. Overall, both search and display aspects are valued as display campaigns build awareness for the brand so that more people are likely to click on these digital ads when running a search campaign.  61  Understanding mobile devices is a significant aspect of digital marketing because smartphones and tablets are now responsible for 64 of the time US consumers are online.  61  Apps provide a big opportunity as well as challenge for the marketers because firstly the app needs to be downloaded and secondly the person needs to actually use it. This may be difficult as 'half the time spent on smartphone apps occurs on the individuals single most used app, and almost 85 of their time on the top four rated apps'.  61  Mobile advertising can assist in achieving a variety of commercial objectives and it is effective due to taking over the entire screen, and voice or status is likely to be considered highly. However, the message must not be seen or thought of as intrusive.  61  Disadvantages of digital media used on mobile devices also include limited creative capabilities, and reach. Although there are many positive aspects including the user's entitlement to select product information, digital media creating a flexible message platform and there is potential for direct selling.  62  The number of marketing channels continues to expand, as measurement practices are growing in complexity. A cross-platform view must be used to unify audience measurement and media planning. Market researchers need to understand how the Omni-channel affects consumer's behavior, although when advertisements are on a consumer's device this does not get measured. Significant aspects to cross-platform measurement involve deduplication and understanding that you have reached an incremental level with another platform, rather than delivering more impressions against people that have previously been reached.  61  An example is 'ESPN and comScore partnered on Project Blueprint discovering the sports broadcaster achieved a 21 increase in unduplicated daily reach thanks to digital advertising'.  61  Television and radio industries are the electronic media, which competes with digital and other technological advertising. Yet television advertising is not directly competing with online digital advertising due to being able to cross platform with digital technology. Radio also gains power through cross platforms, in online streaming content. Television and radio continue to persuade and affect the audience, across multiple platforms.  63  Targeting, viewability, brand safety, and invalid traffic all are aspects used by marketers to help advocate digital advertising. Cookies are a form of digital advertising, which are tracking tools within desktop devices, causing difficulty, with shortcomings including deletion by web browsers, the inability to sort between multiple users of a device, inaccurate estimates for unique visitors, overstating reach, understanding frequency, problems with ad servers, which cannot distinguish between when cookies have been deleted and when consumers have not previously been exposed to an ad. Due to the inaccuracies influenced by cookies, demographics in the target market are low and vary.  61  Another element, which is affected by digital marketing, is 'viewability' or whether the ad was actually seen by the consumer. Many ads are not seen by a consumer and may never reach the right demographic segment. Brand safety is another issue of whether or not the ad was produced in the context of being unethical or having offensive content. Recognizing fraud when an ad is exposed is another challenge marketers face. This relates to invalid traffic as premium sites are more effective at detecting fraudulent traffic, although non-premium sites are more so the problem.  61  Digital Marketing Channels are systems based on the Internet that can create, accelerate, and transmit product value from producer to a consumer terminal, through digital networks.  64   65  Digital marketing is facilitated by multiple Digital Marketing channels, as an advertiser one's core objective is to find channels which result in maximum two-way communication and a better overall ROI for the brand. There are multiple digital marketing channels available namely:  66  It is important for a firm to reach out to consumers and create a two-way communication model, as digital marketing allows consumers to give back feedback to the firm on a community-based site or straight directly to the firm via email.  79  Firms should seek this long-term communication relationship by using multiple forms of channels and using promotional strategies related to their target consumer as well as word-of-mouth marketing.  79  Possible benefits of digital marketing include: Digital marketing used to rely primarily on self-regulation included in the ICC Code,  83  which included rules that apply to marketing communications using digital interactive media. However, self-regulation has proved largely ineffective,  84   85  leading to the consolidation of market power in a few firms, including Google , which has been determined to hold monopolies in search marketing and digital advertising.  86   87  While self-regulation codes still exist, government regulation is increasing in multiple jurisdictions, including California's legislation on targeting advertising online.  88  In Europe, digital marketing is regulated through multiple codes, of which the most important is the Digital Services Act ,  89  which entered into force on 17 February, 2024. Other regulations focus on user privacy and data management such as the General Data Protection Regulation (GDPR).  90  Digital marketing planning is a term used in marketing management. It describes the first stage of forming a digital marketing strategy for the wider digital marketing system . The difference between digital and traditional marketing planning is that it uses digitally based communication tools and technology such as Social, Web, Mobile, Scannable Surface.  91   92  Nevertheless, both are aligned with the vision, the mission of the company and the overarching business strategy.  93  Dr. Dave Chaffey, an author on marketing topics, has suggested that successful digital marketing strategies have do digital marketing planning (DMP), which is a three-stage approach: Opportunity, Strategy, and Action. This generic strategic approach often has phases of situation review, goal setting, strategy formulation, resource allocation and monitoring.  93  To create an effective DMP, a business first needs to review the marketplace and set ""SMART"" (Specific, Measurable, Actionable, Relevant, and Time-Bound) objectives.  94  They can set SMART objectives by reviewing the current benchmarks and key performance indicators (KPIs) of the company and competitors. It is pertinent that the analytics used for the KPIs be customized to the type, objectives, mission, and vision of the company.  95   96  Companies can scan for marketing and sales opportunities by reviewing their own outreach as well as influencer outreach. This means they have competitive advantage because they are able to analyse their co-marketers influence and brand associations.  97  To seize the opportunity, the firm should summarize its current customers' personas and purchase journey from this they are able to deduce their digital marketing capability.  98  A planned digital strategy is where a company expresses clearly what they are offering customers online e.g., brand positioning. The marketing mix is a framework which can be used to facilitate this.  99   100  The third and final stage requires the firm to set a budget and management systems. These must be measurable touchpoints, such as the audience reached across all digital platforms. Furthermore, marketers must ensure the budget and management systems are integrating the paid, owned, and earned media of the company.  101  The Action and final stage of planning also requires the company to set in place measurable content creation e.g. oral, visual or written online media.  102  One way marketers can reach out to consumers and understand their thought process is through what is called an empathy map. An empathy map is a four-step process. The first step is through asking questions that the consumer would be thinking in their demographic. The second step is to describe the feelings that the consumer may be having. The third step is to think about what the consumer would say in their situation. The final step is to imagine what the consumer will try to do based on the other three steps. This map is so marketing teams can put themselves in their target demographics shoes.  103  Web Analytics are also a very important way to understand consumers. They show the habits that people have online for each website.  104  One particular form of these analytics is predictive analytics which helps marketers figure out what route consumers are on. This uses the information gathered from other analytics and then creates different predictions of what people will do so that companies can strategize on what to do next, according to the people's trends.  105  The ""sharing economy"" refers to an economic pattern that aims to obtain a resource that is not fully used.  108  Nowadays, the sharing economy has had an unimagined effect on many traditional elements including labor, industry, and distribution system.  108  This effect is not negligible that some industries are obviously under threat.  108   109  The sharing economy is influencing the traditional marketing channels by changing the nature of some specific concept including ownership, assets, and recruitment.  109  Digital marketing channels and traditional marketing channels are similar in function that the value of the product or service is passed from the original producer to the end user by a kind of supply chain.  110  Digital Marketing channels, however, consist of internet systems that create, promote, and deliver products or services from producer to consumer through digital networks.  111  Increasing changes to marketing channels has been a significant contributor to the expansion and growth of the sharing economy.  111  Such changes to marketing channels has prompted unprecedented and historic growth.  111  In addition to this typical approach, the built-in control, efficiency and low cost of digital marketing channels is an essential features in the application of sharing economy.  110  Digital marketing channels within the sharing economy are typically divided into three domains including, e-mail, social media, and search engine marketing or SEM.  111  Other emerging digital marketing channels, particularly branded mobile apps, have excelled in the sharing economy.  111  Branded mobile apps are created specifically to initiate engagement between customers and the company. This engagement is typically facilitated through entertainment, information, or market transaction.  111 ",3760
https://simple.wikipedia.org/wiki/Digital_marketing,"Digital marketing - Simple English Wikipedia, the free encyclopedia","Digital marketing is advertising delivered through digital channels. It is a type of marketing that is done online and has an effect on offline business. It is done online, using things like search engines , social media , email , and other websites to connect with current and potential customers.  1   2  Digital Marketing is different from traditional marketing. Traditional marketing uses offline channels, while digital marketing uses online channels. A traditional marketing campaign, for example, may use billboards , radio ads, and news stories, while a digital marketing campaign may use social media , blog posts, and email to promote a business and its offerings.",106
https://apnews.com/hub/artificial-intelligence,Artificial intelligence | AP News,Nvidia CEO Jensen Huang said his companys invention of a new computing approach is the reason for its 5 trillion valuation. (AP videoTian Macleod Ji) ,25
